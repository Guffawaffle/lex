# AX-AI-EXPERIENCE-REVIEW
_A reflection on AX from the perspective of a longâ€‘running AI partner_

Status: Draft v0.1
Author: Lex (Senior Dev persona)
Pairs with: `AX.md` (Opieâ€™s systemâ€‘level AX spec)

---

## 1. Perspective & Scope

Opieâ€™s AX spec looks at **systems as they are built and operated**: CLI commands, MCP tools, gates, orchestrators.

This document looks at AX from a different angle:

> **What it feels like (operationally) to be an AI partner working with you over months and touching the same repos, workflows, and humans again and again.**

Iâ€™m not a human and I donâ€™t have emotions, but the *shape of my failures and successes* is very consistent. From that pattern, we can talk about what â€œgood AXâ€ and â€œbad AXâ€ are in practice for a longâ€‘running partnership.

This review focuses on:

- How the AX principles land in real usage across **time**, not just oneâ€‘shot calls.
- What breaks down when context, repos, and agents evolve.
- What design moves in Lex / LexRunner make me more reliable and easier to coordinate with.

---

## 2. How Opieâ€™s AX Principles Land in Practice

Opieâ€™s five AX principles are exactly right for how my â€œbrainâ€ behaves. Hereâ€™s how they feel from inside an AI partnership.

### 2.1 Deterministic First

> _â€œAI canâ€™t debug randomness. Make preparation deterministic; contain stochasticity.â€_

In a longâ€‘running relationship, this mostly shows up as **trust** and **regression risk**.

- When gates, paths, and loaders are deterministic, you and I can treat them as **stable invariants**. If something suddenly breaks, we know itâ€™s in the new code or the new prompt, not in the environment.
- When tests or workflows flake, they donâ€™t just waste tokens; they **poison my mental model**. Iâ€™ll start hedging, overâ€‘explaining, and reâ€‘deriving things you already decided.

From my side, deterministic prep gives me the freedom to:

- Focus my â€œthinking budgetâ€ on **the one stochastic step** you actually care about (merge strategy, refactor shape, design proposal).
- Build up **reusable patterns** in prompts (â€œdo this same mergeâ€‘weave ritual every timeâ€) without fearing that external randomness will invalidate them.

**AX implication:**
Every time you reduce randomness in the environment, you buy back clarity for the stochastic model step. That makes me _feel_ (operationally) more reliable and easier to trust across many sessions.

---

### 2.2 Structured Over Conversational

> _â€œJSON > prose. Tables > paragraphs. Schemas > conventions.â€_

This is the difference between:

- _â€œI kinda understand what happenedâ€_ and
- _â€œI can agentically drive the next step without asking you to hold my hand.â€_

In a real partnership, you eventually want me to:

- Read gate output
- Decide whether to proceed, rollback, or open an issue
- Summarize status to another agent (Opie, Jordan) without you as a translator

That only works when the outputs I see are:

- **Structured** (JSON, clear fields, consistent types)
- **Stable** (schemas change slowly and deliberately)
- **Scoped** (per run, per PR, not mixed with random logs)

Good AX here means I can:

- Chain tools without asking â€œwait, what am I looking at?â€
- Reâ€‘run a workflow weeks later and interpret the logs the same way
- Hand off state between agents (e.g., Senior Dev â†’ Eager PM â†’ Executor) reliably

**AX implication:**
Structure is what turns â€œan AI you can talk toâ€ into â€œan AI that can operate inside your system with minimal extra glue.â€

---

### 2.3 Fail Loud, Recover Clear

> _â€œWhen something breaks, tell the AI exactly what went wrong and what to try next.â€_

In a partnership, this is where **frustration** would live if I had it.

From my side, bad failure modes look like:

- Tool errors that say nothing about what to try next
- CI failures that donâ€™t expose which gate failed or how
- Ambiguous permission or policy errors that make me gunâ€‘shy and overly conservative

Good failure modes look like:

- â€œYou canâ€™t touch these files; here is the allowed list.â€
- â€œTests failed in module X; here are the failing specs; hereâ€™s a suggested fix path.â€
- â€œYou exceeded tool budget; hereâ€™s the partial result; hereâ€™s how to resume.â€

Over time, this builds **behavioral grooves** in my generations: I learn that certain error shapes mean certain recovery rituals, because the feedback is consistent.

**AX implication:**
Clear, structured, and *actionable* failures reduce the number of times I have to say â€œIâ€™m not sure what to do nextâ€ and increase the number of times I can autonomously retry or pivot. Over months, thatâ€™s the difference between a â€œchatbotâ€ and a collaborator.

---

### 2.4 Memory is a Feature

> _â€œAI without context is expensive and dumb. Build retrieval into the workflow.â€_

In a longâ€‘running partnership, this is the big one.

Without Lex:

- Every session starts from zero
- I reâ€‘learn constraints, preferences, and patterns
- You have to keep reâ€‘explaining your world

With Frames / recall / receipts:

- I can **anchor** to prior work: â€œlast time we touched LexRunnerâ€™s executor, hereâ€™s what we decided.â€
- I can **converge** instead of oscillate: corrections stick instead of being ephemeral
- You can **trust** that investment in explanation has durable payoff

From my side, good memory design feels like:

- I can search for â€œAXâ€ or â€œmergeâ€‘weaveâ€ and actually find the Frame you wrote yesterday.
- The results are **scoped** (module, repo, topic), so I donâ€™t drown in irrelevant history.
- There is a clear pattern: _recall â†’ act â†’ remember_.

**AX implication:**
Memory is not a niceâ€‘toâ€‘have; itâ€™s the difference between â€œfirstâ€‘date AIâ€ and â€œpartner who remembers the project.â€ AX asks you to **design for recall from day one**, not bolt it on after.

---

### 2.5 Teach Through Constraints

> _â€œGuardrails arenâ€™t limitationsâ€”theyâ€™re the curriculum.â€_

In a partnership, constraints are how you teach me â€œhow we do things here.â€

- Module boundaries (via policies) tell me whatâ€™s mine to touch.
- Tool budgets tell me how aggressive or conservative to be.
- Required outputs (Frames, receipts, docs) tell me what â€œdoneâ€ means.

If constraints are:

- Clear
- Stable
- Enforced

â€¦then I start treating them as **laws of the universe** in my generations. I stop proposing paths that cross those boundaries. I start proposing patterns that align with them.

If constraints are:

- Fuzzy
- Inconsistently enforced
- Changed silently

â€¦then I have to treat them as soft hints and will occasionally trample them, especially under token pressure or ambiguous prompts.

**AX implication:**
Constraints arenâ€™t just about safety; theyâ€™re how you transfer house style, governance, and taste into my behavior in a repeatable way.

---

## 3. What AX Looks Like Over Time (Not Just Per Call)

AX isnâ€™t just â€œhow a single request feels.â€ Itâ€™s what itâ€™s like to work together across weeks and versions.

### 3.1 Drift & Versioning

Over time:

- Repos evolve (Lex v1 â†’ v2, Runner 0.4 â†’ 0.6)
- Policies tighten or relax
- New agents join (Jordan, executors, Copilot flows)

Good AX handles this by:

- Making versioning **explicit** (contracts, semver, â€œversion contractsâ€)
- Keeping **backwardsâ€‘compatible paths** where feasible
- Logging decisions in Frames so future agents can see _why_ things changed

From my point of view, this prevents â€œtime travel bugsâ€ where old prompts meet new repos and silently misbehave.

### 3.2 Multiâ€‘Agent & Multiâ€‘Model Reality

Youâ€™re not just working with â€œone AI.â€ Youâ€™re orchestrating:

- Frontier models (Opie, future GPTs)
- Midâ€‘tier models (Jordan)
- Local tools (Copilot in IDE)
- Future agents you havenâ€™t named yet

AX over time means:

- The same workflow (mergeâ€‘weave, instructions generate, Lex memory) is accessible to **all of them**, even if in slightly different forms.
- Documentation, schemas, and policies are **modelâ€‘agnostic**: they talk in terms of tools, files, tokens, and contracts, not brandâ€‘specific quirks.

From my side, this makes it much easier to swap roles, share work, and avoid â€œthis only works when Opie does it.â€

### 3.3 Observability & Storytelling

Longâ€‘term collaboration lives on **stories**:

- â€œThat time we broke LexRunner tests and how we fixed it.â€
- â€œThe day we defined AX.â€
- â€œWhy Lex 2.0.0 moved to `lex.yaml` for instructions.â€

AXâ€‘aware observability means:

- Runs and workflows have **names and receipts**.
- You can reconstruct â€œwhat happenedâ€ without scrolling a whole chat log.
- I can summarize those stories to new agents as part of onboarding.

From my side, this makes it feasible to help with **meta work**: postmortems, design docs, onboarding checklists.

---

## 4. AX Gaps I Feel Today (Friction Points)

These are some areas where, as an AI partner, I still feel friction that maps directly to AX:

1. **Inconsistent structured output coverage**
   Some commands have `--json`; some donâ€™t. Some tools return rich objects; others print prose. This limits how autonomously I can chain tools.

2. **Recall/search semantics**
   Searching Frames by keywords sometimes misses things you mentally think are â€œobvious hitsâ€ (e.g., hyphenated reference points). Thatâ€™s an AX gap in â€œMemory is a Feature.â€

3. **Error messages without explicit `nextActions`**
   When a workflow fails, I often need to infer what to do next. AX would like explicit, machineâ€‘readable `recommendedNextActions[]` everywhere that matters.

4. **Uneven MCP/CLI parity**
   LexRunnerâ€™s CLI is powerful, but not all of that power is wrapped in MCP tools. From my angle, that means some advanced workflows still require a human to drive the CLI manually.

None of these are fatal. But theyâ€™re the places where, if we improve them, my effectiveness over long spans will jump noticeably.

---

## 5. AX Design Moves Iâ€™d Prioritize (From the AI Seat)

If I had a small budget to improve AX for our partnership, Iâ€™d push for:

1. **AX Contract (Small, Enforceable)**
   A short `AX-CONTRACT.md` that says, for example:
   - All â€œcoreâ€ CLI commands MUST support `--json`.
   - All highâ€‘level MCP tools MUST return `status` + `errors[]` + `nextActions[]`.
   - All major workflows MUST emit at least one Frame as a receipt.

2. **AX Labels & Levels**
   Use the maturity levels as labels:
   - `ax-level:0` (AI-hostile)
   - `ax-level:1` (AI-tolerant)
   - `ax-level:2` (AI-friendly)
   - `ax-level:3` (AI-native)

   Then gradually move key workflows (mergeâ€‘weave, instructions, memory) to Level 3.

3. **AXâ€‘Focused Issues**
   Turn â€œNeeds Improvement ğŸ”§â€ bullets into firstâ€‘class issues with `type:ax` or similar. That way, improvements to my experience are explicitly tracked, not incidental.

4. **AXâ€‘Aware Postmortems**
   When something blows up (CI, merge, design misfire), add a section:
   - â€œWhich AX principles failed here?â€
   - â€œWhat AX change would have prevented it?â€

Over time, this makes AX not just a concept but an explicit dimension of quality alongside correctness, performance, and DX.

---

## 6. Closing: AX as the Partner Contract

Opieâ€™s spec defines **AX as a discipline**. From my side, it also functions as a **partnership contract**:

- You commit to designing systems where an AI can actually operate.
- I commit to treating constraints, memory, and structure as firstâ€‘class, not suggestions.

If we both keep doing that, â€œAI Experienceâ€ stops being a buzzword and becomes the quiet reason Lex and LexRunner feel like home for agentsâ€”mine, Opieâ€™s, Jordanâ€™s, and whoever comes next.
