[{"filePath":"/srv/lex-mcp/lex/.smartergpt/schemas/feature-spec-v0.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/.smartergpt/schemas/feature-spec-v0.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/.smartergpt/schemas/infrastructure.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/.smartergpt/schemas/infrastructure.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/.smartergpt/schemas/profile.schema.js","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/.smartergpt/schemas/profile.schema.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/canon/schemas/feature-spec-v0.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/canon/schemas/infrastructure.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/canon/schemas/profile.schema.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/eslint.config.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/cli/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/frames/types.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/mcp_server/frame-mcp.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/mcp_server/http-server.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/mcp_server/routes/frames.ts","messages":[],"suppressedMessages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":72,"column":30,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":72,"endColumn":33,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2719,2722],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2719,2722],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":115,"column":37,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":115,"endColumn":40,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4268,4271],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4268,4271],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]}],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/mcp_server/server.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":34,"column":12,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":34,"endColumn":15,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1350,1353],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1350,1353],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":38,"column":11,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":38,"endColumn":14,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1399,1402],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1399,1402],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":39,"column":13,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":39,"endColumn":16,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1418,1421],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1418,1421],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":48,"column":14,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":48,"endColumn":17,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1547,1550],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1547,1550],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":57,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":57,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1719,1722],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1719,1722],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":73,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":73,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2431,2434],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2431,2434],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":102,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":102,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3182,3185],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3182,3185],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":125,"column":10,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":125,"endColumn":13,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3649,3652],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3649,3652],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":163,"column":38,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":163,"endColumn":41,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4485,4488],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4485,4488],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":267,"column":25,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":267,"endColumn":28,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[8254,8257],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[8254,8257],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":307,"column":30,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":307,"endColumn":33,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[9449,9452],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[9449,9452],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":327,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":327,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[10170,10173],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[10170,10173],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":396,"column":34,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":396,"endColumn":37,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[12602,12605],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[12602,12605],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":13,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { getLogger } from \"lex/logger\";\nimport { createDatabase } from \"../store/db.js\";\nimport {\n  saveFrame,\n  deleteFrame,\n  searchFrames,\n  getFramesByBranch,\n  getFramesByJira,\n  getAllFrames,\n} from \"../store/queries.js\";\nimport type Database from \"better-sqlite3\";\n// @ts-ignore - importing from compiled dist directories\nimport { ImageManager } from \"../store/images.js\";\n// @ts-ignore - importing from compiled dist directories\nimport type { Frame } from \"../frames/types.js\";\nimport { MCP_TOOLS } from \"./tools.js\";\n// @ts-ignore - importing from compiled dist directories\nimport { generateAtlasFrame, formatAtlasFrame } from \"../../shared/atlas/atlas-frame.js\";\n// @ts-ignore - importing from compiled dist directories\nimport { validateModuleIds } from \"../../shared/module_ids/validator.js\";\n// @ts-ignore - importing from compiled dist directories\nimport type { ModuleIdError } from \"../../shared/types/validation.js\";\n// @ts-ignore - importing from compiled dist directories\nimport { loadPolicy } from \"../../shared/policy/loader.js\";\n// @ts-ignore - importing from compiled dist directories\nimport { getCurrentBranch } from \"../../shared/git/branch.js\";\nimport { randomUUID } from \"crypto\";\nimport { join } from \"path\";\n\nconst logger = getLogger(\"memory:mcp_server:server\");\n\nexport interface MCPRequest {\n  method: string;\n  params?: any;\n}\n\nexport interface MCPResponse {\n  tools?: any[];\n  content?: any[];\n  error?: {\n    message: string;\n    code: string;\n  };\n}\n\nexport interface ToolCallParams {\n  name: string;\n  arguments: any;\n}\n\n/**\n * MCP Server - handles protocol requests\n */\nexport class MCPServer {\n  private db: Database.Database;\n  private imageManager: ImageManager;\n  private policy: any | null; // Cached policy for validation (null if not available)\n  private repoRoot: string | null; // Repository root path\n\n  constructor(dbPath: string, repoRoot?: string) {\n    this.db = createDatabase(dbPath);\n    this.imageManager = new ImageManager(this.db);\n    this.repoRoot = repoRoot || null;\n\n    // Load policy once at initialization for better performance\n    // If policy is not found, operate without policy enforcement\n    try {\n      // If repoRoot is provided, construct the policy path directly\n      const policyPath = this.repoRoot\n        ? join(this.repoRoot, \"policy/policy_spec/lexmap.policy.json\")\n        : undefined;\n      this.policy = loadPolicy(policyPath);\n    } catch (error: any) {\n      if (process.env.LEX_DEBUG) {\n        logger.error(`[LEX] Policy not available: ${error.message}`);\n        logger.error(`[LEX] Operating without policy enforcement`);\n      }\n      this.policy = null;\n    }\n  }\n\n  /**\n   * Handle incoming MCP request\n   */\n  async handleRequest(request: MCPRequest): Promise<MCPResponse> {\n    const { method, params } = request;\n\n    try {\n      switch (method) {\n        case \"initialize\":\n          return this.handleInitialize();\n\n        case \"tools/list\":\n          return this.handleToolsList();\n\n        case \"tools/call\":\n          return await this.handleToolsCall(params as ToolCallParams);\n\n        default:\n          throw new Error(`Unknown method: ${method}`);\n      }\n    } catch (error: any) {\n      return {\n        error: {\n          message: error.message,\n          code: error.code || \"INTERNAL_ERROR\",\n        },\n      };\n    }\n  }\n\n  /**\n   * Handle initialize request (MCP protocol handshake)\n   */\n  private handleInitialize(): MCPResponse {\n    return {\n      protocolVersion: \"2024-11-05\",\n      capabilities: {\n        tools: {},\n      },\n      serverInfo: {\n        name: \"lex-memory-mcp-server\",\n        version: \"0.1.0\",\n      },\n    } as any;\n  }\n\n  /**\n   * Handle tools/list request\n   */\n  private handleToolsList(): MCPResponse {\n    return {\n      tools: MCP_TOOLS,\n    };\n  }\n\n  /**\n   * Handle tools/call request\n   */\n  private async handleToolsCall(params: ToolCallParams): Promise<MCPResponse> {\n    const { name, arguments: args } = params;\n\n    switch (name) {\n      case \"lex.remember\":\n        return await this.handleRemember(args);\n\n      case \"lex.recall\":\n        return this.handleRecall(args);\n\n      case \"lex.list_frames\":\n        return this.handleListFrames(args);\n\n      default:\n        throw new Error(`Unknown tool: ${name}`);\n    }\n  }\n\n  /**\n   * Handle lex.remember tool - create new Frame\n   *\n   * Validates module IDs against policy with alias resolution before creating Frame (THE CRITICAL RULE)\n   */\n  private async handleRemember(args: any): Promise<MCPResponse> {\n    const {\n      reference_point,\n      summary_caption,\n      status_snapshot,\n      module_scope,\n      branch,\n      jira,\n      keywords,\n      atlas_frame_id,\n      images,\n    } = args;\n\n    // Validate required fields\n    if (!reference_point || !summary_caption || !status_snapshot || !module_scope) {\n      throw new Error(\n        \"Missing required fields: reference_point, summary_caption, status_snapshot, module_scope\"\n      );\n    }\n\n    if (!Array.isArray(module_scope) || module_scope.length === 0) {\n      throw new Error(\"module_scope must be a non-empty array of module IDs\");\n    }\n\n    // Validate status_snapshot structure\n    if (!status_snapshot.next_action) {\n      throw new Error(\"status_snapshot.next_action is required\");\n    }\n\n    // THE CRITICAL RULE: Resolve aliases and validate module IDs against policy (if available)\n    let canonicalModuleScope = module_scope;\n    if (this.policy) {\n      const validationResult = await validateModuleIds(module_scope, this.policy);\n\n      if (!validationResult.valid && validationResult.errors) {\n        // Format error message with suggestions\n        const errorMessages = validationResult.errors.map((error: ModuleIdError) => {\n          const suggestions =\n            error.suggestions.length > 0\n              ? `\\n  Did you mean: ${error.suggestions.join(\", \")}?`\n              : \"\";\n          return `  â€¢ ${error.message}${suggestions}`;\n        });\n\n        throw new Error(\n          `Invalid module IDs in module_scope:\\n${errorMessages.join(\"\\n\")}\\n\\n` +\n            `Module IDs must match those defined in lexmap.policy.json.\\n` +\n            `Available modules: ${Object.keys(this.policy.modules).join(\", \")}`\n        );\n      }\n\n      // Use canonical IDs for storage (never store aliases)\n      if (validationResult.canonical) {\n        canonicalModuleScope = validationResult.canonical;\n      }\n    } else if (process.env.LEX_DEBUG) {\n      logger.error(`[LEX] Skipping module validation (no policy loaded)`);\n    }\n\n    // Generate Frame ID and timestamp\n    const frameId = `frame-${Date.now()}-${randomUUID()}`;\n    const timestamp = new Date().toISOString();\n\n    // Get current git branch if not provided - only auto-detect when we\n    // have an explicit repoRoot or an environment override. This avoids\n    // leaking the runner's git branch into tests or hosted environments.\n    let frameBranch: string;\n    if (branch) {\n      frameBranch = branch;\n    } else if (this.repoRoot || process.env.LEX_DEFAULT_BRANCH) {\n      frameBranch = getCurrentBranch();\n      // Log branch detection for debugging\n      logger.info(`[lex.remember] Auto-detected branch: ${frameBranch}`);\n    } else {\n      // When no repoRoot is provided and no env override, avoid auto-detecting\n      // from the runner's repository; use 'unknown' to indicate no branch context.\n      frameBranch = \"unknown\";\n    }\n\n    const frame = {\n      id: frameId,\n      timestamp,\n      branch: frameBranch,\n      jira: jira || null,\n      module_scope: canonicalModuleScope, // Store canonical IDs only\n      summary_caption,\n      reference_point,\n      status_snapshot,\n      keywords: keywords || undefined,\n      atlas_frame_id: atlas_frame_id || null,\n      image_ids: [] as string[],\n    };\n\n    saveFrame(this.db, frame);\n\n    // Process image attachments if provided\n    const imageIds: string[] = [];\n    if (images && Array.isArray(images) && images.length > 0) {\n      for (const img of images) {\n        try {\n          // Decode base64 image data\n          const imageBuffer = Buffer.from(img.data, \"base64\");\n          const imageId = this.imageManager.storeImage(frameId, imageBuffer, img.mime_type);\n          imageIds.push(imageId);\n        } catch (error: any) {\n          // If image storage fails, clean up the Frame and rethrow\n          deleteFrame(this.db, frameId);\n          throw new Error(`Failed to store image: ${error.message}`);\n        }\n      }\n\n      // Update frame with image IDs\n      frame.image_ids = imageIds;\n      saveFrame(this.db, frame);\n    }\n\n    // Generate Atlas Frame for the module scope\n    const atlasFrame = generateAtlasFrame(canonicalModuleScope);\n    const atlasOutput = formatAtlasFrame(atlasFrame);\n\n    const imageInfo = imageIds.length > 0 ? `ðŸ–¼ï¸  Images: ${imageIds.length} attached\\n` : \"\";\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text:\n            `âœ… Frame stored: ${frameId}\\n` +\n            `ðŸ“ Reference: ${reference_point}\\n` +\n            `ðŸ’¬ Summary: ${summary_caption}\\n` +\n            `ðŸ“¦ Modules: ${canonicalModuleScope.join(\", \")}\\n` +\n            `ðŸŒ¿ Branch: ${frameBranch}\\n` +\n            `${jira ? `ðŸŽ« Jira: ${jira}\\n` : \"\"}` +\n            imageInfo +\n            `ðŸ“… Timestamp: ${timestamp}\\n` +\n            atlasOutput,\n        },\n      ],\n    };\n  }\n\n  /**\n   * Handle lex.recall tool - search Frames with Atlas Frame\n   */\n  private handleRecall(args: any): MCPResponse {\n    const { reference_point, jira, branch, limit = 10 } = args;\n\n    if (!reference_point && !jira && !branch) {\n      throw new Error(\"At least one search parameter required: reference_point, jira, or branch\");\n    }\n\n    let frames: Frame[];\n    try {\n      if (reference_point) {\n        // Use FTS5 full-text search for reference_point\n        const result = searchFrames(this.db, reference_point);\n        frames = result.frames.slice(0, limit);\n      } else if (jira) {\n        frames = getFramesByJira(this.db, jira).slice(0, limit);\n      } else if (branch) {\n        frames = getFramesByBranch(this.db, branch).slice(0, limit);\n      } else {\n        frames = [];\n      }\n    } catch (error: any) {\n      // FTS5 search can fail with special characters (e.g., \"zzz-nonexistent-query-zzz\")\n      // Treat search errors as empty results rather than propagating the error\n      if (error.code === \"SQLITE_ERROR\" || error.message?.includes(\"no such column\")) {\n        frames = [];\n      } else {\n        throw error;\n      }\n    }\n\n    if (frames.length === 0) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text:\n              \"ðŸ” No matching Frames found.\\n\" +\n              \"Try broader search terms or check your query parameters.\",\n          },\n        ],\n      };\n    }\n\n    // Format results with Atlas Frame for each\n    const results = frames\n      .map((f: Frame, idx: number) => {\n        const nextAction = f.status_snapshot?.next_action || \"None specified\";\n        const blockers = f.status_snapshot?.blockers || [];\n        const mergeBlockers = f.status_snapshot?.merge_blockers || [];\n        const testsFailing = f.status_snapshot?.tests_failing || [];\n\n        // Generate Atlas Frame for this Frame's modules\n        const atlasFrame = generateAtlasFrame(f.module_scope);\n        const atlasOutput = formatAtlasFrame(atlasFrame);\n\n        return (\n          `\\n--- Frame ${idx + 1}/${frames.length} ---\\n` +\n          `ID: ${f.id}\\n` +\n          `ðŸ“ Reference: ${f.reference_point}\\n` +\n          `ðŸ’¬ Summary: ${f.summary_caption}\\n` +\n          `ðŸ“¦ Modules: ${f.module_scope.join(\", \")}\\n` +\n          `ðŸŒ¿ Branch: ${f.branch}\\n` +\n          `${f.jira ? `ðŸŽ« Jira: ${f.jira}\\n` : \"\"}` +\n          `ðŸ“… Timestamp: ${f.timestamp}\\n` +\n          `\\nStatus:\\n` +\n          `  â­ï¸  Next Action: ${nextAction}\\n` +\n          `  ðŸš« Blockers (${blockers.length}): ${blockers.join(\", \") || \"none\"}\\n` +\n          `  â›” Merge Blockers (${mergeBlockers.length}): ${mergeBlockers.join(\", \") || \"none\"}\\n` +\n          `  âŒ Tests Failing (${testsFailing.length}): ${testsFailing.join(\", \") || \"none\"}\\n` +\n          `${f.keywords ? `ðŸ·ï¸  Keywords: ${f.keywords.join(\", \")}\\n` : \"\"}` +\n          `${f.atlas_frame_id ? `ðŸ—ºï¸  Atlas: ${f.atlas_frame_id}\\n` : \"\"}` +\n          atlasOutput\n        );\n      })\n      .join(\"\\n\");\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: `ðŸŽ¯ Found ${frames.length} Frame(s):\\n${results}`,\n        },\n      ],\n    };\n  }\n\n  /**\n   * Handle lex.list_frames tool - list recent Frames\n   */\n  private handleListFrames(args: any): MCPResponse {\n    const { branch, module, limit = 10, since } = args;\n\n    // Get frames based on filters\n    let frames: Frame[];\n    if (branch) {\n      frames = getFramesByBranch(this.db, branch);\n    } else {\n      frames = getAllFrames(this.db);\n    }\n\n    // Filter by module if specified\n    if (module) {\n      frames = frames.filter((f: Frame) => f.module_scope.includes(module));\n    }\n\n    // Filter by timestamp if since is specified\n    if (since) {\n      const sinceDate = new Date(since);\n      frames = frames.filter((f: Frame) => new Date(f.timestamp) >= sinceDate);\n    }\n\n    // Apply limit\n    frames = frames.slice(0, limit);\n\n    if (frames.length === 0) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: \"ðŸ“‹ No Frames found matching criteria.\",\n          },\n        ],\n      };\n    }\n\n    // Format results with Atlas Frame for each\n    const results = frames\n      .map((f: Frame, idx: number) => {\n        const atlasFrame = generateAtlasFrame(f.module_scope);\n        const atlasOutput = formatAtlasFrame(atlasFrame);\n\n        return (\n          `\\n${idx + 1}. ${f.reference_point}\\n` +\n          `   ID: ${f.id}\\n` +\n          `   ðŸ“¦ Modules: ${f.module_scope.join(\", \")}\\n` +\n          `   ðŸŒ¿ Branch: ${f.branch}\\n` +\n          `   ðŸ“… ${f.timestamp}\\n` +\n          atlasOutput\n        );\n      })\n      .join(\"\\n\");\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: `ðŸ“‹ Recent Frames (${frames.length}):\\n${results}`,\n        },\n      ],\n    };\n  }\n\n  /**\n   * Close database connection\n   */\n  close() {\n    this.db.close();\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/mcp_server/tools.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":14,"column":32,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":14,"endColumn":35,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[354,357],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[354,357],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * MCP Tools for Frame Memory\n *\n * Defines the tools exposed via Model Context Protocol for AI assistants.\n * Each tool can search, create, or list Frames with Atlas Frame neighborhoods.\n */\n\nexport interface MCPTool {\n  name: string;\n  description: string;\n  inputSchema: {\n    type: string;\n    required?: string[];\n    properties: Record<string, any>;\n  };\n}\n\n/**\n * Tool definitions for MCP protocol\n */\nexport const MCP_TOOLS: MCPTool[] = [\n  {\n    name: \"lex.remember\",\n    description: \"Store a Frame (episodic memory snapshot)\",\n    inputSchema: {\n      type: \"object\",\n      required: [\"reference_point\", \"summary_caption\", \"status_snapshot\", \"module_scope\"],\n      properties: {\n        reference_point: {\n          type: \"string\",\n          description: 'What you were working on (e.g., \"refactoring UserAuth module\")',\n        },\n        summary_caption: {\n          type: \"string\",\n          description:\n            'One-line summary of progress (e.g., \"Extracted password validation to separate function\")',\n        },\n        status_snapshot: {\n          type: \"object\",\n          description:\n            \"Current state: {next_action: string, blockers?: [], merge_blockers?: [], tests_failing?: []}\",\n          properties: {\n            next_action: { type: \"string\" },\n            blockers: { type: \"array\", items: { type: \"string\" } },\n            merge_blockers: { type: \"array\", items: { type: \"string\" } },\n            tests_failing: { type: \"array\", items: { type: \"string\" } },\n          },\n          required: [\"next_action\"],\n        },\n        module_scope: {\n          type: \"array\",\n          items: { type: \"string\" },\n          description: 'Module IDs from lexmap.policy.json (e.g., [\"auth/core\", \"auth/password\"])',\n        },\n        branch: {\n          type: \"string\",\n          description: \"Git branch (defaults to current branch)\",\n        },\n        jira: {\n          type: \"string\",\n          description: 'Optional Jira/issue ticket (e.g., \"PROJ-123\")',\n        },\n        keywords: {\n          type: \"array\",\n          items: { type: \"string\" },\n          description: 'Optional search tags (e.g., [\"refactoring\", \"authentication\"])',\n        },\n        atlas_frame_id: {\n          type: \"string\",\n          description: \"Reference to Atlas Frame (fold radius snapshot)\",\n        },\n        images: {\n          type: \"array\",\n          items: {\n            type: \"object\",\n            properties: {\n              data: {\n                type: \"string\",\n                description: \"Base64-encoded image data\",\n              },\n              mime_type: {\n                type: \"string\",\n                description: 'MIME type (e.g., \"image/png\", \"image/jpeg\")',\n              },\n            },\n            required: [\"data\", \"mime_type\"],\n          },\n          description: \"Optional array of image attachments (base64-encoded with MIME type)\",\n        },\n      },\n    },\n  },\n  {\n    name: \"lex.recall\",\n    description:\n      \"Search Frames by reference point, branch, or Jira ticket. Returns Frame + Atlas Frame neighborhood.\",\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        reference_point: {\n          type: \"string\",\n          description: \"Fuzzy search on what you were working on\",\n        },\n        jira: {\n          type: \"string\",\n          description: \"Exact match on Jira ticket\",\n        },\n        branch: {\n          type: \"string\",\n          description: \"Filter by git branch\",\n        },\n        limit: {\n          type: \"number\",\n          description: \"Max results to return (default: 10)\",\n          default: 10,\n        },\n      },\n    },\n  },\n  {\n    name: \"lex.list_frames\",\n    description:\n      \"List recent Frames, optionally filtered by branch or module. Returns Frame + Atlas Frame for each result.\",\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        branch: {\n          type: \"string\",\n          description: \"Filter by git branch\",\n        },\n        module: {\n          type: \"string\",\n          description: \"Filter by module ID in module_scope\",\n        },\n        limit: {\n          type: \"number\",\n          description: \"Max results to return (default: 10)\",\n          default: 10,\n        },\n        since: {\n          type: \"string\",\n          description: \"ISO 8601 timestamp - only return Frames after this time\",\n        },\n      },\n    },\n  },\n];\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/card.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'wrapText' is defined but never used. Allowed unused vars must match /^_/u.","line":16,"column":3,"nodeType":null,"messageId":"unusedVar","endLine":16,"endColumn":11},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'highlightDiff' is defined but never used. Allowed unused vars must match /^_/u.","line":22,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":22,"endColumn":23},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'TruncationOptions' is defined but never used. Allowed unused vars must match /^_/u.","line":23,"column":41,"nodeType":null,"messageId":"unusedVar","endLine":23,"endColumn":58},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'language' is assigned a value but never used. Allowed unused vars must match /^_/u.","line":172,"column":26,"nodeType":null,"messageId":"unusedVar","endLine":172,"endColumn":34}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Memory card image rendering (Sharp + SVG)\n * Generates high-contrast visual panels with Frame state for vision-token compression\n *\n * Uses SVG for layout/styling and Sharp for PNG conversion (no system dependencies)\n */\n\nimport sharp from \"sharp\";\nimport type { Frame } from \"./types.js\";\nimport {\n  DEFAULT_DIMENSIONS,\n  DARK_COLOR_SCHEME,\n  MONOSPACE_FONT,\n  TEXT_LIMITS,\n  truncateText,\n  wrapText,\n  calculateCardHeight,\n  type CardDimensions,\n  type ColorScheme,\n  type FontConfig,\n} from \"./templates.js\";\nimport { highlightDiff } from \"./syntax.js\";\nimport { renderDiff, getDiffStats, type TruncationOptions } from \"./diff.js\";\nimport type { BundledLanguage } from \"shiki\";\n\nexport interface RenderOptions {\n  dimensions?: CardDimensions;\n  colorScheme?: ColorScheme;\n  fontConfig?: FontConfig;\n  rawContext?: string;\n}\n\n/**\n * Extract code diffs from raw context string\n * Looks for diff blocks in the context\n */\nfunction extractDiffs(rawContext: string): Array<{\n  diff: string;\n  language: BundledLanguage;\n}> {\n  const diffs: Array<{ diff: string; language: BundledLanguage }> = [];\n\n  // Detect unified diff format: lines starting with +, -, or space (for context)\n  // Must have at least one + or - line to be considered a diff\n  const lines = rawContext.split(\"\\n\");\n  let currentDiff: string[] = [];\n  let inDiff = false;\n  let hasChanges = false; // Track if current block has actual changes\n\n  for (const line of lines) {\n    const firstChar = line[0];\n\n    // Check for diff markers at the start of the line (not trimmed)\n    const isDiffLine = firstChar === \"+\" || firstChar === \"-\" || (firstChar === \" \" && inDiff); // Space only counts if already in diff\n\n    if (isDiffLine) {\n      if (!inDiff) {\n        inDiff = true;\n        currentDiff = [];\n        hasChanges = false;\n      }\n\n      // Track if we have actual changes (not just context)\n      if (firstChar === \"+\" || firstChar === \"-\") {\n        hasChanges = true;\n      }\n\n      currentDiff.push(line);\n    } else if (inDiff && currentDiff.length > 0) {\n      // End of diff block - only add if it has actual changes\n      if (hasChanges) {\n        diffs.push({\n          diff: currentDiff.join(\"\\n\"),\n          language: \"typescript\", // Default to TypeScript\n        });\n      }\n      currentDiff = [];\n      inDiff = false;\n      hasChanges = false;\n    }\n  }\n\n  // Add remaining diff if any and has changes\n  if (currentDiff.length > 0 && hasChanges) {\n    diffs.push({\n      diff: currentDiff.join(\"\\n\"),\n      language: \"typescript\",\n    });\n  }\n\n  return diffs;\n}\n\n/**\n * Generate SVG content for the memory card\n */\nasync function generateSVG(frame: Frame, options: Required<RenderOptions>): Promise<string> {\n  const { dimensions, colorScheme, fontConfig, rawContext } = options;\n  const dynamicHeight = calculateCardHeight(frame, dimensions);\n\n  let yOffset = dimensions.padding;\n  const lineHeight = dimensions.lineHeight;\n\n  const svgParts: string[] = [];\n\n  // SVG header\n  svgParts.push(\n    `<svg width=\"${dimensions.width}\" height=\"${dynamicHeight}\" xmlns=\"http://www.w3.org/2000/svg\">`\n  );\n\n  // Background\n  svgParts.push(`<rect width=\"100%\" height=\"100%\" fill=\"${colorScheme.background}\"/>`);\n\n  // Title\n  svgParts.push(\n    `<text x=\"${dimensions.padding}\" y=\"${yOffset}\" font-family=\"${fontConfig.family}\" font-size=\"${fontConfig.sizeTitle}\" fill=\"${colorScheme.heading}\" font-weight=\"bold\">Memory Card: ${escapeXml(frame.id.substring(0, 20))}</text>`\n  );\n  yOffset += lineHeight * 1.5;\n\n  // Timestamp and Branch\n  svgParts.push(\n    `<text x=\"${dimensions.padding}\" y=\"${yOffset}\" font-family=\"${fontConfig.family}\" font-size=\"${fontConfig.sizeSmall}\" fill=\"${colorScheme.muted}\">${escapeXml(new Date(frame.timestamp).toLocaleString())}</text>`\n  );\n  yOffset += lineHeight;\n\n  svgParts.push(\n    `<text x=\"${dimensions.padding}\" y=\"${yOffset}\" font-family=\"${fontConfig.family}\" font-size=\"${fontConfig.sizeBody}\" fill=\"${colorScheme.accent}\">Branch: ${escapeXml(frame.branch)}</text>`\n  );\n  yOffset += lineHeight * 1.5;\n\n  // Divider\n  svgParts.push(\n    `<line x1=\"${dimensions.padding}\" y1=\"${yOffset}\" x2=\"${dimensions.width - dimensions.padding}\" y2=\"${yOffset}\" stroke=\"${colorScheme.muted}\" stroke-width=\"1\"/>`\n  );\n  yOffset += lineHeight;\n\n  // Summary Caption\n  const summaryText = truncateText(frame.summary_caption, TEXT_LIMITS.summaryCaption);\n  svgParts.push(\n    `<text x=\"${dimensions.padding}\" y=\"${yOffset}\" font-family=\"${fontConfig.family}\" font-size=\"${fontConfig.sizeBody}\" fill=\"${colorScheme.text}\">${escapeXml(summaryText)}</text>`\n  );\n  yOffset += lineHeight * 1.5;\n\n  // Reference Point\n  svgParts.push(\n    `<text x=\"${dimensions.padding}\" y=\"${yOffset}\" font-family=\"${fontConfig.family}\" font-size=\"${fontConfig.sizeSmall}\" fill=\"${colorScheme.muted}\">Ref: ${escapeXml(truncateText(frame.reference_point, TEXT_LIMITS.referencePoint))}</text>`\n  );\n  yOffset += lineHeight * 1.5;\n\n  // Status Snapshot\n  svgParts.push(\n    `<text x=\"${dimensions.padding}\" y=\"${yOffset}\" font-family=\"${fontConfig.family}\" font-size=\"${fontConfig.sizeHeading}\" fill=\"${colorScheme.heading}\" font-weight=\"bold\">Status</text>`\n  );\n  yOffset += lineHeight;\n\n  const nextAction = truncateText(frame.status_snapshot.next_action, TEXT_LIMITS.nextAction);\n  svgParts.push(\n    `<text x=\"${dimensions.padding}\" y=\"${yOffset}\" font-family=\"${fontConfig.family}\" font-size=\"${fontConfig.sizeBody}\" fill=\"${colorScheme.text}\">Next: ${escapeXml(nextAction)}</text>`\n  );\n  yOffset += lineHeight * 1.5;\n\n  // Code Diffs (if present in raw context)\n  if (rawContext) {\n    const diffs = extractDiffs(rawContext);\n\n    if (diffs.length > 0) {\n      svgParts.push(\n        `<text x=\"${dimensions.padding}\" y=\"${yOffset}\" font-family=\"${fontConfig.family}\" font-size=\"${fontConfig.sizeHeading}\" fill=\"${colorScheme.heading}\" font-weight=\"bold\">Recent Changes</text>`\n      );\n      yOffset += lineHeight;\n\n      for (const { diff, language } of diffs.slice(0, 2)) {\n        // Limit to 2 diffs\n        // Apply smart truncation\n        const truncatedDiff = renderDiff(diff, { maxLines: 20, contextLines: 2 });\n        const stats = getDiffStats(diff);\n\n        // Show diff stats\n        svgParts.push(\n          `<text x=\"${dimensions.padding}\" y=\"${yOffset}\" font-family=\"${fontConfig.family}\" font-size=\"${fontConfig.sizeSmall}\" fill=\"${colorScheme.muted}\">+${stats.additions} -${stats.deletions}</text>`\n        );\n        yOffset += lineHeight;\n\n        // Render diff lines (simplified for SVG - no full syntax highlighting in SVG)\n        const diffLines = truncatedDiff.split(\"\\n\").slice(0, 15); // Limit lines\n        for (const line of diffLines) {\n          let color = colorScheme.text;\n          if (line.startsWith(\"+\")) {\n            color = colorScheme.diffAddition;\n          } else if (line.startsWith(\"-\")) {\n            color = colorScheme.diffDeletion;\n          } else if (line.includes(\"lines omitted\") || line.includes(\"more lines\")) {\n            color = colorScheme.diffContext;\n          }\n\n          svgParts.push(\n            `<text x=\"${dimensions.padding + 10}\" y=\"${yOffset}\" font-family=\"${fontConfig.family}\" font-size=\"${fontConfig.sizeSmall}\" fill=\"${color}\">${escapeXml(line.substring(0, 80))}</text>`\n          );\n          yOffset += lineHeight * 0.8;\n        }\n\n        yOffset += lineHeight * 0.5;\n      }\n    }\n  }\n\n  // Close SVG\n  svgParts.push(\"</svg>\");\n\n  return svgParts.join(\"\\n\");\n}\n\n/**\n * Escape XML special characters\n */\nfunction escapeXml(text: string): string {\n  return text\n    .replace(/&/g, \"&amp;\")\n    .replace(/</g, \"&lt;\")\n    .replace(/>/g, \"&gt;\")\n    .replace(/\"/g, \"&quot;\")\n    .replace(/'/g, \"&apos;\");\n}\n\n/**\n * Render memory card as PNG image\n */\nexport async function renderMemoryCard(frame: Frame, rawContext?: string): Promise<Buffer> {\n  return renderMemoryCardWithOptions(frame, { rawContext });\n}\n\n/**\n * Render memory card with custom options\n */\nexport async function renderMemoryCardWithOptions(\n  frame: Frame,\n  options: RenderOptions\n): Promise<Buffer> {\n  // Merge with defaults\n  const fullOptions: Required<RenderOptions> = {\n    dimensions: options.dimensions || DEFAULT_DIMENSIONS,\n    colorScheme: options.colorScheme || DARK_COLOR_SCHEME,\n    fontConfig: options.fontConfig || MONOSPACE_FONT,\n    rawContext: options.rawContext || \"\",\n  };\n\n  // Generate SVG\n  const svg = await generateSVG(frame, fullOptions);\n\n  // Convert SVG to PNG using Sharp\n  const buffer = await sharp(Buffer.from(svg)).png().toBuffer();\n\n  return buffer;\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/diff.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/example.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/graph-example.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/graph.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'MIN_DISTANCE_THRESHOLD' is assigned a value but never used. Allowed unused vars must match /^_/u.","line":102,"column":7,"nodeType":null,"messageId":"unusedVar","endLine":102,"endColumn":29}],"suppressedMessages":[{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":429,"column":9,"nodeType":"VariableDeclarator","messageId":"anyAssignment","endLine":429,"endColumn":53,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":429,"column":50,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":429,"endColumn":53,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[12635,12638],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[12635,12638],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}],"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":431,"column":9,"nodeType":"VariableDeclarator","messageId":"anyAssignment","endLine":431,"endColumn":51,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .default on an `any` value.","line":431,"column":29,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":431,"endColumn":36,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":435,"column":7,"nodeType":"VariableDeclarator","messageId":"anyAssignment","endLine":435,"endColumn":28,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":435,"column":15,"nodeType":"Identifier","messageId":"unsafeCall","endLine":435,"endColumn":20,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":439,"column":5,"nodeType":"AssignmentExpression","messageId":"anyAssignment","endLine":439,"endColumn":56,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":439,"column":13,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":439,"endColumn":25,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .resize on an `any` value.","line":439,"column":19,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":439,"endColumn":25,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-return","severity":1,"message":"Unsafe return of a value of type `any`.","line":443,"column":3,"nodeType":"ReturnStatement","messageId":"unsafeReturn","endLine":443,"endColumn":33,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":443,"column":10,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":443,"endColumn":30,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":443,"column":10,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":443,"endColumn":19,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .png on an `any` value.","line":443,"column":16,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":443,"endColumn":19,"suppressions":[{"kind":"directive","justification":""}]},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .toBuffer on an `any` value.","line":443,"column":22,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":443,"endColumn":30,"suppressions":[{"kind":"directive","justification":""}]}],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Graph rendering for Atlas Frames\n * Generates SVG visualizations showing module nodes, dependency edges,\n * and visual indicators for allowed vs forbidden connections.\n */\n\n// Use inline types to avoid cross-package type dependencies that violate rootDir\nexport interface AtlasModule {\n  id: string;\n  coords?: [number, number];\n  owns_paths?: string[];\n  owns_namespaces?: string[];\n  allowed_callers?: string[];\n  forbidden_callers?: string[];\n  feature_flags?: string[];\n  requires_permissions?: string[];\n  kill_patterns?: string[];\n  notes?: string;\n}\n\nexport interface AtlasEdge {\n  from: string;\n  to: string;\n  allowed: boolean;\n  reason?: string;\n}\n\nexport interface AtlasFrame {\n  atlas_timestamp: string;\n  seed_modules: string[];\n  fold_radius: number;\n  modules: AtlasModule[];\n  edges: AtlasEdge[];\n  critical_rule: string;\n}\n\nimport {\n  forceDirectedLayout,\n  hierarchicalLayout,\n  type Layout,\n  type LayoutConfig,\n} from \"./layouts.js\";\n\nexport interface GraphRenderOptions {\n  width?: number;\n  height?: number;\n  layout?: \"force-directed\" | \"hierarchical\";\n  layoutConfig?: LayoutConfig;\n  showTooltips?: boolean;\n  nodeColors?: Record<string, string>;\n}\n\nexport interface GraphNode {\n  id: string;\n  x: number;\n  y: number;\n  radius: number;\n  isSeed: boolean;\n  module: AtlasModule;\n}\n\nexport interface GraphEdgeRenderable {\n  from: GraphNode;\n  to: GraphNode;\n  allowed: boolean;\n  reason?: string;\n}\n\nconst DEFAULT_OPTIONS: Required<GraphRenderOptions> = {\n  width: 800,\n  height: 600,\n  layout: \"force-directed\",\n  layoutConfig: {},\n  showTooltips: true,\n  nodeColors: {},\n};\n\n// Module type detection based on ID patterns\nfunction detectModuleType(moduleId: string): string {\n  const lower = moduleId.toLowerCase();\n  if (lower.includes(\"ui/\") || lower.includes(\"component\")) return \"component\";\n  if (lower.includes(\"api/\") || lower.includes(\"service\")) return \"service\";\n  if (lower.includes(\"util\") || lower.includes(\"helper\")) return \"util\";\n  if (lower.includes(\"backend\") || lower.includes(\"core\")) return \"core\";\n  if (lower.includes(\"database\") || lower.includes(\"db\")) return \"database\";\n  return \"default\";\n}\n\n// Color mapping for different module types\nconst MODULE_TYPE_COLORS: Record<string, string> = {\n  component: \"#4CAF50\",\n  service: \"#2196F3\",\n  util: \"#FF9800\",\n  core: \"#9C27B0\",\n  database: \"#795548\",\n  default: \"#607D8B\",\n};\n\n// Constants for rendering\nconst MAX_LABEL_LENGTH = 20;\nconst LABEL_TRUNCATE_AT = 17;\nconst MIN_DISTANCE_THRESHOLD = 0.1;\nconst WARNING_ICON = \"\\u26A0\\uFE0F\"; // âš ï¸ as Unicode\n\n/**\n * Calculate node size based on number of dependencies\n */\nfunction calculateNodeRadius(module: AtlasModule, edges: AtlasEdge[]): number {\n  const minRadius = 20;\n  const maxRadius = 50;\n  const baseRadius = 30;\n\n  // Count incoming and outgoing edges\n  const edgeCount = edges.filter((e) => e.from === module.id || e.to === module.id).length;\n\n  // Scale radius based on edge count (logarithmic scaling)\n  const scaledRadius = baseRadius + Math.log(edgeCount + 1) * 5;\n  return Math.min(maxRadius, Math.max(minRadius, scaledRadius));\n}\n\n/**\n * Render Atlas Frame as SVG graph\n */\nexport function renderAtlasFrameGraph(\n  atlasFrame: AtlasFrame,\n  options: GraphRenderOptions = {}\n): string {\n  const opts = { ...DEFAULT_OPTIONS, ...options };\n\n  // Create graph nodes\n  const nodes: GraphNode[] = atlasFrame.modules.map((module) => {\n    const radius = calculateNodeRadius(module, atlasFrame.edges);\n    const isSeed = atlasFrame.seed_modules.includes(module.id);\n\n    return {\n      id: module.id,\n      x: module.coords?.[0] ?? 0,\n      y: module.coords?.[1] ?? 0,\n      radius,\n      isSeed,\n      module,\n    };\n  });\n\n  // Apply layout algorithm\n  const layout: Layout =\n    opts.layout === \"hierarchical\"\n      ? hierarchicalLayout(nodes, atlasFrame.edges, opts.layoutConfig)\n      : forceDirectedLayout(nodes, atlasFrame.edges, opts.layoutConfig);\n\n  // Scale to fit canvas\n  scaleToFit(layout.nodes, opts.width, opts.height);\n\n  // Build edges with positioned nodes\n  const nodeMap = new Map(layout.nodes.map((n) => [n.id, n]));\n  const edges: GraphEdgeRenderable[] = [];\n  for (const edge of atlasFrame.edges) {\n    const from = nodeMap.get(edge.from);\n    const to = nodeMap.get(edge.to);\n    if (from && to) {\n      edges.push({ from, to, allowed: edge.allowed, reason: edge.reason });\n    }\n  }\n\n  // Generate SVG\n  return generateSVG(layout.nodes, edges, opts);\n}\n\n/**\n * Scale nodes to fit within canvas bounds\n */\nfunction scaleToFit(nodes: GraphNode[], width: number, height: number): void {\n  if (nodes.length === 0) return;\n\n  const padding = 60;\n  const availableWidth = width - 2 * padding;\n  const availableHeight = height - 2 * padding;\n\n  // Find current bounds\n  let minX = Infinity,\n    maxX = -Infinity;\n  let minY = Infinity,\n    maxY = -Infinity;\n\n  for (const node of nodes) {\n    minX = Math.min(minX, node.x - node.radius);\n    maxX = Math.max(maxX, node.x + node.radius);\n    minY = Math.min(minY, node.y - node.radius);\n    maxY = Math.max(maxY, node.y + node.radius);\n  }\n\n  const currentWidth = maxX - minX;\n  const currentHeight = maxY - minY;\n\n  // Calculate scale factor\n  const scaleX = currentWidth > 0 ? availableWidth / currentWidth : 1;\n  const scaleY = currentHeight > 0 ? availableHeight / currentHeight : 1;\n  const scale = Math.min(scaleX, scaleY, 1); // Don't scale up, only down\n\n  // Apply scaling and centering\n  for (const node of nodes) {\n    node.x = (node.x - minX) * scale + padding;\n    node.y = (node.y - minY) * scale + padding;\n  }\n}\n\n/**\n * Generate SVG markup\n */\nfunction generateSVG(\n  nodes: GraphNode[],\n  edges: GraphEdgeRenderable[],\n  options: Required<GraphRenderOptions>\n): string {\n  const { width, height, showTooltips, nodeColors } = options;\n\n  let svg = `<svg width=\"${width}\" height=\"${height}\" xmlns=\"http://www.w3.org/2000/svg\">`;\n\n  // Add styles\n  svg += `\n  <defs>\n    <style>\n      .node { cursor: pointer; }\n      .node:hover { opacity: 0.8; }\n      .edge-allowed { stroke: #4CAF50; fill: none; }\n      .edge-forbidden { stroke: #F44336; fill: none; stroke-dasharray: 5,5; }\n      .node-label {\n        font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif;\n        font-size: 12px;\n        fill: #333;\n        text-anchor: middle;\n        pointer-events: none;\n      }\n      .tooltip {\n        font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif;\n        font-size: 11px;\n        fill: white;\n        pointer-events: none;\n      }\n      .tooltip-bg {\n        fill: rgba(0, 0, 0, 0.8);\n        rx: 4;\n      }\n    </style>\n\n    <!-- Arrow markers for edges -->\n    <marker id=\"arrow-allowed\" markerWidth=\"10\" markerHeight=\"10\" refX=\"9\" refY=\"3\" orient=\"auto\" markerUnits=\"strokeWidth\">\n      <path d=\"M0,0 L0,6 L9,3 z\" fill=\"#4CAF50\" />\n    </marker>\n    <marker id=\"arrow-forbidden\" markerWidth=\"10\" markerHeight=\"10\" refX=\"9\" refY=\"3\" orient=\"auto\" markerUnits=\"strokeWidth\">\n      <path d=\"M0,0 L0,6 L9,3 z\" fill=\"#F44336\" />\n    </marker>\n  </defs>\n  `;\n\n  // Add background\n  svg += `<rect width=\"${width}\" height=\"${height}\" fill=\"#f5f5f5\"/>`;\n\n  // Render edges first (so they appear below nodes)\n  svg += '<g id=\"edges\">';\n  for (const edge of edges) {\n    svg += renderEdge(edge);\n  }\n  svg += \"</g>\";\n\n  // Render nodes\n  svg += '<g id=\"nodes\">';\n  for (const node of nodes) {\n    const color = nodeColors[node.id] || MODULE_TYPE_COLORS[detectModuleType(node.id)];\n    svg += renderNode(node, color, showTooltips);\n  }\n  svg += \"</g>\";\n\n  svg += \"</svg>\";\n  return svg;\n}\n\n/**\n * Render a single edge\n */\nfunction renderEdge(edge: GraphEdgeRenderable): string {\n  const { from, to, allowed } = edge;\n\n  // Calculate edge endpoints at circle boundaries\n  const dx = to.x - from.x;\n  const dy = to.y - from.y;\n  const distance = Math.sqrt(dx * dx + dy * dy);\n\n  if (distance === 0) return \"\";\n\n  // Offset from and to points by node radius\n  const offsetX = dx / distance;\n  const offsetY = dy / distance;\n\n  const x1 = from.x + offsetX * from.radius;\n  const y1 = from.y + offsetY * from.radius;\n  const x2 = to.x - offsetX * to.radius;\n  const y2 = to.y - offsetY * to.radius;\n\n  const className = allowed ? \"edge-allowed\" : \"edge-forbidden\";\n  const marker = allowed ? \"url(#arrow-allowed)\" : \"url(#arrow-forbidden)\";\n  const strokeWidth = 2;\n\n  let svg = `<line x1=\"${x1}\" y1=\"${y1}\" x2=\"${x2}\" y2=\"${y2}\" `;\n  svg += `class=\"${className}\" stroke-width=\"${strokeWidth}\" marker-end=\"${marker}\">`;\n\n  // Add title for tooltip\n  if (edge.reason) {\n    svg += `<title>${from.id} â†’ ${to.id} (${edge.reason})</title>`;\n  } else {\n    svg += `<title>${from.id} â†’ ${to.id}</title>`;\n  }\n\n  svg += \"</line>\";\n\n  // Add warning icon for forbidden edges\n  if (!allowed) {\n    const midX = (x1 + x2) / 2;\n    const midY = (y1 + y2) / 2;\n    svg += `<text x=\"${midX}\" y=\"${midY}\" font-size=\"14\" fill=\"#F44336\" text-anchor=\"middle\">${WARNING_ICON}</text>`;\n  }\n\n  return svg;\n}\n\n/**\n * Render a single node\n */\nfunction renderNode(node: GraphNode, color: string, showTooltips: boolean): string {\n  const { x, y, radius, isSeed, module } = node;\n\n  // Seed modules have bold border\n  const strokeWidth = isSeed ? 3 : 1;\n  const stroke = isSeed ? \"#000\" : \"#666\";\n\n  let svg = `<g class=\"node\">`;\n\n  // Circle\n  svg += `<circle cx=\"${x}\" cy=\"${y}\" r=\"${radius}\" fill=\"${color}\" stroke=\"${stroke}\" stroke-width=\"${strokeWidth}\">`;\n  svg += `<title>${module.id}</title>`;\n  svg += \"</circle>\";\n\n  // Label (truncate if too long)\n  const label =\n    module.id.length > MAX_LABEL_LENGTH\n      ? module.id.substring(0, LABEL_TRUNCATE_AT) + \"...\"\n      : module.id;\n  svg += `<text x=\"${x}\" y=\"${y + radius + 15}\" class=\"node-label\">${escapeXml(label)}</text>`;\n\n  // Tooltip (if enabled)\n  if (showTooltips) {\n    svg += renderTooltip(node);\n  }\n\n  svg += \"</g>\";\n  return svg;\n}\n\n/**\n * Render tooltip content for a node\n * Note: This creates a hidden tooltip that would be shown on hover with JavaScript\n */\nfunction renderTooltip(node: GraphNode): string {\n  const { module } = node;\n\n  let tooltip = \"\";\n  tooltip += `\\n<!-- Tooltip for ${module.id} -->`;\n  tooltip += `\\n<!-- ID: ${module.id} -->`;\n\n  if (module.owns_paths && module.owns_paths.length > 0) {\n    tooltip += `\\n<!-- Paths: ${module.owns_paths.join(\", \")} -->`;\n  }\n\n  if (module.feature_flags && module.feature_flags.length > 0) {\n    tooltip += `\\n<!-- Flags: ${module.feature_flags.join(\", \")} -->`;\n  }\n\n  if (module.requires_permissions && module.requires_permissions.length > 0) {\n    tooltip += `\\n<!-- Permissions: ${module.requires_permissions.join(\", \")} -->`;\n  }\n\n  return tooltip;\n}\n\n/**\n * Escape XML special characters\n */\nfunction escapeXml(text: string): string {\n  return text\n    .replace(/&/g, \"&amp;\")\n    .replace(/</g, \"&lt;\")\n    .replace(/>/g, \"&gt;\")\n    .replace(/\"/g, \"&quot;\")\n    .replace(/'/g, \"&apos;\");\n}\n\n/**\n * Export graph as PNG using sharp\n * Converts SVG to PNG for embedding in memory cards\n */\nexport async function exportGraphAsPNG(\n  svgContent: string,\n  options: { width?: number; height?: number } = {}\n): Promise<Buffer> {\n  // Import sharp dynamically to avoid issues if not installed\n\n  // CRITICAL: DO NOT REMOVE THESE ESLINT-DISABLES WITHOUT EXPLICIT APPROVAL\n  // The 'sharp' library uses a complex CommonJS/ESM hybrid export system that TypeScript\n  // cannot properly type when using dynamic imports. We MUST use 'any' here because:\n  //\n  // 1. Dynamic imports of CommonJS modules don't have proper type information at runtime\n  // 2. Sharp's types assume static imports, but we use dynamic imports for optional deps\n  // 3. The .default fallback pattern is required for ESM/CJS interop but isn't typed\n  // 4. Attempting to type this correctly would require:\n  //    - Runtime type introspection (defeats TypeScript's purpose)\n  //    - Assuming import patterns that may break across Node versions\n  //    - Complex conditional types that are harder to maintain than this pragma\n  //\n  // This pattern is documented in the sharp library itself for optional installations.\n  // See: https://sharp.pixelplumbing.com/install#cross-platform\n  //\n  // If you believe you can fix this, you must:\n  // 1. Ensure it works with both ESM and CommonJS Node.js configurations\n  // 2. Test with sharp installed AND uninstalled (should gracefully fail)\n  // 3. Verify across Node.js versions 18, 20, and 22\n  // 4. Document the fix in the PR description with test evidence\n  //\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/no-unsafe-assignment\n  const sharpModule = (await import(\"sharp\")) as any;\n  // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment, @typescript-eslint/no-unsafe-member-access\n  const sharp = sharpModule.default || sharpModule;\n\n  const buffer = Buffer.from(svgContent);\n  // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment, @typescript-eslint/no-unsafe-call\n  let image = sharp(buffer);\n\n  if (options.width || options.height) {\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment, @typescript-eslint/no-unsafe-member-access, @typescript-eslint/no-unsafe-call\n    image = image.resize(options.width, options.height);\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unsafe-return, @typescript-eslint/no-unsafe-member-access, @typescript-eslint/no-unsafe-call\n  return image.png().toBuffer();\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/integration-demo.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/layouts.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'layer' is assigned a value but never used. Allowed unused vars must match /^_/u.","line":268,"column":15,"nodeType":null,"messageId":"unusedVar","endLine":268,"endColumn":20},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'config' is assigned a value but never used. Allowed unused args must match /^_/u.","line":296,"column":3,"nodeType":null,"messageId":"unusedVar","endLine":296,"endColumn":9}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Layout algorithms for graph visualization\n * Provides force-directed and hierarchical layout options\n */\n\nimport type { GraphNode } from \"./graph.js\";\n\n// Use inline type to avoid cross-package dependencies\nexport interface AtlasEdge {\n  from: string;\n  to: string;\n  allowed: boolean;\n  reason?: string;\n}\n\nexport interface LayoutConfig {\n  iterations?: number;\n  repulsion?: number;\n  attraction?: number;\n  damping?: number;\n  levelSpacing?: number;\n  nodeSpacing?: number;\n}\n\nexport interface Layout {\n  nodes: GraphNode[];\n  width: number;\n  height: number;\n}\n\nconst DEFAULT_FORCE_CONFIG: Required<LayoutConfig> = {\n  iterations: 100,\n  repulsion: 2000,\n  attraction: 0.02,\n  damping: 0.85,\n  levelSpacing: 150,\n  nodeSpacing: 100,\n};\n\n// Constants for layout calculations\nconst MIN_DISTANCE_THRESHOLD = 0.1;\n\n/**\n * Force-directed graph layout (Fruchterman-Reingold algorithm)\n * Creates organic-looking layouts where connected nodes attract and all nodes repel\n */\nexport function forceDirectedLayout(\n  nodes: GraphNode[],\n  edges: AtlasEdge[],\n  config: LayoutConfig = {}\n): Layout {\n  const cfg = { ...DEFAULT_FORCE_CONFIG, ...config };\n\n  if (nodes.length === 0) {\n    return { nodes: [], width: 800, height: 600 };\n  }\n\n  // Create a mutable copy of nodes with positions\n  const layoutNodes = nodes.map((n) => ({ ...n }));\n\n  // Initialize velocities\n  const velocities = new Map<string, { vx: number; vy: number }>();\n  layoutNodes.forEach((node) => {\n    velocities.set(node.id, { vx: 0, vy: 0 });\n  });\n\n  // Build adjacency for quick edge lookups\n  const adjacency = new Map<string, Set<string>>();\n  for (const edge of edges) {\n    if (!adjacency.has(edge.from)) adjacency.set(edge.from, new Set());\n    if (!adjacency.has(edge.to)) adjacency.set(edge.to, new Set());\n    adjacency.get(edge.from)!.add(edge.to);\n    // For undirected behavior, also add reverse\n    adjacency.get(edge.to)!.add(edge.from);\n  }\n\n  const width = 1000;\n  const height = 1000;\n  const minDistance = 10;\n\n  // Run iterations\n  for (let iter = 0; iter < cfg.iterations; iter++) {\n    const forces = new Map<string, { fx: number; fy: number }>();\n\n    // Initialize forces\n    for (const node of layoutNodes) {\n      forces.set(node.id, { fx: 0, fy: 0 });\n    }\n\n    // Repulsive forces (all pairs)\n    for (let i = 0; i < layoutNodes.length; i++) {\n      for (let j = i + 1; j < layoutNodes.length; j++) {\n        const n1 = layoutNodes[i];\n        const n2 = layoutNodes[j];\n\n        const dx = n2.x - n1.x;\n        const dy = n2.y - n1.y;\n        const distSq = dx * dx + dy * dy;\n        const dist = Math.sqrt(distSq);\n\n        if (dist < MIN_DISTANCE_THRESHOLD) continue;\n\n        // Coulomb's law: F = k / r^2\n        const force = cfg.repulsion / distSq;\n        const fx = (dx / dist) * force;\n        const fy = (dy / dist) * force;\n\n        const f1 = forces.get(n1.id)!;\n        const f2 = forces.get(n2.id)!;\n        f1.fx -= fx;\n        f1.fy -= fy;\n        f2.fx += fx;\n        f2.fy += fy;\n      }\n    }\n\n    // Attractive forces (connected nodes)\n    for (const edge of edges) {\n      // Only use allowed edges for attraction\n      if (!edge.allowed) continue;\n\n      const n1 = layoutNodes.find((n) => n.id === edge.from);\n      const n2 = layoutNodes.find((n) => n.id === edge.to);\n\n      if (!n1 || !n2) continue;\n\n      const dx = n2.x - n1.x;\n      const dy = n2.y - n1.y;\n      const dist = Math.sqrt(dx * dx + dy * dy);\n\n      if (dist < MIN_DISTANCE_THRESHOLD) continue;\n\n      // Hooke's law: F = k * d\n      const force = dist * cfg.attraction;\n      const fx = (dx / dist) * force;\n      const fy = (dy / dist) * force;\n\n      const f1 = forces.get(n1.id)!;\n      const f2 = forces.get(n2.id)!;\n      f1.fx += fx;\n      f1.fy += fy;\n      f2.fx -= fx;\n      f2.fy -= fy;\n    }\n\n    // Update positions\n    for (const node of layoutNodes) {\n      const vel = velocities.get(node.id)!;\n      const force = forces.get(node.id)!;\n\n      // Update velocity with damping\n      vel.vx = (vel.vx + force.fx) * cfg.damping;\n      vel.vy = (vel.vy + force.fy) * cfg.damping;\n\n      // Update position\n      node.x += vel.vx;\n      node.y += vel.vy;\n\n      // Keep within bounds\n      node.x = Math.max(minDistance, Math.min(width - minDistance, node.x));\n      node.y = Math.max(minDistance, Math.min(height - minDistance, node.y));\n    }\n  }\n\n  return { nodes: layoutNodes, width, height };\n}\n\n/**\n * Hierarchical graph layout (top-down tree)\n * Organizes nodes in layers based on dependency structure\n */\nexport function hierarchicalLayout(\n  nodes: GraphNode[],\n  edges: AtlasEdge[],\n  config: LayoutConfig = {}\n): Layout {\n  const cfg = { ...DEFAULT_FORCE_CONFIG, ...config };\n\n  if (nodes.length === 0) {\n    return { nodes: [], width: 800, height: 600 };\n  }\n\n  // Create a mutable copy of nodes\n  const layoutNodes = nodes.map((n) => ({ ...n }));\n\n  // Build adjacency lists (directed)\n  const outgoing = new Map<string, Set<string>>();\n  const incoming = new Map<string, Set<string>>();\n\n  for (const node of layoutNodes) {\n    outgoing.set(node.id, new Set());\n    incoming.set(node.id, new Set());\n  }\n\n  for (const edge of edges) {\n    if (!edge.allowed) continue; // Only use allowed edges for hierarchy\n\n    const out = outgoing.get(edge.from);\n    const inc = incoming.get(edge.to);\n\n    if (out) out.add(edge.to);\n    if (inc) inc.add(edge.from);\n  }\n\n  // Assign layers using topological sort (BFS from roots)\n  const layers = new Map<string, number>();\n  const queue: string[] = [];\n\n  // Start with nodes that have no incoming edges (roots)\n  for (const node of layoutNodes) {\n    if (incoming.get(node.id)!.size === 0) {\n      layers.set(node.id, 0);\n      queue.push(node.id);\n    }\n  }\n\n  // If no roots found, start with seed nodes\n  if (queue.length === 0) {\n    for (const node of layoutNodes) {\n      if (node.isSeed) {\n        layers.set(node.id, 0);\n        queue.push(node.id);\n      }\n    }\n  }\n\n  // BFS to assign layers\n  while (queue.length > 0) {\n    const nodeId = queue.shift()!;\n    const currentLayer = layers.get(nodeId)!;\n\n    const neighbors = outgoing.get(nodeId);\n    if (!neighbors) continue;\n\n    for (const neighborId of neighbors) {\n      const existingLayer = layers.get(neighborId);\n      const newLayer = currentLayer + 1;\n\n      if (existingLayer === undefined || newLayer > existingLayer) {\n        layers.set(neighborId, newLayer);\n        queue.push(neighborId);\n      }\n    }\n  }\n\n  // Assign remaining nodes to a default layer\n  for (const node of layoutNodes) {\n    if (!layers.has(node.id)) {\n      layers.set(node.id, 0);\n    }\n  }\n\n  // Group nodes by layer\n  const layerGroups = new Map<number, GraphNode[]>();\n  for (const node of layoutNodes) {\n    const layer = layers.get(node.id)!;\n    if (!layerGroups.has(layer)) {\n      layerGroups.set(layer, []);\n    }\n    layerGroups.get(layer)!.push(node);\n  }\n\n  // Calculate positions\n  const maxLayer = Math.max(...Array.from(layers.values()), 0);\n  const height = (maxLayer + 1) * cfg.levelSpacing + 100;\n\n  let maxWidth = 0;\n  for (const [layer, layerNodes] of layerGroups.entries()) {\n    const layerWidth = layerNodes.length * cfg.nodeSpacing;\n    maxWidth = Math.max(maxWidth, layerWidth);\n  }\n  const width = maxWidth + 100;\n\n  // Position nodes\n  for (const [layer, layerNodes] of layerGroups.entries()) {\n    const y = 50 + layer * cfg.levelSpacing;\n    const layerWidth = layerNodes.length * cfg.nodeSpacing;\n    const startX = (width - layerWidth) / 2;\n\n    layerNodes.forEach((node, index) => {\n      node.x = startX + index * cfg.nodeSpacing + cfg.nodeSpacing / 2;\n      node.y = y;\n    });\n  }\n\n  return { nodes: layoutNodes, width, height };\n}\n\n/**\n * Circular layout (nodes arranged in a circle)\n * Simple fallback layout for small graphs\n */\nexport function circularLayout(\n  nodes: GraphNode[],\n  edges: AtlasEdge[],\n  config: LayoutConfig = {}\n): Layout {\n  if (nodes.length === 0) {\n    return { nodes: [], width: 800, height: 600 };\n  }\n\n  const layoutNodes = nodes.map((n) => ({ ...n }));\n  const width = 800;\n  const height = 600;\n  const centerX = width / 2;\n  const centerY = height / 2;\n  const radius = Math.min(width, height) / 2 - 100;\n\n  const angleStep = (2 * Math.PI) / layoutNodes.length;\n\n  layoutNodes.forEach((node, index) => {\n    const angle = index * angleStep;\n    node.x = centerX + radius * Math.cos(angle);\n    node.y = centerY + radius * Math.sin(angle);\n  });\n\n  return { nodes: layoutNodes, width, height };\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/syntax.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'createHighlighter' is defined but never used. Allowed unused vars must match /^_/u.","line":2,"column":22,"nodeType":null,"messageId":"unusedVar","endLine":2,"endColumn":39},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":190,"column":51,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":190,"endColumn":54,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4914,4917],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4914,4917],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { getLogger } from \"lex/logger\";\nimport { codeToHtml, createHighlighter } from \"shiki\";\nimport type { BundledLanguage } from \"shiki\";\n\nconst logger = getLogger(\"memory:renderer:syntax\");\n\n// Common languages supported\nexport const SUPPORTED_LANGUAGES = [\n  \"typescript\",\n  \"javascript\",\n  \"python\",\n  \"php\",\n  \"java\",\n  \"go\",\n  \"rust\",\n  \"cpp\",\n  \"c\",\n  \"csharp\",\n  \"ruby\",\n  \"swift\",\n  \"kotlin\",\n  \"sql\",\n  \"html\",\n  \"css\",\n  \"json\",\n  \"yaml\",\n  \"markdown\",\n  \"bash\",\n  \"shell\",\n] as const;\n\nexport type SupportedLanguage = (typeof SUPPORTED_LANGUAGES)[number];\n\n// Language detection from file extension or content\nconst LANGUAGE_EXTENSIONS: Record<string, BundledLanguage> = {\n  ts: \"typescript\",\n  tsx: \"typescript\",\n  js: \"javascript\",\n  jsx: \"javascript\",\n  py: \"python\",\n  php: \"php\",\n  java: \"java\",\n  go: \"go\",\n  rs: \"rust\",\n  cpp: \"cpp\",\n  cc: \"cpp\",\n  c: \"c\",\n  cs: \"csharp\",\n  rb: \"ruby\",\n  swift: \"swift\",\n  kt: \"kotlin\",\n  sql: \"sql\",\n  html: \"html\",\n  css: \"css\",\n  json: \"json\",\n  yml: \"yaml\",\n  yaml: \"yaml\",\n  md: \"markdown\",\n  sh: \"bash\",\n  bash: \"bash\",\n};\n\n/**\n * Detect language from file extension\n */\nexport function detectLanguageFromExtension(filename: string): BundledLanguage {\n  const ext = filename.split(\".\").pop()?.toLowerCase();\n  return ext && ext in LANGUAGE_EXTENSIONS ? LANGUAGE_EXTENSIONS[ext] : \"typescript\"; // Default to TypeScript\n}\n\n/**\n * Highlight code with syntax highlighting\n *\n * @param code - Code to highlight\n * @param language - Programming language\n * @param theme - Color theme (default: 'dark-plus' to match VS Code)\n * @returns HTML string with syntax highlighting\n */\nexport async function highlightCode(\n  code: string,\n  language: BundledLanguage = \"typescript\",\n  theme: \"dark-plus\" | \"light-plus\" = \"dark-plus\"\n): Promise<string> {\n  try {\n    const html = await codeToHtml(code, {\n      lang: language,\n      theme: theme,\n    });\n    return html;\n  } catch (error) {\n    // Fallback to plain text if highlighting fails\n    logger.error({ err: error, language }, \"Syntax highlighting failed\");\n    return `<pre><code>${escapeHtml(code)}</code></pre>`;\n  }\n}\n\n/**\n * Highlight a diff with syntax highlighting\n * Preserves +/- indicators while applying syntax highlighting\n *\n * @param diff - Unified diff string\n * @param language - Programming language\n * @param theme - Color theme\n * @returns HTML string with syntax highlighted diff\n */\nexport async function highlightDiff(\n  diff: string,\n  language: BundledLanguage = \"typescript\",\n  theme: \"dark-plus\" | \"light-plus\" = \"dark-plus\"\n): Promise<string> {\n  try {\n    const lines = diff.split(\"\\n\");\n    const processedLines: string[] = [];\n\n    for (const line of lines) {\n      if (!line) {\n        processedLines.push(\"\");\n        continue;\n      }\n\n      const firstChar = line[0];\n      const isAddition = firstChar === \"+\";\n      const isDeletion = firstChar === \"-\";\n      const isUnchanged = firstChar === \" \";\n\n      if (isAddition || isDeletion || isUnchanged) {\n        // Extract the code without the diff marker\n        const code = line.substring(1);\n\n        // Highlight the code\n        const highlighted = await codeToHtml(code, {\n          lang: language,\n          theme: theme,\n        });\n\n        // Extract just the highlighted content (remove outer pre/code tags)\n        const match = highlighted.match(/<code[^>]*>(.*?)<\\/code>/s);\n        const highlightedContent = match ? match[1] : escapeHtml(code);\n\n        // Wrap in appropriate styling based on diff type\n        let className = \"\";\n        let prefix = \"\";\n\n        if (isAddition) {\n          className = \"diff-addition\";\n          prefix = \"+\";\n        } else if (isDeletion) {\n          className = \"diff-deletion\";\n          prefix = \"-\";\n        } else {\n          className = \"diff-unchanged\";\n          prefix = \" \";\n        }\n\n        processedLines.push(\n          `<div class=\"${className}\"><span class=\"diff-marker\">${prefix}</span>${highlightedContent}</div>`\n        );\n      } else {\n        // Context line (file headers, line numbers, etc.)\n        processedLines.push(`<div class=\"diff-context\">${escapeHtml(line)}</div>`);\n      }\n    }\n\n    return `<div class=\"diff-container\">${processedLines.join(\"\\n\")}</div>`;\n  } catch (error) {\n    logger.error({ err: error }, \"Diff highlighting failed\");\n    // Fallback to plain diff\n    return `<pre class=\"diff-fallback\"><code>${escapeHtml(diff)}</code></pre>`;\n  }\n}\n\n/**\n * Escape HTML special characters\n */\nfunction escapeHtml(text: string): string {\n  const htmlEscapes: Record<string, string> = {\n    \"&\": \"&amp;\",\n    \"<\": \"&lt;\",\n    \">\": \"&gt;\",\n    '\"': \"&quot;\",\n    \"'\": \"&#39;\",\n  };\n  return text.replace(/[&<>\"']/g, (char) => htmlEscapes[char]);\n}\n\n/**\n * Check if a language is supported\n */\nexport function isLanguageSupported(language: string): language is BundledLanguage {\n  return SUPPORTED_LANGUAGES.includes(language as any);\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/templates.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":129,"column":44,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":129,"endColumn":47,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2719,2722],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2719,2722],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .summary_caption on an `any` value.","line":137,"column":24,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":137,"endColumn":39},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .status_snapshot on an `any` value.","line":147,"column":24,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":147,"endColumn":39},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .status_snapshot on an `any` value.","line":152,"column":13,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":152,"endColumn":28},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .status_snapshot on an `any` value.","line":154,"column":41,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":154,"endColumn":56},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .status_snapshot on an `any` value.","line":159,"column":13,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":159,"endColumn":28},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .status_snapshot on an `any` value.","line":162,"column":13,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":162,"endColumn":28},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .status_snapshot on an `any` value.","line":169,"column":13,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":169,"endColumn":28},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .status_snapshot on an `any` value.","line":171,"column":38,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":171,"endColumn":53},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .keywords on an `any` value.","line":179,"column":13,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":179,"endColumn":21},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .jira on an `any` value.","line":184,"column":13,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":184,"endColumn":17},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .atlas_frame_id on an `any` value.","line":185,"column":13,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":185,"endColumn":27}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":12,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Layout templates and styling for memory card rendering\n * Optimized for LLM vision input with high-contrast, readable design\n */\n\nexport interface CardDimensions {\n  width: number;\n  height: number;\n  padding: number;\n  lineHeight: number;\n}\n\nexport interface ColorScheme {\n  background: string;\n  text: string;\n  heading: string;\n  accent: string;\n  muted: string;\n  warning: string;\n  error: string;\n  diffAddition: string;\n  diffDeletion: string;\n  diffUnchanged: string;\n  diffContext: string;\n}\n\nexport interface FontConfig {\n  family: string;\n  sizeTitle: number;\n  sizeHeading: number;\n  sizeBody: number;\n  sizeSmall: number;\n}\n\n/**\n * Default card dimensions optimized for vision models\n * Based on research: ~800px wide for good token compression\n */\nexport const DEFAULT_DIMENSIONS: CardDimensions = {\n  width: 800,\n  height: 1000,\n  padding: 40,\n  lineHeight: 24,\n};\n\n/**\n * High-contrast dark theme color scheme\n * Optimized for readability in vision models\n */\nexport const DARK_COLOR_SCHEME: ColorScheme = {\n  background: \"#1a1a1a\",\n  text: \"#e0e0e0\",\n  heading: \"#ffffff\",\n  accent: \"#4a9eff\",\n  muted: \"#888888\",\n  warning: \"#ffaa00\",\n  error: \"#ff4444\",\n  diffAddition: \"#22863a\",\n  diffDeletion: \"#b31d28\",\n  diffUnchanged: \"#6a737d\",\n  diffContext: \"#586069\",\n};\n\n/**\n * Monospace font configuration for technical content\n */\nexport const MONOSPACE_FONT: FontConfig = {\n  family: \"monospace\",\n  sizeTitle: 28,\n  sizeHeading: 20,\n  sizeBody: 16,\n  sizeSmall: 14,\n};\n\n/**\n * Maximum text lengths to prevent overflow\n */\nexport const TEXT_LIMITS = {\n  summaryCaption: 120,\n  referencePoint: 80,\n  nextAction: 200,\n  blockerItem: 100,\n  maxBlockers: 5,\n  maxKeywords: 8,\n};\n\n/**\n * Truncate text with ellipsis if it exceeds max length\n */\nexport function truncateText(text: string, maxLength: number): string {\n  if (text.length <= maxLength) {\n    return text;\n  }\n  return text.substring(0, maxLength - 3) + \"...\";\n}\n\n/**\n * Wrap text to fit within a given width\n * Returns array of lines\n */\nexport function wrapText(text: string, maxWidth: number, charWidth: number): string[] {\n  const maxCharsPerLine = Math.floor(maxWidth / charWidth);\n  const words = text.split(\" \");\n  const lines: string[] = [];\n  let currentLine = \"\";\n\n  for (const word of words) {\n    const testLine = currentLine ? `${currentLine} ${word}` : word;\n    if (testLine.length <= maxCharsPerLine) {\n      currentLine = testLine;\n    } else {\n      if (currentLine) {\n        lines.push(currentLine);\n      }\n      currentLine = word;\n    }\n  }\n\n  if (currentLine) {\n    lines.push(currentLine);\n  }\n\n  return lines;\n}\n\n/**\n * Calculate dynamic card height based on content\n */\nexport function calculateCardHeight(frame: any, dimensions: CardDimensions): number {\n  let lines = 0;\n\n  // Title + timestamp + branch + divider\n  lines += 5;\n\n  // Summary caption (wrapped)\n  const summaryLines = Math.ceil(\n    truncateText(frame.summary_caption, TEXT_LIMITS.summaryCaption).length / 60\n  );\n  lines += summaryLines + 1;\n\n  // Reference point\n  lines += 2;\n\n  // Status snapshot\n  lines += 2; // heading + next action\n  const nextActionLines = Math.ceil(\n    truncateText(frame.status_snapshot.next_action, TEXT_LIMITS.nextAction).length / 60\n  );\n  lines += nextActionLines;\n\n  // Blockers\n  if (frame.status_snapshot.blockers?.length > 0) {\n    lines += 1; // heading\n    const blockerCount = Math.min(frame.status_snapshot.blockers.length, TEXT_LIMITS.maxBlockers);\n    lines += blockerCount;\n  }\n\n  // Merge blockers\n  if (frame.status_snapshot.merge_blockers?.length > 0) {\n    lines += 1; // heading\n    const mergeBlockerCount = Math.min(\n      frame.status_snapshot.merge_blockers.length,\n      TEXT_LIMITS.maxBlockers\n    );\n    lines += mergeBlockerCount;\n  }\n\n  // Tests failing\n  if (frame.status_snapshot.tests_failing?.length > 0) {\n    lines += 1; // heading\n    const testCount = Math.min(frame.status_snapshot.tests_failing.length, TEXT_LIMITS.maxBlockers);\n    lines += testCount;\n  }\n\n  // Module scope\n  lines += 2;\n\n  // Keywords\n  if (frame.keywords?.length > 0) {\n    lines += 2;\n  }\n\n  // Optional fields\n  if (frame.jira) lines += 1;\n  if (frame.atlas_frame_id) lines += 1;\n\n  // Raw context section\n  lines += 4; // spacing and potential context\n\n  const calculatedHeight = dimensions.padding * 2 + lines * dimensions.lineHeight;\n  return Math.max(calculatedHeight, dimensions.height);\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/timeline.example.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'writeFileSync' is defined but never used. Allowed unused vars must match /^_/u.","line":10,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":10,"endColumn":23}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { getLogger } from \"lex/logger\";\nimport {\n  buildTimeline,\n  renderTimelineText,\n  renderModuleScopeEvolution,\n  renderBlockerTracking,\n  renderTimelineHTML,\n} from \"./timeline.js\";\nimport type { Frame } from \"./types.js\";\nimport { writeFileSync } from \"fs\";\n\nconst logger = getLogger(\"memory:renderer:timeline.example\");\n\n// Example frames for TICKET-123: Add user authentication\nconst frames: Frame[] = [\n  {\n    id: \"frame-abc123\",\n    timestamp: \"2025-11-01T14:00:00-05:00\",\n    branch: \"feature/user-auth\",\n    jira: \"TICKET-123\",\n    module_scope: [\"ui/login-form\"],\n    summary_caption: \"Started implementation\",\n    reference_point: \"auth login start\",\n    status_snapshot: {\n      next_action: \"Build login form UI components\",\n    },\n  },\n  {\n    id: \"frame-def456\",\n    timestamp: \"2025-11-02T09:30:00-05:00\",\n    branch: \"feature/user-auth\",\n    jira: \"TICKET-123\",\n    module_scope: [\"ui/login-form\", \"services/auth-core\"],\n    summary_caption: \"Auth API integration\",\n    reference_point: \"auth api integration\",\n    status_snapshot: {\n      next_action: \"Configure CORS headers for auth endpoint\",\n      blockers: [\"CORS configuration issue\"],\n    },\n  },\n  {\n    id: \"frame-ghi789\",\n    timestamp: \"2025-11-02T16:45:00-05:00\",\n    branch: \"feature/user-auth\",\n    jira: \"TICKET-123\",\n    module_scope: [\"ui/login-form\", \"services/auth-core\"],\n    summary_caption: \"Fixed CORS, tests failing\",\n    reference_point: \"cors fixed but tests failing\",\n    status_snapshot: {\n      next_action: \"Debug and fix test_login_flow failure\",\n      tests_failing: [\"test_login_flow\"],\n    },\n  },\n  {\n    id: \"frame-jkl012\",\n    timestamp: \"2025-11-03T11:20:00-05:00\",\n    branch: \"feature/user-auth\",\n    jira: \"TICKET-123\",\n    module_scope: [\"ui/login-form\", \"services/auth-core\"],\n    summary_caption: \"All tests passing\",\n    reference_point: \"tests passing ready for review\",\n    status_snapshot: {\n      next_action: \"Submit PR and request code review\",\n    },\n  },\n];\n\n// Build timeline\nconst timeline = buildTimeline(frames);\n\n// Render text output\nlogger.info(\"=\".repeat(80));\nlogger.info(\"TIMELINE TEXT OUTPUT\");\nlogger.info(\"=\".repeat(80));\nlogger.info(\"TIMELINE TEXT OUTPUT\");\nlogger.info(\"=\".repeat(80));\nlogger.info(\"\");\nconst textOutput = renderTimelineText(timeline, \"TICKET-123: Add user authentication\");\nlogger.info(textOutput);\n\n// Module scope evolution\nlogger.info(\"=\".repeat(80));\nlogger.info(\"MODULE SCOPE EVOLUTION\");\nlogger.info(\"=\".repeat(80));\nconst evolutionGraph = renderModuleScopeEvolution(timeline);\nlogger.info(evolutionGraph);\n\n// Blocker tracking\nlogger.info(\"=\".repeat(80));\nlogger.info(\"BLOCKER TRACKING\");\nlogger.info(\"=\".repeat(80));\nconst blockerTracking = renderBlockerTracking(timeline);\nlogger.info(blockerTracking);\n\n// Generate HTML output (optional)\nconst htmlOutput = renderTimelineHTML(timeline, \"TICKET-123: Add user authentication\");\nlogger.info(\"=\".repeat(80));\nlogger.info(\"HTML OUTPUT (preview)\");\nlogger.info(\"=\".repeat(80));\nlogger.info(\"HTML file would be written to disk.\");\nlogger.info(`Length: ${htmlOutput.length} characters`);\nlogger.info(`Contains title: ${htmlOutput.includes(\"TICKET-123\")}`);\nlogger.info(\"\");\n\n// Uncomment to write HTML to file:\n// writeFileSync('/tmp/timeline-example.html', htmlOutput, 'utf-8');\n// logger.info('âœ“ HTML timeline written to /tmp/timeline-example.html');\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/timeline.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/renderer/types.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/store/db.ts","messages":[{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":75,"column":15,"nodeType":"VariableDeclarator","messageId":"anyAssignment","endLine":75,"endColumn":79},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .name on an `any` value.","line":76,"column":25,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":76,"endColumn":29}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Database initialization and schema management for Frame storage\n *\n * Creates SQLite database with FTS5 virtual table for full-text search\n * on reference_point, keywords, and summary_caption.\n */\n\nimport Database from \"better-sqlite3\";\nimport { homedir } from \"os\";\nimport { join, dirname } from \"path\";\nimport { mkdirSync, existsSync, readFileSync } from \"fs\";\n\nexport interface FrameRow {\n  id: string;\n  timestamp: string;\n  branch: string;\n  jira: string | null;\n  module_scope: string; // JSON stringified array\n  summary_caption: string;\n  reference_point: string;\n  status_snapshot: string; // JSON stringified object\n  keywords: string | null; // JSON stringified array\n  atlas_frame_id: string | null;\n  feature_flags: string | null; // JSON stringified array\n  permissions: string | null; // JSON stringified array\n  // Merge-weave metadata (v2)\n  run_id: string | null;\n  plan_hash: string | null;\n  spend: string | null; // JSON stringified object\n}\n\n/**\n * Get default database path: .smartergpt.local/lex/memory.db (relative to repo root)\n * Falls back to ~/.lex/frames.db if not in a lex repository\n * Can be overridden with LEX_DB_PATH environment variable\n */\nexport function getDefaultDbPath(): string {\n  // Check for environment variable override\n  if (process.env.LEX_DB_PATH) {\n    return process.env.LEX_DB_PATH;\n  }\n\n  // Try to find repo root\n  try {\n    const repoRoot = findRepoRoot(process.cwd());\n    const localPath = join(repoRoot, \".smartergpt.local\", \"lex\", \"memory.db\");\n\n    // Ensure directory exists\n    const localDir = join(repoRoot, \".smartergpt.local\", \"lex\");\n    if (!existsSync(localDir)) {\n      mkdirSync(localDir, { recursive: true });\n    }\n\n    return localPath;\n  } catch {\n    // Fallback to home directory if not in repo\n    const lexDir = join(homedir(), \".lex\");\n    if (!existsSync(lexDir)) {\n      mkdirSync(lexDir, { recursive: true });\n    }\n    return join(lexDir, \"frames.db\");\n  }\n}\n\n/**\n * Find repository root by looking for package.json with name \"lex\"\n */\nfunction findRepoRoot(startPath: string): string {\n  let currentPath = startPath;\n\n  while (currentPath !== dirname(currentPath)) {\n    const packageJsonPath = join(currentPath, \"package.json\");\n    if (existsSync(packageJsonPath)) {\n      try {\n        const packageJson = JSON.parse(readFileSync(packageJsonPath, \"utf-8\"));\n        if (packageJson.name === \"lex\") {\n          return currentPath;\n        }\n      } catch {\n        // Invalid package.json, continue searching\n      }\n    }\n    currentPath = dirname(currentPath);\n  }\n\n  throw new Error(\"Repository root not found\");\n}\n\n/**\n * Initialize database with schema and indexes\n */\nexport function initializeDatabase(db: Database.Database): void {\n  // Set SQLite pragmas for performance and reliability\n  db.pragma(\"journal_mode = WAL\");\n  db.pragma(\"busy_timeout = 5000\");\n  db.pragma(\"synchronous = NORMAL\");\n  db.pragma(\"cache_size = 10000\");\n  db.pragma(\"foreign_keys = ON\");\n\n  // Create schema version table for migration support\n  db.exec(`\n    CREATE TABLE IF NOT EXISTS schema_version (\n      version INTEGER PRIMARY KEY,\n      applied_at TEXT NOT NULL DEFAULT (datetime('now'))\n    );\n  `);\n\n  // Check current schema version\n  const versionRow = db.prepare(\"SELECT MAX(version) as version FROM schema_version\").get() as {\n    version: number | null;\n  };\n  const currentVersion = versionRow?.version || 0;\n\n  // Apply migrations\n  if (currentVersion < 1) {\n    applyMigrationV1(db);\n    db.prepare(\"INSERT INTO schema_version (version) VALUES (?)\").run(1);\n  }\n  if (currentVersion < 2) {\n    applyMigrationV2(db);\n    db.prepare(\"INSERT INTO schema_version (version) VALUES (?)\").run(2);\n  }\n  if (currentVersion < 3) {\n    applyMigrationV3(db);\n    db.prepare(\"INSERT INTO schema_version (version) VALUES (?)\").run(3);\n  }\n}\n\n/**\n * Migration V1: Initial schema\n */\nfunction applyMigrationV1(db: Database.Database): void {\n  // Create frames table with all fields from FRAME.md\n  db.exec(`\n    CREATE TABLE IF NOT EXISTS frames (\n      id TEXT PRIMARY KEY,\n      timestamp TEXT NOT NULL,\n      branch TEXT NOT NULL,\n      jira TEXT,\n      module_scope TEXT NOT NULL,\n      summary_caption TEXT NOT NULL,\n      reference_point TEXT NOT NULL,\n      status_snapshot TEXT NOT NULL,\n      keywords TEXT,\n      atlas_frame_id TEXT,\n      feature_flags TEXT,\n      permissions TEXT\n    );\n  `);\n\n  // Create FTS5 virtual table for fuzzy search on reference_point, keywords, summary_caption\n  db.exec(`\n    CREATE VIRTUAL TABLE IF NOT EXISTS frames_fts USING fts5(\n      reference_point,\n      summary_caption,\n      keywords,\n      content='frames',\n      content_rowid='rowid'\n    );\n  `);\n\n  // Create triggers to keep FTS index in sync with frames table\n  db.exec(`\n    CREATE TRIGGER IF NOT EXISTS frames_ai AFTER INSERT ON frames BEGIN\n      INSERT INTO frames_fts(rowid, reference_point, summary_caption, keywords)\n      VALUES (new.rowid, new.reference_point, new.summary_caption, new.keywords);\n    END;\n  `);\n\n  db.exec(`\n    CREATE TRIGGER IF NOT EXISTS frames_ad AFTER DELETE ON frames BEGIN\n      DELETE FROM frames_fts WHERE rowid = old.rowid;\n    END;\n  `);\n\n  db.exec(`\n    CREATE TRIGGER IF NOT EXISTS frames_au AFTER UPDATE ON frames BEGIN\n      UPDATE frames_fts\n      SET reference_point = new.reference_point,\n          summary_caption = new.summary_caption,\n          keywords = new.keywords\n      WHERE rowid = new.rowid;\n    END;\n  `);\n\n  // Create indexes for common query patterns\n  db.exec(`\n    CREATE INDEX IF NOT EXISTS idx_frames_timestamp ON frames(timestamp DESC);\n  `);\n\n  db.exec(`\n    CREATE INDEX IF NOT EXISTS idx_frames_branch ON frames(branch);\n  `);\n\n  db.exec(`\n    CREATE INDEX IF NOT EXISTS idx_frames_jira ON frames(jira);\n  `);\n\n  db.exec(`\n    CREATE INDEX IF NOT EXISTS idx_frames_atlas_frame_id ON frames(atlas_frame_id);\n  `);\n}\n\n/**\n * Migration V2: Add images table\n */\nfunction applyMigrationV2(db: Database.Database): void {\n  // Create images table for Frame attachments\n  db.exec(`\n    CREATE TABLE IF NOT EXISTS images (\n      image_id TEXT PRIMARY KEY,\n      frame_id TEXT NOT NULL,\n      data BLOB NOT NULL,\n      mime_type TEXT NOT NULL,\n      created_at INTEGER NOT NULL,\n      FOREIGN KEY (frame_id) REFERENCES frames(id) ON DELETE CASCADE\n    );\n  `);\n\n  // Create index for frame_id lookups\n  db.exec(`\n    CREATE INDEX IF NOT EXISTS idx_images_frame_id ON images(frame_id);\n  `);\n}\n\n/**\n * Migration V3: Add merge-weave metadata fields (Frame schema v2)\n */\nfunction applyMigrationV3(db: Database.Database): void {\n  // Add new optional columns for merge-weave provenance\n  // Safe to add with NULL default, backward compatible\n  db.exec(`\n    ALTER TABLE frames ADD COLUMN run_id TEXT;\n  `);\n\n  db.exec(`\n    ALTER TABLE frames ADD COLUMN plan_hash TEXT;\n  `);\n\n  db.exec(`\n    ALTER TABLE frames ADD COLUMN spend TEXT;\n  `);\n}\n\n/**\n * Create and initialize a database connection\n */\nexport function createDatabase(dbPath?: string): Database.Database {\n  const path = dbPath || getDefaultDbPath();\n  const db = new Database(path);\n  initializeDatabase(db);\n  return db;\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/store/framestore.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":64,"column":22,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":64,"endColumn":25,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1723,1726],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1723,1726],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":78,"column":29,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":78,"endColumn":32,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2041,2044],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2041,2044],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":91,"column":7,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":91,"endColumn":10,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2367,2370],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2367,2370],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// Legacy class-based API for Frame storage\n// Wraps the new modular implementation (db.ts, queries.ts, index.ts)\n// This provides backward compatibility while using the new modular code internally\n\nimport { getLogger } from \"lex/logger\";\nimport Database from \"better-sqlite3\";\nimport { createDatabase } from \"./db.js\";\nimport {\n  saveFrame as save,\n  getFrameById as getById,\n  searchFrames as search,\n  deleteFrame as remove,\n  getFramesByBranch,\n  getFramesByJira,\n  getAllFrames,\n} from \"./queries.js\";\nimport type { Frame } from \"../frames/types.js\";\n\nconst logger = getLogger(\"memory:store:framestore\");\n\nexport interface FrameRow {\n  id: string;\n  timestamp: string;\n  branch: string;\n  jira: string | null;\n  module_scope: string; // JSON stringified array\n  summary_caption: string;\n  reference_point: string;\n  status_snapshot: string; // JSON stringified object\n  keywords: string | null; // JSON stringified array\n  atlas_frame_id: string | null;\n}\n\n/**\n * Frame storage manager using SQLite\n *\n * @deprecated Use the modular API from index.ts instead\n * @example\n * ```typescript\n * // Old API (still works)\n * const store = new FrameStore('/path/to/db');\n * store.insertFrame(frame);\n *\n * // New API (recommended)\n * import { getDb, saveFrame } from 'lex/store';\n * const db = getDb('/path/to/db');\n * saveFrame(db, frame);\n * ```\n *\n * Frames are stored locally with full-text search on reference_point for fuzzy recall.\n * No telemetry. No cloud sync.\n */\nexport class FrameStore {\n  private db: Database.Database;\n\n  constructor(dbPath: string) {\n    this.db = createDatabase(dbPath);\n  }\n\n  /**\n   * Insert or update a Frame\n   * @deprecated Use saveFrame from the modular API\n   */\n  insertFrame(frame: any): boolean {\n    try {\n      save(this.db, frame as Frame);\n      return true;\n    } catch (error) {\n      logger.error({ err: error }, \"Failed to insert frame\");\n      return false;\n    }\n  }\n\n  /**\n   * Retrieve Frame by ID\n   * @deprecated Use getFrameById from the modular API\n   */\n  getFrameById(id: string): any | null {\n    return getById(this.db, id);\n  }\n\n  /**\n   * Search Frames with FTS and optional filters\n   * @deprecated Use searchFrames, getFramesByBranch, or getFramesByJira from the modular API\n   */\n  searchFrames(query: {\n    reference_point?: string;\n    jira?: string;\n    branch?: string;\n    limit?: number;\n  }): any[] {\n    if (query.reference_point) {\n      // Return just the frames array from SearchResult for backward compatibility\n      return search(this.db, query.reference_point).frames;\n    }\n\n    if (query.jira) {\n      return getFramesByJira(this.db, query.jira);\n    }\n\n    if (query.branch) {\n      return getFramesByBranch(this.db, query.branch);\n    }\n\n    return getAllFrames(this.db, query.limit);\n  }\n\n  /**\n   * Delete Frame by ID\n   * @deprecated Use deleteFrame from the modular API\n   */\n  deleteFrame(id: string): boolean {\n    return remove(this.db, id);\n  }\n\n  /**\n   * Close database connection\n   */\n  close() {\n    this.db.close();\n  }\n\n  /**\n   * Get the underlying database instance (for testing/internal use)\n   * @internal\n   */\n  getDatabase(): Database.Database {\n    return this.db;\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/store/images.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/store/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/memory/store/queries.ts","messages":[{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":44,"column":5,"nodeType":"Property","messageId":"anyAssignment","endLine":44,"endColumn":47},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":48,"column":5,"nodeType":"Property","messageId":"anyAssignment","endLine":48,"endColumn":66},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":50,"column":5,"nodeType":"Property","messageId":"anyAssignment","endLine":50,"endColumn":81},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":51,"column":5,"nodeType":"Property","messageId":"anyAssignment","endLine":51,"endColumn":75},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":55,"column":5,"nodeType":"Property","messageId":"anyAssignment","endLine":55,"endColumn":57},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":126,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":126,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3803,3806],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3803,3806],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .code on an `any` value.","line":129,"column":14,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":129,"endColumn":18},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":130,"column":8,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":130,"endColumn":32},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .message on an `any` value.","line":130,"column":15,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":130,"endColumn":22},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":131,"column":9,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":131,"endColumn":33},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .message on an `any` value.","line":131,"column":16,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":131,"endColumn":23},{"ruleId":"@typescript-eslint/no-unsafe-call","severity":1,"message":"Unsafe call of a(n) `any` typed value.","line":132,"column":9,"nodeType":"MemberExpression","messageId":"unsafeCall","endLine":132,"endColumn":33},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .message on an `any` value.","line":132,"column":16,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":132,"endColumn":23}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":13,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Frame storage queries\n *\n * CRUD operations and search functions for Frames.\n */\n\nimport Database from \"better-sqlite3\";\nimport type { FrameRow } from \"./db.js\";\nimport type { Frame, FrameStatusSnapshot } from \"../frames/types.js\";\n\n/**\n * Convert Frame object to database row\n */\nfunction frameToRow(frame: Frame): FrameRow {\n  return {\n    id: frame.id,\n    timestamp: frame.timestamp,\n    branch: frame.branch,\n    jira: frame.jira || null,\n    module_scope: JSON.stringify(frame.module_scope),\n    summary_caption: frame.summary_caption,\n    reference_point: frame.reference_point,\n    status_snapshot: JSON.stringify(frame.status_snapshot),\n    keywords: frame.keywords ? JSON.stringify(frame.keywords) : null,\n    atlas_frame_id: frame.atlas_frame_id || null,\n    feature_flags: frame.feature_flags ? JSON.stringify(frame.feature_flags) : null,\n    permissions: frame.permissions ? JSON.stringify(frame.permissions) : null,\n    // Merge-weave metadata (v2)\n    run_id: frame.runId || null,\n    plan_hash: frame.planHash || null,\n    spend: frame.spend ? JSON.stringify(frame.spend) : null,\n  };\n}\n\n/**\n * Convert database row to Frame object\n */\nfunction rowToFrame(row: FrameRow): Frame {\n  return {\n    id: row.id,\n    timestamp: row.timestamp,\n    branch: row.branch,\n    jira: row.jira || undefined,\n    module_scope: JSON.parse(row.module_scope),\n    summary_caption: row.summary_caption,\n    reference_point: row.reference_point,\n    status_snapshot: JSON.parse(row.status_snapshot) as FrameStatusSnapshot,\n    keywords: row.keywords ? JSON.parse(row.keywords) : undefined,\n    atlas_frame_id: row.atlas_frame_id || undefined,\n    feature_flags: row.feature_flags ? JSON.parse(row.feature_flags) : undefined,\n    permissions: row.permissions ? JSON.parse(row.permissions) : undefined,\n    // Merge-weave metadata (v2) - backward compatible, defaults to undefined\n    runId: row.run_id || undefined,\n    planHash: row.plan_hash || undefined,\n    spend: row.spend ? JSON.parse(row.spend) : undefined,\n  };\n}\n\n/**\n * Save a Frame to the database (insert or update)\n */\nexport function saveFrame(db: Database.Database, frame: Frame): void {\n  const row = frameToRow(frame);\n\n  const stmt = db.prepare(`\n    INSERT OR REPLACE INTO frames (\n      id, timestamp, branch, jira, module_scope, summary_caption,\n      reference_point, status_snapshot, keywords, atlas_frame_id,\n      feature_flags, permissions, run_id, plan_hash, spend\n    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n  `);\n\n  stmt.run(\n    row.id,\n    row.timestamp,\n    row.branch,\n    row.jira,\n    row.module_scope,\n    row.summary_caption,\n    row.reference_point,\n    row.status_snapshot,\n    row.keywords,\n    row.atlas_frame_id,\n    row.feature_flags,\n    row.permissions,\n    row.run_id,\n    row.plan_hash,\n    row.spend\n  );\n}\n\n/**\n * Get a Frame by ID\n */\nexport function getFrameById(db: Database.Database, id: string): Frame | null {\n  const stmt = db.prepare(\"SELECT * FROM frames WHERE id = ?\");\n  const row = stmt.get(id) as FrameRow | undefined;\n\n  if (!row) return null;\n\n  return rowToFrame(row);\n}\n\nexport interface SearchResult {\n  frames: Frame[];\n  hint?: string;\n}\n\n/**\n * Search Frames using FTS5 full-text search\n * @param query Natural language query string (searches reference_point, summary_caption, keywords)\n * @returns SearchResult with frames array and optional hint for FTS5 syntax errors\n */\nexport function searchFrames(db: Database.Database, query: string): SearchResult {\n  try {\n    const stmt = db.prepare(`\n      SELECT f.*\n      FROM frames f\n      JOIN frames_fts fts ON f.rowid = fts.rowid\n      WHERE frames_fts MATCH ?\n      ORDER BY f.timestamp DESC\n    `);\n\n    const rows = stmt.all(query) as FrameRow[];\n    return { frames: rows.map(rowToFrame) };\n  } catch (error: any) {\n    // Check if this is an FTS5-related error (caused by special characters)\n    if (\n      error?.code === \"SQLITE_ERROR\" &&\n      (error?.message?.includes(\"fts5: syntax error\") ||\n        error?.message?.includes(\"no such column\") ||\n        error?.message?.includes(\"unknown special query\"))\n    ) {\n      // Extract a simpler search term by removing special characters\n      const simplifiedQuery = query.replace(/[^a-zA-Z0-9\\s]/g, \" \").trim();\n      const hint = simplifiedQuery\n        ? `Search contained special characters. Try simpler terms (e.g., '${simplifiedQuery}')`\n        : \"Search contained special characters. Try simpler terms\";\n\n      return {\n        frames: [],\n        hint,\n      };\n    }\n    // Re-throw non-FTS5 errors\n    throw error;\n  }\n}\n\n/**\n * Get all Frames for a specific branch\n */\nexport function getFramesByBranch(db: Database.Database, branch: string): Frame[] {\n  const stmt = db.prepare(`\n    SELECT * FROM frames\n    WHERE branch = ?\n    ORDER BY timestamp DESC\n  `);\n\n  const rows = stmt.all(branch) as FrameRow[];\n  return rows.map(rowToFrame);\n}\n\n/**\n * Get all Frames for a specific Jira/ticket ID\n */\nexport function getFramesByJira(db: Database.Database, jiraId: string): Frame[] {\n  const stmt = db.prepare(`\n    SELECT * FROM frames\n    WHERE jira = ?\n    ORDER BY timestamp DESC\n  `);\n\n  const rows = stmt.all(jiraId) as FrameRow[];\n  return rows.map(rowToFrame);\n}\n\n/**\n * Get all Frames that touch a specific module\n * @param moduleId Module ID to search for in module_scope arrays\n */\nexport function getFramesByModuleScope(db: Database.Database, moduleId: string): Frame[] {\n  // Get all frames and filter in JavaScript to avoid SQL injection\n  // This is safe because module_scope is stored as JSON array\n  const stmt = db.prepare(`\n    SELECT * FROM frames\n    ORDER BY timestamp DESC\n  `);\n\n  const rows = stmt.all() as FrameRow[];\n\n  // Filter frames that contain the moduleId in their module_scope array\n  return rows.map(rowToFrame).filter((frame) => frame.module_scope.includes(moduleId));\n}\n\n/**\n * Get all Frames (with optional limit)\n */\nexport function getAllFrames(db: Database.Database, limit?: number): Frame[] {\n  const stmt = db.prepare(`\n    SELECT * FROM frames\n    ORDER BY timestamp DESC\n    ${limit ? \"LIMIT ?\" : \"\"}\n  `);\n\n  const rows = limit ? (stmt.all(limit) as FrameRow[]) : (stmt.all() as FrameRow[]);\n  return rows.map(rowToFrame);\n}\n\n/**\n * Delete a Frame by ID\n */\nexport function deleteFrame(db: Database.Database, id: string): boolean {\n  const stmt = db.prepare(\"DELETE FROM frames WHERE id = ?\");\n  const result = stmt.run(id);\n  return result.changes > 0;\n}\n\n/**\n * Get count of all Frames\n */\nexport function getFrameCount(db: Database.Database): number {\n  const stmt = db.prepare(\"SELECT COUNT(*) as count FROM frames\");\n  const result = stmt.get() as { count: number };\n  return result.count;\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/merge-weave/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/merge-weave/types.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/policy/check/lexmap-check.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/policy/check/reporter.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/policy/check/violations.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/policy/merge/lexmap-merge.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'path' is defined but never used. Allowed unused vars must match /^_/u.","line":31,"column":13,"nodeType":null,"messageId":"unusedVar","endLine":31,"endColumn":17},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":83,"column":13,"nodeType":"VariableDeclarator","messageId":"anyAssignment","endLine":83,"endColumn":54}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"#!/usr/bin/env node\n/**\n * LexMap Merge Tool\n *\n * Combines scanner outputs from multiple language scanners into a single unified view.\n *\n * Usage:\n *     lexmap merge scanner1.json scanner2.json ... > merged.json\n *\n * Philosophy:\n *     This tool MERGES scanner outputs, it does NOT enforce policy.\n *     Policy enforcement happens AFTER merge, using lexmap.policy.json.\n *\n * Flow:\n *     1. Read all scanner output JSON files\n *     2. Validate each against scanner-output.schema.json\n *     3. Merge file lists (deduplicating by path)\n *     4. Output unified scanner-output.json\n *\n * Next Step:\n *     Feed merged output to policy checker which:\n *     - Resolves file paths â†’ module_scope (using lexmap.policy.json)\n *     - Checks allowed_callers vs actual imports\n *     - Reports violations\n *\n * Author: LexMap\n * License: MIT\n */\n\nimport * as fs from \"fs\";\nimport * as path from \"path\";\n\ninterface Declaration {\n  type: string;\n  name: string;\n  namespace?: string;\n}\n\ninterface Import {\n  from: string;\n  type: string;\n  imported?: string[];\n  alias?: string | null;\n}\n\ninterface FileData {\n  path: string;\n  module_scope?: string;\n  declarations: Declaration[];\n  imports: Import[];\n  feature_flags: string[];\n  permissions: string[];\n  warnings: string[];\n}\n\ninterface ModuleEdge {\n  from_module: string;\n  to_module: string;\n  from_file: string;\n  import_statement: string;\n}\n\ninterface ScannerOutput {\n  language: string;\n  files: FileData[];\n  module_edges?: ModuleEdge[];\n}\n\ninterface MergedOutput {\n  sources: string[];\n  files: FileData[];\n  module_edges: ModuleEdge[];\n}\n\nclass LexMapMerge {\n  private scannerOutputs: ScannerOutput[] = [];\n  private fileMap: Map<string, FileData> = new Map();\n  private moduleEdges: ModuleEdge[] = [];\n\n  loadScanner(filePath: string): void {\n    try {\n      const content = fs.readFileSync(filePath, \"utf-8\");\n      const data: ScannerOutput = JSON.parse(content);\n\n      // Basic validation\n      if (!data.language || !Array.isArray(data.files)) {\n        console.error(`Error: ${filePath} does not conform to scanner-output.schema.json`);\n        process.exit(1);\n      }\n\n      this.scannerOutputs.push(data);\n      console.error(\n        `Loaded scanner output: ${filePath} (${data.language}, ${data.files.length} files)`\n      );\n    } catch (error) {\n      console.error(`Error loading ${filePath}:`, error);\n      process.exit(1);\n    }\n  }\n\n  merge(): MergedOutput {\n    const sources: string[] = [];\n\n    // Collect all files, deduplicating by path\n    for (const scanner of this.scannerOutputs) {\n      sources.push(scanner.language);\n\n      // Merge module edges\n      if (scanner.module_edges) {\n        this.moduleEdges.push(...scanner.module_edges);\n      }\n\n      for (const file of scanner.files) {\n        const existingFile = this.fileMap.get(file.path);\n\n        if (existingFile) {\n          // File already seen - merge metadata\n          // This shouldn't happen often (different scanners for different languages)\n          // but handle it gracefully\n          console.error(`Warning: File ${file.path} appears in multiple scanner outputs`);\n\n          // Prefer module_scope from scanner if it exists\n          if (file.module_scope && !existingFile.module_scope) {\n            existingFile.module_scope = file.module_scope;\n          }\n\n          // Merge arrays (deduplicate)\n          existingFile.feature_flags = [\n            ...new Set([...existingFile.feature_flags, ...file.feature_flags]),\n          ].sort();\n          existingFile.permissions = [\n            ...new Set([...existingFile.permissions, ...file.permissions]),\n          ].sort();\n          existingFile.warnings = [...new Set([...existingFile.warnings, ...file.warnings])];\n        } else {\n          // New file - add to map\n          this.fileMap.set(file.path, file);\n        }\n      }\n    }\n\n    // Deduplicate module edges based on from_module, to_module, and import_statement\n    const edgeMap = new Map<string, ModuleEdge>();\n    for (const edge of this.moduleEdges) {\n      const key = `${edge.from_module}:${edge.to_module}:${edge.import_statement}`;\n      if (!edgeMap.has(key)) {\n        edgeMap.set(key, edge);\n      }\n    }\n\n    return {\n      sources,\n      files: Array.from(this.fileMap.values()).sort((a, b) => a.path.localeCompare(b.path)),\n      module_edges: Array.from(edgeMap.values()),\n    };\n  }\n}\n\nfunction main() {\n  const args = process.argv.slice(2);\n\n  if (args.length < 1) {\n    console.error(\"Usage: lexmap merge <scanner1.json> <scanner2.json> ... > merged.json\");\n    console.error(\"\");\n    console.error(\"Combines scanner outputs from multiple language scanners.\");\n    console.error(\"Output conforms to scanner-output.schema.json structure.\");\n    console.error(\"\");\n    console.error(\"Example:\");\n    console.error(\"  python3 php_scanner.py app/ > php.json\");\n    console.error(\"  node ts_scanner.ts ui/ > ts.json\");\n    console.error(\"  lexmap merge php.json ts.json > merged.json\");\n    process.exit(1);\n  }\n\n  const merger = new LexMapMerge();\n\n  // Load all scanner outputs\n  for (const scannerFile of args) {\n    if (!fs.existsSync(scannerFile)) {\n      console.error(`Error: File not found: ${scannerFile}`);\n      process.exit(1);\n    }\n    merger.loadScanner(scannerFile);\n  }\n\n  // Merge and output\n  const merged = merger.merge();\n\n  console.log(JSON.stringify(merged, null, 2));\n  console.error(`\\nMerged ${merged.files.length} files from ${merged.sources.length} scanners`);\n}\n\nmain();\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/policy/merge/merge.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/policy/merge/types.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/policy/scanners/common.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/policy/scanners/test_scanners.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/policy/scanners/ts_scanner.ts","messages":[{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":106,"column":9,"nodeType":"AssignmentExpression","messageId":"anyAssignment","endLine":106,"endColumn":48},{"ruleId":"@typescript-eslint/restrict-template-expressions","severity":1,"message":"Invalid type \"unknown\" of template literal expression.","line":108,"column":63,"nodeType":"Identifier","messageId":"invalidType","endLine":108,"endColumn":68},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":169,"column":14,"nodeType":null,"messageId":"unusedVar","endLine":169,"endColumn":19}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"#!/usr/bin/env node\n/**\n * LexMap TypeScript/JavaScript Scanner Plugin\n *\n * Scans TypeScript and JavaScript files and extracts architectural facts.\n *\n * Contract: Outputs JSON conforming to ../docs/schemas/scanner-output.schema.json\n *\n * Usage:\n *     node ts_scanner.ts <directory> > output.json\n *\n * Philosophy:\n *     This scanner is DUMB BY DESIGN.\n *     It observes code and reports facts.\n *     It does NOT make architectural decisions.\n *\n *     - Extracts: classes, functions, interfaces, imports\n *     - Detects: feature flags, permission checks\n *     - Reports: what it sees, nothing more\n *\n *     LexMap (not the scanner) decides:\n *     - Which module a file belongs to\n *     - Whether an import is allowed\n *     - Whether a boundary is violated\n *\n * Output Schema:\n *     {\n *       \"language\": \"typescript\",\n *       \"files\": [\n *         {\n *           \"path\": \"relative/path/to/File.ts\",\n *           \"declarations\": [...],\n *           \"imports\": [...],\n *           \"feature_flags\": [...],\n *           \"permissions\": [...],\n *           \"warnings\": []\n *         }\n *       ]\n *     }\n *\n * Dependencies:\n *     npm install typescript glob\n *\n * Author: LexMap Scanner Plugin\n * License: MIT\n */\n\nimport * as ts from \"typescript\";\nimport * as fs from \"fs\";\nimport * as path from \"path\";\nimport { glob } from \"glob\";\nimport {\n  Policy,\n  ModuleEdge,\n  resolveFileToModule,\n  resolveImportToModule,\n  detectFeatureFlags,\n  detectPermissions,\n} from \"./common.js\";\n\ninterface Declaration {\n  type: string;\n  name: string;\n  namespace?: string;\n}\n\ninterface Import {\n  from: string;\n  type: string;\n  imported?: string[];\n}\n\ninterface FileData {\n  path: string;\n  module_scope?: string;\n  declarations: Declaration[];\n  imports: Import[];\n  feature_flags: string[];\n  permissions: string[];\n  warnings: string[];\n}\n\ninterface ScannerOutput {\n  language: string;\n  files: FileData[];\n  module_edges?: ModuleEdge[];\n}\n\nclass TypeScriptScanner {\n  private rootDir: string;\n  private output: ScannerOutput;\n  private policy?: Policy;\n\n  constructor(rootDir: string, policyPath?: string) {\n    this.rootDir = path.resolve(rootDir);\n    this.output = {\n      language: \"typescript\",\n      files: [],\n      module_edges: [],\n    };\n\n    // Load policy file if provided\n    if (policyPath && fs.existsSync(policyPath)) {\n      try {\n        const policyContent = fs.readFileSync(policyPath, \"utf-8\");\n        this.policy = JSON.parse(policyContent);\n      } catch (error) {\n        console.error(`Warning: Failed to load policy file: ${error}`);\n      }\n    }\n  }\n\n  async scan(): Promise<ScannerOutput> {\n    // Find all .ts and .tsx files (excluding node_modules, .d.ts)\n    const pattern = `${this.rootDir}/**/*.{ts,tsx}`;\n    const files = await glob(pattern, {\n      ignore: [\"**/node_modules/**\", \"**/*.d.ts\"],\n    });\n\n    for (const filePath of files) {\n      const fileData = this.scanFile(filePath);\n      if (fileData) {\n        this.output.files.push(fileData);\n      }\n    }\n\n    return this.output;\n  }\n\n  private scanFile(filePath: string): FileData | null {\n    try {\n      const content = fs.readFileSync(filePath, \"utf-8\");\n      const relativePath = path.relative(this.rootDir, filePath);\n\n      const sourceFile = ts.createSourceFile(filePath, content, ts.ScriptTarget.Latest, true);\n\n      const imports = this.extractImports(sourceFile);\n      const fileData: FileData = {\n        path: relativePath,\n        declarations: this.extractDeclarations(sourceFile),\n        imports,\n        feature_flags: detectFeatureFlags(content),\n        permissions: detectPermissions(content),\n        warnings: [],\n      };\n\n      // Resolve module ownership if policy is available\n      if (this.policy) {\n        const moduleId = resolveFileToModule(relativePath, this.policy);\n        if (moduleId) {\n          fileData.module_scope = moduleId;\n\n          // Detect cross-module calls\n          for (const imp of imports) {\n            const targetModuleId = resolveImportToModule(imp.from, relativePath, this.policy);\n            if (targetModuleId && targetModuleId !== moduleId) {\n              this.output.module_edges!.push({\n                from_module: moduleId,\n                to_module: targetModuleId,\n                from_file: relativePath,\n                import_statement: imp.from,\n              });\n            }\n          }\n        }\n      }\n\n      return fileData;\n    } catch (error) {\n      return null;\n    }\n  }\n\n  private extractDeclarations(sourceFile: ts.SourceFile): Declaration[] {\n    const declarations: Declaration[] = [];\n\n    const visit = (node: ts.Node) => {\n      // Extract classes\n      if (ts.isClassDeclaration(node) && node.name) {\n        declarations.push({\n          type: \"class\",\n          name: node.name.text,\n        });\n      }\n\n      // Extract interfaces\n      if (ts.isInterfaceDeclaration(node)) {\n        declarations.push({\n          type: \"interface\",\n          name: node.name.text,\n        });\n      }\n\n      // Extract type aliases\n      if (ts.isTypeAliasDeclaration(node)) {\n        declarations.push({\n          type: \"type\",\n          name: node.name.text,\n        });\n      }\n\n      // Extract function declarations\n      if (ts.isFunctionDeclaration(node) && node.name) {\n        declarations.push({\n          type: \"function\",\n          name: node.name.text,\n        });\n      }\n\n      // Extract const/let/var declarations (top-level exports)\n      if (ts.isVariableStatement(node)) {\n        node.declarationList.declarations.forEach((decl) => {\n          if (ts.isIdentifier(decl.name)) {\n            // Check if it's exported\n            const modifiers = node.modifiers;\n            if (modifiers?.some((m) => m.kind === ts.SyntaxKind.ExportKeyword)) {\n              declarations.push({\n                type: \"variable\",\n                name: decl.name.text,\n              });\n            }\n          }\n        });\n      }\n\n      ts.forEachChild(node, visit);\n    };\n\n    visit(sourceFile);\n    return declarations;\n  }\n\n  private extractImports(sourceFile: ts.SourceFile): Import[] {\n    const imports: Import[] = [];\n\n    const visit = (node: ts.Node) => {\n      if (ts.isImportDeclaration(node)) {\n        const moduleSpecifier = node.moduleSpecifier;\n        if (ts.isStringLiteral(moduleSpecifier)) {\n          const from = moduleSpecifier.text;\n          const imported: string[] = [];\n\n          if (node.importClause) {\n            const { namedBindings } = node.importClause;\n\n            // import { A, B } from 'module'\n            if (namedBindings && ts.isNamedImports(namedBindings)) {\n              namedBindings.elements.forEach((element) => {\n                imported.push(element.name.text);\n              });\n            }\n\n            // import * as name from 'module'\n            if (namedBindings && ts.isNamespaceImport(namedBindings)) {\n              imported.push(namedBindings.name.text);\n            }\n\n            // import defaultName from 'module'\n            if (node.importClause.name) {\n              imported.push(node.importClause.name.text);\n            }\n          }\n\n          imports.push({\n            from,\n            type: \"import_statement\",\n            imported: imported.length > 0 ? imported : undefined,\n          });\n        }\n      }\n\n      ts.forEachChild(node, visit);\n    };\n\n    visit(sourceFile);\n    return imports;\n  }\n}\n\nasync function main() {\n  const args = process.argv.slice(2);\n\n  if (args.length < 1) {\n    console.error(\"Usage: node ts_scanner.ts <directory> [policy.json]\");\n    console.error(\"\");\n    console.error(\"Outputs JSON conforming to ../docs/schemas/scanner-output.schema.json\");\n    console.error(\"\");\n    console.error(\"Options:\");\n    console.error(\"  policy.json  Optional path to lexmap.policy.json for module resolution\");\n    process.exit(1);\n  }\n\n  const directory = args[0];\n  const policyPath = args[1];\n\n  if (!fs.existsSync(directory) || !fs.statSync(directory).isDirectory()) {\n    console.error(`Error: ${directory} is not a directory`);\n    process.exit(1);\n  }\n\n  const scanner = new TypeScriptScanner(directory, policyPath);\n  const output = await scanner.scan();\n\n  // Output JSON to stdout\n  console.log(JSON.stringify(output, null, 2));\n}\n\nmain().catch((error) => {\n  console.error(\"Error:\", error);\n  process.exit(1);\n});\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/aliases/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/aliases/resolver.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'AmbiguousSubstringError' is defined but never used. Allowed unused vars must match /^_/u.","line":13,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":13,"endColumn":33},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'NoMatchFoundError' is defined but never used. Allowed unused vars must match /^_/u.","line":13,"column":35,"nodeType":null,"messageId":"unusedVar","endLine":13,"endColumn":52},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":42,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":42,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1455,1458],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1455,1458],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-unsafe-member-access","severity":1,"message":"Unsafe member access .message on an `any` value.","line":46,"column":64,"nodeType":"Identifier","messageId":"unsafeMemberExpression","endLine":46,"endColumn":71}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Module ID Alias Resolver\n *\n * Provides alias resolution for module IDs with explicit alias table support.\n * This allows humans to use shorthand names during /remember while maintaining\n * vocabulary alignment with lexmap.policy.json.\n */\n\nexport { AmbiguousSubstringError, NoMatchFoundError } from \"./types.js\";\n// @ts-ignore - cross-package import from compiled dist\nimport type { Policy } from \"../types/policy.js\";\nimport type { AliasTable, AliasResolution, ResolverOptions } from \"./types.js\";\nimport { AmbiguousSubstringError, NoMatchFoundError } from \"./types.js\";\nimport { readFileSync } from \"fs\";\nimport { join, dirname } from \"path\";\nimport { fileURLToPath } from \"url\";\n\n// Cache for loaded alias table\nlet aliasTableCache: AliasTable | null = null;\n\n/**\n * Load alias table from aliases.json with caching\n *\n * @param aliasTablePath - Optional path to alias table JSON file\n * @returns Loaded and cached alias table\n */\nexport function loadAliasTable(aliasTablePath?: string): AliasTable {\n  // Return cached table if available\n  if (aliasTableCache) {\n    return aliasTableCache;\n  }\n\n  try {\n    // Default to aliases.json in the same directory as this module\n    const defaultPath =\n      aliasTablePath || join(dirname(fileURLToPath(import.meta.url)), \"aliases.json\");\n\n    const content = readFileSync(defaultPath, \"utf-8\");\n    aliasTableCache = JSON.parse(content) as AliasTable;\n\n    return aliasTableCache;\n  } catch (error: any) {\n    // If alias table doesn't exist or can't be loaded, return empty table\n    // This is expected for new installations\n    if (process.env.LEX_DEBUG) {\n      console.error(`[LEX] Could not load alias table: ${error.message}`);\n      console.error(`[LEX] Using empty alias table`);\n    }\n\n    aliasTableCache = { aliases: {} };\n    return aliasTableCache;\n  }\n}\n\n/**\n * Clear the alias table cache (useful for testing)\n */\nexport function clearAliasTableCache(): void {\n  aliasTableCache = null;\n}\n\n/**\n * Find all module IDs that contain the given substring\n *\n * @param substring - The substring to search for\n * @param availableModules - Set of available module IDs\n * @param minLength - Minimum substring length (default: 3)\n * @returns Array of matching module IDs\n */\nexport function findSubstringMatches(\n  substring: string,\n  availableModules: Set<string>,\n  minLength: number = 3\n): string[] {\n  // Enforce minimum length\n  if (substring.length < minLength) {\n    return [];\n  }\n\n  const matches: string[] = [];\n  const lowerSubstring = substring.toLowerCase();\n\n  for (const moduleId of availableModules) {\n    if (moduleId.toLowerCase().includes(lowerSubstring)) {\n      matches.push(moduleId);\n    }\n  }\n\n  return matches;\n}\n\n/**\n * Resolve a module ID through the alias system\n *\n * Resolution order:\n * 1. Exact match (confidence 1.0)\n * 2. Alias table (confidence 1.0) [Phase 1]\n * 3. Fuzzy typo correction (handled by module_ids/validator) [Phase 2]\n * 4. Unique substring match (confidence 0.9) [Phase 3]\n * 5. Return unknown with confidence 0\n *\n * @param input - The module ID string to resolve (may be an alias or substring)\n * @param policy - The policy containing canonical module IDs\n * @param aliasTable - Optional pre-loaded alias table (will load default if not provided)\n * @param options - Optional resolver options\n * @returns AliasResolution with canonical ID, confidence, and source\n *\n * @example\n * ```typescript\n * // Exact match (fast path)\n * const result1 = await resolveModuleId('services/auth-core', policy);\n * // { canonical: 'services/auth-core', confidence: 1.0, original: 'services/auth-core', source: 'exact' }\n *\n * // Alias lookup\n * const result2 = await resolveModuleId('auth-core', policy);\n * // { canonical: 'services/auth-core', confidence: 1.0, original: 'auth-core', source: 'alias' }\n *\n * // Unique substring\n * const result3 = await resolveModuleId('user-access', policy);\n * // { canonical: 'services/user-access-api', confidence: 0.9, original: 'user-access', source: 'substring' }\n *\n * // Unknown\n * const result4 = await resolveModuleId('unknown-module', policy);\n * // { canonical: 'unknown-module', confidence: 0, original: 'unknown-module', source: 'fuzzy' }\n * ```\n */\nexport async function resolveModuleId(\n  input: string,\n  policy: Policy,\n  aliasTable?: AliasTable,\n  options?: ResolverOptions\n): Promise<AliasResolution> {\n  const policyModuleIds = new Set(Object.keys(policy.modules));\n\n  // Default options\n  const opts: Required<ResolverOptions> = {\n    noSubstring: options?.noSubstring ?? false,\n    minSubstringLength: options?.minSubstringLength ?? 3,\n    maxAmbiguousMatches: options?.maxAmbiguousMatches ?? 5,\n  };\n\n  // Phase 1: Exact match in policy (fast path)\n  if (policyModuleIds.has(input)) {\n    return {\n      canonical: input,\n      confidence: 1.0,\n      original: input,\n      source: \"exact\",\n    };\n  }\n\n  // Phase 2: Alias table lookup\n  const table = aliasTable || loadAliasTable();\n  if (table.aliases[input]) {\n    const aliasEntry = table.aliases[input];\n    return {\n      canonical: aliasEntry.canonical,\n      confidence: aliasEntry.confidence,\n      original: input,\n      source: \"alias\",\n    };\n  }\n\n  // Phase 3: Fuzzy matching (handled by module_ids/validator, not here)\n  // This resolver returns confidence 0 and lets the validator handle fuzzy logic\n\n  // Phase 4: Substring matching (if enabled)\n  if (!opts.noSubstring) {\n    const substringMatches = findSubstringMatches(input, policyModuleIds, opts.minSubstringLength);\n\n    if (substringMatches.length === 1) {\n      // Unique substring match - confidence 0.9\n      return {\n        canonical: substringMatches[0],\n        confidence: 0.9,\n        original: input,\n        source: \"substring\",\n      };\n    } else if (substringMatches.length > 1) {\n      // Ambiguous - return with confidence 0 and mark as fuzzy\n      // The caller can check for substring matches if needed\n      return {\n        canonical: input,\n        confidence: 0,\n        original: input,\n        source: \"fuzzy\",\n      };\n    }\n  }\n\n  // No match found - return original with confidence 0\n  return {\n    canonical: input,\n    confidence: 0,\n    original: input,\n    source: \"fuzzy\",\n  };\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/aliases/types.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/atlas-frame.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'PolicyModule' is defined but never used. Allowed unused vars must match /^_/u.","line":9,"column":15,"nodeType":null,"messageId":"unusedVar","endLine":9,"endColumn":27}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Atlas Frame - Spatial neighborhood extraction from policy graph\n *\n * Computes the \"map page\" around a set of modules with fold radius.\n * Implements full policy graph traversal with N-hop neighborhood extraction.\n */\n\nimport { loadPolicy } from \"../policy/loader.js\";\nimport type { PolicyModule } from \"../types/policy.js\";\nimport { extractNeighborhood, generateCoordinates } from \"./graph.js\";\nexport interface AtlasFrame {\n  atlas_timestamp: string;\n  seed_modules: string[];\n  fold_radius: number;\n  modules: AtlasModule[];\n  edges: AtlasEdge[];\n  critical_rule: string;\n}\n\nexport interface AtlasModule {\n  id: string;\n  coords?: [number, number];\n  owns_paths?: string[];\n  owns_namespaces?: string[];\n  allowed_callers?: string[];\n  forbidden_callers?: string[];\n  feature_flags?: string[];\n  requires_permissions?: string[];\n  kill_patterns?: string[];\n  notes?: string;\n}\n\nexport interface AtlasEdge {\n  from: string;\n  to: string;\n  allowed: boolean;\n  reason?: string;\n}\n\n/**\n * Generate Atlas Frame for a set of seed modules\n *\n * Implements full fold radius algorithm with policy graph traversal:\n * - Loads policy graph from lexmap.policy.json\n * - Starts with seed modules\n * - Expands N hops via allowed_callers/forbidden_callers edges\n * - Includes full policy metadata for all discovered modules\n * - Returns complete neighborhood with edges and coordinates\n *\n * Algorithm:\n * 1. Load policy from lexmap.policy.json\n * 2. Use BFS to extract N-hop neighborhood from seed modules\n * 3. Generate 2D coordinates for visualization\n * 4. Include full PolicyModule metadata for each module\n * 5. Include all edges (allowed + forbidden) between modules\n *\n * @param seedModules - Module IDs from Frame.module_scope\n * @param foldRadius - How many hops to expand (default: 1)\n * @param policyPath - Optional custom policy path\n * @returns Atlas Frame with neighborhood context\n */\nexport function generateAtlasFrame(\n  seedModules: string[],\n  foldRadius: number = 1,\n  policyPath?: string\n): AtlasFrame {\n  const timestamp = new Date().toISOString();\n\n  // Load policy graph\n  const policy = loadPolicy(policyPath);\n\n  // Extract neighborhood using BFS traversal\n  const neighborhood = extractNeighborhood(policy, seedModules, foldRadius);\n\n  // Generate coordinates for visualization\n  const coordinates = generateCoordinates(neighborhood.modules, neighborhood.edges);\n\n  // Build AtlasModule objects with full metadata\n  const modules: AtlasModule[] = [];\n  for (const moduleId of neighborhood.modules) {\n    const policyModule = policy.modules[moduleId];\n\n    if (!policyModule) {\n      // Module not found in policy - include minimal data\n      modules.push({\n        id: moduleId,\n        coords: coordinates.get(moduleId),\n      });\n      continue;\n    }\n\n    // Include full policy metadata\n    const atlasModule: AtlasModule = {\n      id: moduleId,\n      coords: coordinates.get(moduleId),\n    };\n\n    // Copy all PolicyModule fields to AtlasModule\n    if (policyModule.owns_paths) {\n      atlasModule.owns_paths = policyModule.owns_paths;\n    }\n    if (policyModule.owns_namespaces) {\n      atlasModule.owns_namespaces = policyModule.owns_namespaces;\n    }\n    if (policyModule.allowed_callers) {\n      atlasModule.allowed_callers = policyModule.allowed_callers;\n    }\n    if (policyModule.forbidden_callers) {\n      atlasModule.forbidden_callers = policyModule.forbidden_callers;\n    }\n    if (policyModule.feature_flags) {\n      atlasModule.feature_flags = policyModule.feature_flags;\n    }\n    if (policyModule.requires_permissions) {\n      atlasModule.requires_permissions = policyModule.requires_permissions;\n    }\n    if (policyModule.kill_patterns) {\n      atlasModule.kill_patterns = policyModule.kill_patterns;\n    }\n    if (policyModule.notes) {\n      atlasModule.notes = policyModule.notes;\n    }\n\n    modules.push(atlasModule);\n  }\n\n  // Convert edges to AtlasEdge format\n  const edges: AtlasEdge[] = neighborhood.edges.map((edge) => ({\n    from: edge.from,\n    to: edge.to,\n    allowed: edge.type === \"allowed\",\n    reason: edge.type === \"forbidden\" ? \"forbidden_caller\" : undefined,\n  }));\n\n  return {\n    atlas_timestamp: timestamp,\n    seed_modules: seedModules,\n    fold_radius: foldRadius,\n    modules,\n    edges,\n    critical_rule: \"Every module name MUST match the IDs in lexmap.policy.json. No ad hoc naming.\",\n  };\n}\n\n/**\n * Format Atlas Frame for display in MCP response\n */\nexport function formatAtlasFrame(atlasFrame: AtlasFrame): string {\n  const { seed_modules, fold_radius, modules, edges } = atlasFrame;\n\n  let output = `\\nðŸ“Š Atlas Frame (fold radius: ${fold_radius})\\n`;\n  output += `ðŸŒ± Seed modules: ${seed_modules.join(\", \")}\\n`;\n  output += `ðŸ“¦ Total modules in neighborhood: ${modules.length}\\n`;\n\n  if (edges.length > 0) {\n    output += `\\nðŸ”— Edges:\\n`;\n    edges.forEach((edge) => {\n      const status = edge.allowed ? \"âœ… Allowed\" : \"ðŸš« Forbidden\";\n      output += `  ${edge.from} â†’ ${edge.to} [${status}]`;\n      if (edge.reason) {\n        output += ` - ${edge.reason}`;\n      }\n      output += \"\\n\";\n    });\n  }\n\n  return output;\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/auto-tune.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/cache.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'CacheKey' is defined but never used. Allowed unused vars must match /^_/u.","line":13,"column":11,"nodeType":null,"messageId":"unusedVar","endLine":13,"endColumn":19}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Atlas Frame Caching\n *\n * Caches computed Atlas Frames by (module_scope, radius) key to avoid\n * redundant graph traversals. Tracks cache hits/misses for performance monitoring.\n */\n\nimport type { AtlasFrame } from \"./types.js\";\n\n/**\n * Cache key for an Atlas Frame computation\n */\ninterface CacheKey {\n  moduleScope: string[]; // Sorted module IDs\n  radius: number;\n}\n\n/**\n * Cache statistics for monitoring\n */\nexport interface CacheStats {\n  hits: number;\n  misses: number;\n  evictions: number;\n  size: number;\n}\n\n/**\n * In-memory cache for Atlas Frames\n *\n * Uses LRU eviction when cache size exceeds maxSize.\n * Cache keys are based on sorted module_scope + radius for consistency.\n */\nexport class AtlasFrameCache {\n  private cache: Map<string, { frame: AtlasFrame; timestamp: number }> = new Map();\n  private accessOrder: string[] = []; // LRU tracking\n  private maxSize: number;\n  private stats: CacheStats = {\n    hits: 0,\n    misses: 0,\n    evictions: 0,\n    size: 0,\n  };\n\n  /**\n   * Create a new Atlas Frame cache\n   *\n   * @param maxSize - Maximum number of entries to cache (default: 100)\n   */\n  constructor(maxSize: number = 100) {\n    this.maxSize = maxSize;\n  }\n\n  /**\n   * Generate cache key from module scope and radius\n   *\n   * Normalizes module_scope by sorting to ensure consistent keys\n   * regardless of input order.\n   */\n  private getCacheKey(moduleScope: string[], radius: number): string {\n    const sortedModules = Array.from(moduleScope).sort();\n    return `${sortedModules.join(\",\")}:${radius}`;\n  }\n\n  /**\n   * Get cached Atlas Frame if available\n   *\n   * @param moduleScope - Module IDs to look up\n   * @param radius - Fold radius\n   * @returns Cached AtlasFrame or undefined if not found\n   */\n  get(moduleScope: string[], radius: number): AtlasFrame | undefined {\n    const key = this.getCacheKey(moduleScope, radius);\n    const entry = this.cache.get(key);\n\n    if (entry) {\n      // Cache hit - update access order\n      this.stats.hits++;\n      this.updateAccessOrder(key);\n      return entry.frame;\n    }\n\n    // Cache miss\n    this.stats.misses++;\n    return undefined;\n  }\n\n  /**\n   * Store Atlas Frame in cache\n   *\n   * @param moduleScope - Module IDs\n   * @param radius - Fold radius\n   * @param frame - Computed Atlas Frame\n   */\n  set(moduleScope: string[], radius: number, frame: AtlasFrame): void {\n    const key = this.getCacheKey(moduleScope, radius);\n\n    // Check if we need to evict entries\n    if (this.cache.size >= this.maxSize && !this.cache.has(key)) {\n      this.evictLRU();\n    }\n\n    // Store frame with timestamp\n    this.cache.set(key, {\n      frame,\n      timestamp: Date.now(),\n    });\n\n    // Update access order\n    this.updateAccessOrder(key);\n    this.stats.size = this.cache.size;\n  }\n\n  /**\n   * Update LRU access order\n   */\n  private updateAccessOrder(key: string): void {\n    // Remove key from current position\n    const index = this.accessOrder.indexOf(key);\n    if (index > -1) {\n      this.accessOrder.splice(index, 1);\n    }\n\n    // Add to end (most recently used)\n    this.accessOrder.push(key);\n  }\n\n  /**\n   * Evict least recently used entry\n   */\n  private evictLRU(): void {\n    if (this.accessOrder.length === 0) {\n      return;\n    }\n\n    const lruKey = this.accessOrder.shift()!;\n    this.cache.delete(lruKey);\n    this.stats.evictions++;\n    this.stats.size = this.cache.size;\n  }\n\n  /**\n   * Clear all cached entries\n   */\n  clear(): void {\n    this.cache.clear();\n    this.accessOrder = [];\n    this.stats.size = 0;\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats(): CacheStats {\n    return { ...this.stats };\n  }\n\n  /**\n   * Get cache hit rate\n   */\n  getHitRate(): number {\n    const total = this.stats.hits + this.stats.misses;\n    return total === 0 ? 0 : this.stats.hits / total;\n  }\n\n  /**\n   * Reset statistics (but keep cached entries)\n   */\n  resetStats(): void {\n    this.stats = {\n      hits: 0,\n      misses: 0,\n      evictions: 0,\n      size: this.cache.size,\n    };\n  }\n}\n\n/**\n * Global cache instance\n *\n * Shared across all Atlas Frame generation calls.\n * Can be disabled by setting enableCache = false.\n */\nlet globalCache: AtlasFrameCache | null = new AtlasFrameCache();\nlet enableCache = true;\n\n/**\n * Get the global cache instance\n */\nexport function getCache(): AtlasFrameCache | null {\n  return enableCache ? globalCache : null;\n}\n\n/**\n * Enable or disable caching globally\n */\nexport function setEnableCache(enabled: boolean): void {\n  enableCache = enabled;\n  if (!enabled && globalCache) {\n    globalCache.clear();\n  }\n}\n\n/**\n * Reset the global cache\n */\nexport function resetCache(): void {\n  if (globalCache) {\n    globalCache.clear();\n    globalCache.resetStats();\n  }\n}\n\n/**\n * Get global cache statistics\n */\nexport function getCacheStats(): CacheStats {\n  return globalCache\n    ? globalCache.getStats()\n    : {\n        hits: 0,\n        misses: 0,\n        evictions: 0,\n        size: 0,\n      };\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/demo.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/fold-radius.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/graph.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/perf-test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/queue.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/rebuild.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/types.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/validate.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'AtlasNode' is defined but never used. Allowed unused vars must match /^_/u.","line":10,"column":22,"nodeType":null,"messageId":"unusedVar","endLine":10,"endColumn":31},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'AtlasEdge' is defined but never used. Allowed unused vars must match /^_/u.","line":10,"column":33,"nodeType":null,"messageId":"unusedVar","endLine":10,"endColumn":42}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Atlas Integrity Validation\n *\n * Validates the structural integrity of Atlas graphs to ensure:\n * - No orphaned nodes (all nodes reachable from at least one other node or are roots)\n * - No dangling edges (all edge endpoints exist in node set)\n * - Edge weights within valid range [0, 1]\n */\n\nimport type { Atlas, AtlasNode, AtlasEdge } from \"./rebuild.js\";\n\n/**\n * Validation result\n */\nexport interface ValidationResult {\n  valid: boolean;\n  errors: string[];\n  warnings: string[];\n}\n\n/**\n * Validate Atlas integrity\n *\n * Performs comprehensive validation checks:\n * 1. No dangling edges (all edge endpoints exist in node set)\n * 2. No orphaned nodes (every node is reachable from at least one other node, or is a root)\n * 3. Edge weights within valid range [0, 1]\n *\n * @param atlas - Atlas graph to validate\n * @returns Validation result with errors and warnings\n */\nexport function validateAtlas(atlas: Atlas): ValidationResult {\n  const errors: string[] = [];\n  const warnings: string[] = [];\n\n  // Build node ID set for quick lookup\n  const nodeIds = new Set(atlas.nodes.map((n) => n.frameId));\n\n  // Check for dangling edges\n  for (const edge of atlas.edges) {\n    if (!nodeIds.has(edge.from)) {\n      errors.push(`Dangling edge: source node '${edge.from}' does not exist`);\n    }\n    if (!nodeIds.has(edge.to)) {\n      errors.push(`Dangling edge: target node '${edge.to}' does not exist`);\n    }\n  }\n\n  // Check edge weight constraints\n  for (const edge of atlas.edges) {\n    if (edge.weight < 0 || edge.weight > 1) {\n      errors.push(\n        `Edge weight out of range [0, 1]: ${edge.from} â†’ ${edge.to} (weight: ${edge.weight})`\n      );\n    }\n  }\n\n  // Check for orphaned nodes\n  const connectedNodes = new Set<string>();\n\n  // Collect all nodes that have at least one edge (incoming or outgoing)\n  for (const edge of atlas.edges) {\n    connectedNodes.add(edge.from);\n    connectedNodes.add(edge.to);\n  }\n\n  // Find orphaned nodes (nodes with no edges at all)\n  const orphanedNodes: string[] = [];\n  for (const node of atlas.nodes) {\n    if (!connectedNodes.has(node.frameId)) {\n      orphanedNodes.push(node.frameId);\n    }\n  }\n\n  // Orphaned nodes are warnings, not errors (they may be valid isolated frames)\n  if (orphanedNodes.length > 0) {\n    warnings.push(\n      `${orphanedNodes.length} orphaned node(s) with no connections: ${orphanedNodes.slice(0, 5).join(\", \")}${orphanedNodes.length > 5 ? \"...\" : \"\"}`\n    );\n  }\n\n  // Check metadata consistency\n  if (atlas.metadata.frameCount !== atlas.nodes.length) {\n    errors.push(\n      `Metadata frameCount (${atlas.metadata.frameCount}) does not match actual node count (${atlas.nodes.length})`\n    );\n  }\n\n  if (atlas.metadata.edgeCount !== atlas.edges.length) {\n    errors.push(\n      `Metadata edgeCount (${atlas.metadata.edgeCount}) does not match actual edge count (${atlas.edges.length})`\n    );\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n    warnings,\n  };\n}\n\n/**\n * Check if all nodes in Atlas are reachable from at least one root node\n *\n * A root node is a node with no incoming edges (only outgoing edges or isolated).\n * This performs a graph traversal to ensure no nodes are unreachable from the root set.\n *\n * @param atlas - Atlas graph to check\n * @returns True if all nodes are reachable from roots, false otherwise\n */\nexport function checkReachability(atlas: Atlas): boolean {\n  // Build adjacency list for graph traversal\n  const adjacency = new Map<string, Set<string>>();\n  const incomingEdges = new Map<string, number>();\n\n  // Initialize\n  for (const node of atlas.nodes) {\n    adjacency.set(node.frameId, new Set());\n    incomingEdges.set(node.frameId, 0);\n  }\n\n  // Build adjacency list and count incoming edges\n  for (const edge of atlas.edges) {\n    adjacency.get(edge.from)?.add(edge.to);\n    incomingEdges.set(edge.to, (incomingEdges.get(edge.to) || 0) + 1);\n  }\n\n  // Find root nodes (nodes with no incoming edges)\n  const roots: string[] = [];\n  for (const [nodeId, incomingCount] of incomingEdges.entries()) {\n    if (incomingCount === 0) {\n      roots.push(nodeId);\n    }\n  }\n\n  // If no nodes, trivially reachable\n  if (atlas.nodes.length === 0) return true;\n\n  // If no roots but we have nodes, all nodes must be in cycles or isolated\n  // This is still considered \"reachable\" in the sense that they form valid structures\n  if (roots.length === 0) return true;\n\n  // BFS from all roots to find reachable nodes\n  const reachable = new Set<string>();\n  const queue: string[] = [...roots];\n\n  while (queue.length > 0) {\n    const current = queue.shift()!;\n    if (reachable.has(current)) continue;\n\n    reachable.add(current);\n\n    const neighbors = adjacency.get(current);\n    if (neighbors) {\n      for (const neighbor of neighbors) {\n        if (!reachable.has(neighbor)) {\n          queue.push(neighbor);\n        }\n      }\n    }\n  }\n\n  // All nodes should be reachable from roots\n  return reachable.size === atlas.nodes.length;\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/atlas/verify-format.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/cli/check.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":117,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":117,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2797,2800],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2797,2800],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * CLI Command: lex check\n *\n * Wrapper around policy/check for user-friendly policy violation reporting.\n */\n\nimport { readFileSync, existsSync } from \"fs\";\nimport { resolve } from \"path\";\nimport * as output from \"./output.js\";\n\nexport interface CheckOptions {\n  json?: boolean;\n  ticket?: string;\n}\n\ninterface PolicyModule {\n  owns_namespaces?: string[];\n  owns_paths?: string[];\n  exposes?: string[];\n  allowed_callers?: string[];\n  forbidden_callers?: string[];\n  feature_flags?: string[];\n  requires_permissions?: string[];\n  kill_patterns?: string[];\n}\n\ninterface Policy {\n  modules: Record<string, PolicyModule>;\n  global_kill_patterns?: Array<{\n    pattern: string;\n    description: string;\n  }>;\n}\n\ninterface FileData {\n  path: string;\n  module_scope?: string;\n  declarations: Array<{ type: string; name: string; namespace?: string }>;\n  imports: Array<{ from: string; type: string }>;\n  feature_flags: string[];\n  permissions: string[];\n  warnings: string[];\n}\n\ninterface ModuleEdge {\n  from_module: string;\n  to_module: string;\n  from_file: string;\n  import_statement: string;\n}\n\ninterface MergedScannerOutput {\n  sources: string[];\n  files: FileData[];\n  module_edges?: ModuleEdge[];\n}\n\ninterface Violation {\n  file: string;\n  module: string;\n  type: \"forbidden_caller\" | \"kill_pattern\" | \"missing_permission\";\n  message: string;\n  details: string;\n}\n\n/**\n * Execute the 'lex check' command\n * Checks scanner output against policy and reports violations\n */\nexport async function check(\n  mergedJsonPath: string,\n  policyJsonPath: string,\n  options: CheckOptions = {}\n): Promise<void> {\n  try {\n    // Validate file paths\n    const resolvedMergedPath = resolve(mergedJsonPath);\n    const resolvedPolicyPath = resolve(policyJsonPath);\n\n    if (!existsSync(resolvedMergedPath)) {\n      output.error(`\\nâŒ Scanner output not found: ${mergedJsonPath}\\n`);\n      process.exit(2);\n    }\n\n    if (!existsSync(resolvedPolicyPath)) {\n      output.error(`\\nâŒ Policy file not found: ${policyJsonPath}\\n`);\n      process.exit(2);\n    }\n\n    // Load files\n    const scannerContent = readFileSync(resolvedMergedPath, \"utf-8\");\n    const scannerOutput: MergedScannerOutput = JSON.parse(scannerContent);\n\n    const policyContent = readFileSync(resolvedPolicyPath, \"utf-8\");\n    const policy: Policy = JSON.parse(policyContent);\n\n    // Run policy check\n    const violations = checkPolicy(scannerOutput, policy);\n\n    // Output results\n    if (options.json) {\n      output.json({\n        violations,\n        count: violations.length,\n        ticket: options.ticket,\n      });\n    } else {\n      displayViolations(violations, options.ticket);\n    }\n\n    // Exit with appropriate code\n    if (violations.length > 0) {\n      process.exit(1);\n    } else {\n      process.exit(0);\n    }\n  } catch (error: any) {\n    output.error(`\\nâŒ Error: ${error.message}\\n`);\n    process.exit(2);\n  }\n}\n\n/**\n * Check scanner output against policy\n */\nfunction checkPolicy(scannerOutput: MergedScannerOutput, policy: Policy): Violation[] {\n  const violations: Violation[] = [];\n\n  for (const file of scannerOutput.files) {\n    // Use module_scope from scanner if available, otherwise resolve\n    const moduleId = file.module_scope || resolveFileToModule(file.path, policy);\n\n    if (!moduleId) {\n      // File doesn't belong to any known module - skip\n      continue;\n    }\n\n    // Check imports against forbidden_callers\n    for (const imp of file.imports) {\n      const importedModuleId = resolveImportToModule(imp.from, policy);\n\n      if (importedModuleId) {\n        const importedModule = policy.modules[importedModuleId];\n\n        if (importedModule && importedModule.forbidden_callers) {\n          // Check if current module matches any forbidden_caller pattern\n          for (const forbidden of importedModule.forbidden_callers) {\n            if (matchPattern(moduleId, forbidden)) {\n              violations.push({\n                file: file.path,\n                module: moduleId,\n                type: \"forbidden_caller\",\n                message: `Module ${moduleId} imports ${importedModuleId} but is forbidden`,\n                details: `Policy forbids: ${forbidden}`,\n              });\n            }\n          }\n        }\n      }\n    }\n\n    // Check for kill patterns\n    for (const warning of file.warnings) {\n      violations.push({\n        file: file.path,\n        module: moduleId,\n        type: \"kill_pattern\",\n        message: `Kill pattern detected: ${warning}`,\n        details: \"\",\n      });\n    }\n  }\n\n  // Check module_edges if available\n  if (scannerOutput.module_edges) {\n    for (const edge of scannerOutput.module_edges) {\n      const toModule = policy.modules[edge.to_module];\n\n      if (toModule && toModule.forbidden_callers) {\n        for (const forbidden of toModule.forbidden_callers) {\n          if (matchPattern(edge.from_module, forbidden)) {\n            violations.push({\n              file: edge.from_file,\n              module: edge.from_module,\n              type: \"forbidden_caller\",\n              message: `Module ${edge.from_module} calls ${edge.to_module} but is forbidden`,\n              details: `Import: ${edge.import_statement}, Policy forbids: ${forbidden}`,\n            });\n          }\n        }\n      }\n    }\n  }\n\n  return violations;\n}\n\n/**\n * Resolve file path to module ID\n */\nfunction resolveFileToModule(filePath: string, policy: Policy): string | null {\n  for (const [moduleId, module] of Object.entries(policy.modules)) {\n    if (module.owns_paths) {\n      for (const pathPattern of module.owns_paths) {\n        if (matchPath(filePath, pathPattern)) {\n          return moduleId;\n        }\n      }\n    }\n  }\n  return null;\n}\n\n/**\n * Resolve import path to module ID\n */\nfunction resolveImportToModule(importPath: string, policy: Policy): string | null {\n  // Try exact module ID match first (for test compatibility)\n  if (policy.modules[importPath]) {\n    return importPath;\n  }\n\n  // Try to match by namespace first (PHP style)\n  for (const [moduleId, module] of Object.entries(policy.modules)) {\n    if (module.owns_namespaces) {\n      for (const namespace of module.owns_namespaces) {\n        if (importPath.startsWith(namespace)) {\n          return moduleId;\n        }\n      }\n    }\n  }\n\n  // Try to match by file path pattern (TypeScript/JS style)\n  for (const [moduleId, module] of Object.entries(policy.modules)) {\n    if (module.owns_paths) {\n      for (const pathPattern of module.owns_paths) {\n        if (matchPath(importPath, pathPattern)) {\n          return moduleId;\n        }\n      }\n    }\n  }\n\n  return null;\n}\n\n/**\n * Match file path against pattern with glob support\n */\nfunction matchPath(filePath: string, pattern: string): boolean {\n  const regexPattern = pattern.replace(/\\*\\*/g, \".*\").replace(/\\*/g, \"[^/]*\").replace(/\\//g, \"\\\\/\");\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(filePath);\n}\n\n/**\n * Match value against pattern\n */\nfunction matchPattern(value: string, pattern: string): boolean {\n  const regexPattern = pattern.replace(/\\*\\*/g, \".*\").replace(/\\*/g, \"[^/]*\");\n  const regex = new RegExp(`^${regexPattern}$`);\n  return regex.test(value);\n}\n\n/**\n * Display violations in user-friendly format\n */\nfunction displayViolations(violations: Violation[], ticket?: string): void {\n  if (violations.length === 0) {\n    output.success(\"\\nâœ… No policy violations found\\n\");\n    return;\n  }\n\n  output.error(\n    `\\nâŒ Found ${violations.length} policy violation(s)${ticket ? ` (ticket: ${ticket})` : \"\"}:\\n`\n  );\n\n  for (let i = 0; i < violations.length; i++) {\n    const v = violations[i];\n    output.info(`${i + 1}. ${v.file}`);\n    output.info(`   Module: ${v.module}`);\n    output.info(`   Type: ${v.type}`);\n    output.info(`   ${v.message}`);\n    if (v.details) {\n      output.info(`   ${v.details}`);\n    }\n    output.info(\"\");\n  }\n\n  output.info(`Exit code: 1 (violations found)\\n`);\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/cli/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/cli/init.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/cli/lex.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/cli/output.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/cli/output.types.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/cli/recall.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":101,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":101,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3089,3092],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3089,3092],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":199,"column":15,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":199,"endColumn":18,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[6257,6260],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[6257,6260],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * CLI Command: lex recall\n *\n * Searches Frames via query, returns Frame + Atlas Frame with pretty output.\n */\n\nimport type { Frame } from \"../types/frame.js\";\nimport { getDb, searchFrames, getFramesByJira, getFrameById } from \"../../memory/store/index.js\";\nimport { loadPolicy } from \"../policy/loader.js\";\nimport {\n  computeFoldRadius,\n  autoTuneRadius,\n  estimateTokens,\n  getCacheStats,\n} from \"../atlas/index.js\";\nimport { output, json } from \"./output.js\";\n\nexport interface RecallOptions {\n  json?: boolean;\n  foldRadius?: number;\n  autoRadius?: boolean;\n  maxTokens?: number;\n  showCacheStats?: boolean;\n}\n\n/**\n * Execute the 'lex recall' command\n * Searches for Frames and displays results with Atlas Frame context\n */\nexport async function recall(query: string, options: RecallOptions = {}): Promise<void> {\n  try {\n    const db = getDb();\n    let frames: Frame[] = [];\n    let searchHint: string | undefined;\n\n    // Try different search strategies\n    // 1. Try as Frame ID (exact match)\n    const frameById = getFrameById(db, query);\n    if (frameById) {\n      frames = [frameById];\n    } else {\n      // 2. Try as Jira ticket (exact match)\n      const framesByJira = getFramesByJira(db, query);\n      if (framesByJira.length > 0) {\n        frames = framesByJira;\n      } else {\n        // 3. Try as reference point (fuzzy search)\n        const searchResult = searchFrames(db, query);\n        frames = searchResult.frames;\n        searchHint = searchResult.hint;\n      }\n    }\n\n    if (frames.length === 0) {\n      // Print hint to stderr if FTS5 syntax error occurred\n      if (searchHint) {\n        output.error(`\\nâš ï¸  ${searchHint}\\n`);\n      }\n      output.info(`\\nâŒ No frames found matching: \"${query}\"\\n`);\n      process.exit(1);\n    }\n\n    // Output results\n    if (options.json) {\n      // JSON output includes frames and their Atlas Frames\n      const results = [];\n      for (const frame of frames) {\n        const atlasResult = await generateAtlasFrameWithAutoTune(frame, options);\n        results.push({\n          frame,\n          atlasFrame: atlasResult.atlasFrame,\n          foldRadius: atlasResult.actualRadius,\n          autoTuned: atlasResult.autoTuned,\n          tokens: atlasResult.tokens,\n        });\n      }\n      json(results);\n    } else {\n      // Pretty print results\n      for (let i = 0; i < frames.length; i++) {\n        if (i > 0) {\n          output.info(\"\\n\" + \"â”€\".repeat(80) + \"\\n\");\n        }\n        await displayFrame(frames[i], options);\n      }\n\n      // Show cache stats if requested\n      if (options.showCacheStats) {\n        const stats = getCacheStats();\n        const total = stats.hits + stats.misses;\n        const hitRate = total === 0 ? 0 : (stats.hits / total) * 100;\n\n        output.info(`\\nðŸ“Š Cache Statistics:`);\n        output.info(`   Hits: ${stats.hits}`);\n        output.info(`   Misses: ${stats.misses}`);\n        output.info(`   Hit Rate: ${hitRate.toFixed(1)}%`);\n        output.info(`   Cache Size: ${stats.size} entries`);\n        output.info(`   Evictions: ${stats.evictions}`);\n      }\n    }\n  } catch (error: any) {\n    output.error(`\\nâŒ Error: ${error.message}\\n`);\n    process.exit(2);\n  }\n}\n\n/**\n * Display a Frame with Atlas Frame context\n */\nasync function displayFrame(frame: Frame, options: RecallOptions): Promise<void> {\n  output.info(`\\nðŸ“‹ Frame: ${frame.jira || frame.id}`);\n  output.info(`   Timestamp: ${new Date(frame.timestamp).toLocaleString()}`);\n  output.info(`   Branch: ${frame.branch}`);\n  output.info(`\\n   Reference: \"${frame.reference_point}\"`);\n  output.info(`\\n   Summary: ${frame.summary_caption}`);\n\n  output.info(`\\n   Next action: ${frame.status_snapshot.next_action}`);\n\n  if (frame.status_snapshot.blockers && frame.status_snapshot.blockers.length > 0) {\n    output.info(`\\n   Blockers:`);\n    for (const blocker of frame.status_snapshot.blockers) {\n      output.info(`     â€¢ ${blocker}`);\n    }\n  }\n\n  if (frame.status_snapshot.merge_blockers && frame.status_snapshot.merge_blockers.length > 0) {\n    output.info(`\\n   Merge blockers:`);\n    for (const blocker of frame.status_snapshot.merge_blockers) {\n      output.info(`     â€¢ ${blocker}`);\n    }\n  }\n\n  if (frame.status_snapshot.tests_failing && frame.status_snapshot.tests_failing.length > 0) {\n    output.info(`\\n   Tests failing:`);\n    for (const test of frame.status_snapshot.tests_failing) {\n      output.info(`     â€¢ ${test}`);\n    }\n  }\n\n  if (frame.keywords && frame.keywords.length > 0) {\n    output.info(`\\n   Keywords: ${frame.keywords.join(\", \")}`);\n  }\n\n  // Generate Atlas Frame with auto-tuning if enabled\n  const atlasResult = await generateAtlasFrameWithAutoTune(frame, options);\n\n  if (atlasResult.autoTuned) {\n    output.info(\n      `\\nâš™ï¸  Auto-tuned radius: ${atlasResult.requestedRadius} â†’ ${atlasResult.actualRadius} (${atlasResult.tokens} tokens)`\n    );\n  }\n\n  const atlasFrame = atlasResult.atlasFrame;\n  const foldRadius = atlasResult.actualRadius;\n\n  output.info(`\\nðŸ—ºï¸  Atlas Frame (fold radius ${foldRadius}):`);\n  output.info(`\\n   Modules in scope:`);\n  for (const module of frame.module_scope) {\n    output.info(`     â€¢ ${module}`);\n  }\n\n  if (atlasFrame) {\n    output.info(`\\n   Neighborhood (${atlasFrame.modules.length} modules within radius):`);\n\n    // Just list all modules in the atlas\n    for (const module of atlasFrame.modules) {\n      output.info(`     â€¢ ${module.id}`);\n    }\n\n    // Show edges if any\n    if (atlasFrame.edges && atlasFrame.edges.length > 0) {\n      output.info(`\\n   Edges (${atlasFrame.edges.length}):`);\n      for (const edge of atlasFrame.edges.slice(0, 5)) {\n        // Show max 5 edges\n        const symbol = edge.reason === \"allowed\" ? \"âœ“\" : \"âœ—\";\n        output.info(`     ${symbol} ${edge.from} â†’ ${edge.to} (${edge.reason})`);\n      }\n      if (atlasFrame.edges.length > 5) {\n        output.info(`     ... and ${atlasFrame.edges.length - 5} more`);\n      }\n    }\n\n    // Show token estimate\n    if (options.autoRadius || options.maxTokens) {\n      output.info(`\\n   Token estimate: ${atlasResult.tokens} tokens`);\n    }\n  }\n\n  output.info(\"\");\n}\n\n/**\n * Generate Atlas Frame with auto-tuning support\n */\nasync function generateAtlasFrameWithAutoTune(\n  frame: Frame,\n  options: RecallOptions\n): Promise<{\n  atlasFrame: any;\n  actualRadius: number;\n  requestedRadius: number;\n  tokens: number;\n  autoTuned: boolean;\n}> {\n  try {\n    const policy = loadPolicy();\n\n    // For now, use all modules in scope as seeds\n    if (frame.module_scope.length === 0) {\n      return {\n        atlasFrame: null,\n        actualRadius: 0,\n        requestedRadius: options.foldRadius || 1,\n        tokens: 0,\n        autoTuned: false,\n      };\n    }\n\n    const requestedRadius = options.foldRadius || 1;\n\n    // Auto-tune radius if enabled\n    if (options.autoRadius && options.maxTokens) {\n      const result = autoTuneRadius(\n        (radius) => computeFoldRadius(frame.module_scope, radius, policy),\n        requestedRadius,\n        options.maxTokens,\n        (oldRadius, newRadius, tokens, limit) => {\n          // Only log adjustments when not in JSON mode\n          if (!options.json) {\n            output.info(\n              `\\nâš™ï¸  Auto-tuning: radius ${oldRadius} â†’ ${newRadius} (${tokens} tokens exceeded ${limit} limit)`\n            );\n          }\n        }\n      );\n\n      return {\n        atlasFrame: result.atlasFrame,\n        actualRadius: result.radiusUsed,\n        requestedRadius,\n        tokens: result.tokensUsed,\n        autoTuned: result.radiusUsed !== requestedRadius,\n      };\n    }\n\n    // Normal generation without auto-tuning\n    const atlasFrame = computeFoldRadius(frame.module_scope, requestedRadius, policy);\n    const tokens = estimateTokens(atlasFrame);\n\n    return {\n      atlasFrame,\n      actualRadius: requestedRadius,\n      requestedRadius,\n      tokens,\n      autoTuned: false,\n    };\n  } catch (error) {\n    // If Atlas Frame generation fails, continue without it\n    output.warn(\"Could not generate Atlas Frame\", undefined, \"ATLAS_GEN_FAILED\", String(error));\n    return {\n      atlasFrame: null,\n      actualRadius: 0,\n      requestedRadius: options.foldRadius || 1,\n      tokens: 0,\n      autoTuned: false,\n    };\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/cli/remember.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":102,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":102,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3278,3281],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3278,3281],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":115,"column":20,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":115,"endColumn":23,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3557,3560],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3557,3560],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * CLI Command: lex remember\n *\n * Prompts user for Frame metadata, validates module_scope, creates Frame.\n */\n\nimport inquirer from \"inquirer\";\nimport { v4 as uuidv4 } from \"uuid\";\nimport type { Frame } from \"../types/frame.js\";\nimport { validateModuleIds } from \"../module_ids/index.js\";\nimport { loadPolicy } from \"../policy/loader.js\";\nimport { getDb, saveFrame } from \"../../memory/store/index.js\";\nimport { getCurrentBranch } from \"../git/branch.js\";\nimport * as output from \"./output.js\";\n\nexport interface RememberOptions {\n  jira?: string;\n  referencePoint?: string;\n  summary?: string;\n  next?: string;\n  modules?: string[];\n  blockers?: string[];\n  mergeBlockers?: string[];\n  testsFailing?: string[];\n  keywords?: string[];\n  featureFlags?: string[];\n  permissions?: string[];\n  interactive?: boolean;\n  json?: boolean;\n  strict?: boolean;\n  noSubstring?: boolean;\n}\n\n/**\n * Execute the 'lex remember' command\n * Creates a new Frame with user input\n */\nexport async function remember(options: RememberOptions = {}): Promise<void> {\n  try {\n    // Get current git branch\n    const branch = await getCurrentBranch();\n\n    // If interactive mode or missing required fields, prompt for input\n    const answers =\n      options.interactive || !options.summary || !options.next || !options.modules\n        ? await promptForFrameData(options, branch)\n        : options;\n\n    // Resolve and validate module_scope against policy (THE CRITICAL RULE + auto-correction)\n    const policy = loadPolicy();\n\n    const validationResult = await validateModuleIds(answers.modules || [], policy);\n\n    if (!validationResult.valid) {\n      output.error(`\\nâŒ Module validation failed:\\n`);\n      for (const error of validationResult.errors || []) {\n        output.error(`  - ${error.message}`);\n      }\n      output.error(\"\");\n      process.exit(1);\n    }\n\n    // Use canonical (resolved) module IDs from validation\n    const resolvedModules = validationResult.canonical || []; // Build Frame object\n    const frame: Frame = {\n      id: uuidv4(),\n      timestamp: new Date().toISOString(),\n      branch: branch,\n      module_scope: resolvedModules, // Use resolved (potentially auto-corrected) module IDs\n      summary_caption: answers.summary || \"\",\n      reference_point: answers.referencePoint || \"\",\n      status_snapshot: {\n        next_action: answers.next || \"\",\n        blockers: answers.blockers,\n        merge_blockers: answers.mergeBlockers,\n        tests_failing: answers.testsFailing,\n      },\n      jira: answers.jira,\n      keywords: answers.keywords,\n      feature_flags: answers.featureFlags,\n      permissions: answers.permissions,\n    };\n\n    // Save Frame to database\n    const db = getDb();\n    saveFrame(db, frame);\n\n    // Output result\n    if (options.json) {\n      output.json({ id: frame.id, timestamp: frame.timestamp });\n    } else {\n      output.success(\"\\nâœ… Frame created successfully!\\n\");\n      output.info(`Frame ID: ${frame.id}`);\n      output.info(`Timestamp: ${frame.timestamp}`);\n      output.info(`Branch: ${frame.branch}`);\n      if (frame.jira) {\n        output.info(`Jira: ${frame.jira}`);\n      }\n      output.info(`Reference: ${frame.reference_point}`);\n      output.info(`Modules: ${frame.module_scope.join(\", \")}`);\n    }\n  } catch (error: any) {\n    output.error(`\\nâŒ Error: ${error.message}\\n`);\n    process.exit(2);\n  }\n}\n\n/**\n * Prompt user for Frame metadata interactively\n */\nasync function promptForFrameData(\n  options: RememberOptions,\n  _currentBranch: string\n): Promise<RememberOptions> {\n  const questions: any[] = [];\n\n  if (!options.jira) {\n    questions.push({\n      type: \"input\",\n      name: \"jira\",\n      message: \"Jira ticket (optional):\",\n    });\n  }\n\n  if (!options.referencePoint) {\n    questions.push({\n      type: \"input\",\n      name: \"referencePoint\",\n      message: \"Reference point (memorable phrase):\",\n      validate: (input: string) => input.trim().length > 0 || \"Reference point is required\",\n    });\n  }\n\n  if (!options.summary) {\n    questions.push({\n      type: \"input\",\n      name: \"summary\",\n      message: \"Summary (one-line description):\",\n      validate: (input: string) => input.trim().length > 0 || \"Summary is required\",\n    });\n  }\n\n  if (!options.next) {\n    questions.push({\n      type: \"input\",\n      name: \"next\",\n      message: \"Next action:\",\n      validate: (input: string) => input.trim().length > 0 || \"Next action is required\",\n    });\n  }\n\n  if (!options.modules) {\n    questions.push({\n      type: \"input\",\n      name: \"modules\",\n      message: \"Module scope (comma-separated):\",\n      filter: (input: string) =>\n        input\n          .split(\",\")\n          .map((m) => m.trim())\n          .filter((m) => m.length > 0),\n      validate: (input: string[]) => input.length > 0 || \"At least one module is required\",\n    });\n  }\n\n  if (!options.blockers) {\n    questions.push({\n      type: \"input\",\n      name: \"blockers\",\n      message: \"Blockers (comma-separated, optional):\",\n      filter: (input: string) => {\n        if (!input.trim()) return undefined;\n        return input\n          .split(\",\")\n          .map((b) => b.trim())\n          .filter((b) => b.length > 0);\n      },\n    });\n  }\n\n  if (!options.mergeBlockers) {\n    questions.push({\n      type: \"input\",\n      name: \"mergeBlockers\",\n      message: \"Merge blockers (comma-separated, optional):\",\n      filter: (input: string) => {\n        if (!input.trim()) return undefined;\n        return input\n          .split(\",\")\n          .map((b) => b.trim())\n          .filter((b) => b.length > 0);\n      },\n    });\n  }\n\n  const answers = questions.length > 0 ? await inquirer.prompt(questions) : {};\n\n  // Merge with provided options (provided options take precedence)\n  return {\n    ...answers,\n    ...options,\n  };\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/cli/timeline.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":116,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":116,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3227,3230],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3227,3230],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * CLI Command: lex timeline\n *\n * Display a visual timeline showing Frame evolution for a ticket or branch.\n */\n\nimport type { Frame } from \"../types/frame.js\";\nimport { getDb, getFramesByJira, getFramesByBranch } from \"../../memory/store/index.js\";\nimport {\n  buildTimeline,\n  filterTimeline,\n  renderTimelineText,\n  renderModuleScopeEvolution,\n  renderBlockerTracking,\n  renderTimelineJSON,\n  renderTimelineHTML,\n  type TimelineOptions,\n} from \"../../memory/renderer/timeline.js\";\nimport { writeFileSync } from \"fs\";\nimport * as output from \"./output.js\";\n\nexport interface TimelineCommandOptions {\n  since?: string;\n  until?: string;\n  format?: \"text\" | \"json\" | \"html\";\n  output?: string;\n  json?: boolean;\n}\n\n/**\n * Execute the 'lex timeline' command\n * Shows Frame evolution for a ticket or branch\n */\nexport async function timeline(\n  ticketOrBranch: string,\n  options: TimelineCommandOptions = {}\n): Promise<void> {\n  try {\n    const db = getDb();\n    let frames: Frame[] = [];\n    let title: string;\n\n    // Try to find frames by Jira ticket first, then by branch\n    const framesByJira = getFramesByJira(db, ticketOrBranch);\n    if (framesByJira.length > 0) {\n      frames = framesByJira;\n      title = `${ticketOrBranch}: Timeline`;\n    } else {\n      const framesByBranch = getFramesByBranch(db, ticketOrBranch);\n      if (framesByBranch.length > 0) {\n        frames = framesByBranch;\n        title = `Branch ${ticketOrBranch}: Timeline`;\n      } else {\n        // No frames found\n        title = `${ticketOrBranch}: Timeline`;\n      }\n    }\n\n    if (frames.length === 0) {\n      output.error(`\\nâŒ No frames found for: \"${ticketOrBranch}\"\\n`);\n      output.info(\"Try using a Jira ticket ID (e.g., TICKET-123) or a branch name.\\n\");\n      process.exit(1);\n    }\n\n    // Build timeline\n    let timelineData = buildTimeline(frames);\n\n    // Apply filters\n    const timelineOptions: TimelineOptions = {\n      format: options.format || \"text\",\n    };\n\n    if (options.since) {\n      timelineOptions.since = new Date(options.since);\n    }\n\n    if (options.until) {\n      timelineOptions.until = new Date(options.until);\n    }\n\n    if (timelineOptions.since || timelineOptions.until) {\n      timelineData = filterTimeline(timelineData, timelineOptions);\n\n      if (timelineData.length === 0) {\n        output.error(`\\nâŒ No frames found in the specified date range.\\n`);\n        process.exit(1);\n      }\n    }\n\n    // Render timeline based on format\n    const format = options.format || (options.json ? \"json\" : \"text\");\n    let result: string;\n\n    switch (format) {\n      case \"json\":\n        result = renderTimelineJSON(timelineData);\n        break;\n      case \"html\":\n        result = renderTimelineHTML(timelineData, title);\n        break;\n      case \"text\":\n      default:\n        result = renderTimelineText(timelineData, title);\n        result += renderModuleScopeEvolution(timelineData);\n        result += renderBlockerTracking(timelineData);\n        break;\n    }\n\n    // Write to file or stdout\n    if (options.output) {\n      writeFileSync(options.output, result, \"utf-8\");\n      output.success(`\\nâœ… Timeline written to: ${options.output}\\n`);\n    } else {\n      output.raw(result);\n    }\n  } catch (error: any) {\n    output.error(`\\nâŒ Error: ${error.message}\\n`);\n    process.exit(2);\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/config/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/git/branch.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":60,"column":12,"nodeType":null,"messageId":"unusedVar","endLine":60,"endColumn":17}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Git branch detection utility\n *\n * Provides auto-detection of current git branch with fallback handling\n * for edge cases like detached HEAD and non-git repositories.\n */\n\nimport { execSync } from \"child_process\";\n\n/**\n * Cache for the current branch to avoid repeated git calls\n */\nlet branchCache: string | null = null;\n\n/**\n * Get the current git branch name\n *\n * @returns Current git branch name, or fallback value for edge cases\n *\n * Behavior:\n * - Returns current branch name in normal git repository\n * - Returns \"detached\" when HEAD is detached\n * - Returns \"unknown\" when not in a git repository\n * - Respects LEX_DEFAULT_BRANCH environment variable as override\n * - Caches result for performance\n *\n * @example\n * ```ts\n * const branch = getCurrentBranch();\n * console.log(`Current branch: ${branch}`);\n * ```\n */\nexport function getCurrentBranch(): string {\n  // Check for environment variable override first\n  if (process.env.LEX_DEFAULT_BRANCH) {\n    return process.env.LEX_DEFAULT_BRANCH;\n  }\n\n  // Return cached value if available\n  if (branchCache !== null) {\n    return branchCache;\n  }\n\n  try {\n    // Execute git command to get current branch\n    const result = execSync(\"git rev-parse --abbrev-ref HEAD\", {\n      encoding: \"utf-8\",\n      stdio: [\"pipe\", \"pipe\", \"pipe\"],\n    }).trim();\n\n    // Check for detached HEAD state\n    if (result === \"HEAD\") {\n      branchCache = \"detached\";\n      return branchCache;\n    }\n\n    // Cache and return the branch name\n    branchCache = result;\n    return branchCache;\n  } catch (error) {\n    // Not a git repository or git command failed\n    branchCache = \"unknown\";\n    return branchCache;\n  }\n}\n\n/**\n * Clear the branch cache\n *\n * Useful for testing or when the branch might have changed\n * (e.g., after a checkout operation)\n */\nexport function clearBranchCache(): void {\n  branchCache = null;\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/logger/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/module_ids/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/module_ids/validator.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/policy/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/policy/loader.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":144,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":144,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4338,4341],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4338,4341],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Policy Loading Utility\n *\n * Loads and caches policy from lexmap.policy.json\n * Supports custom policy path via environment variable\n */\n\nimport { readFileSync, existsSync } from \"fs\";\nimport { resolve, dirname, join } from \"path\";\n// @ts-ignore - importing from compiled dist directory\nimport type { Policy } from \"../../types/policy.js\";\n\n/**\n * Default working policy path (from repository root)\n */\nconst DEFAULT_POLICY_PATH = \".smartergpt.local/lex/lexmap.policy.json\";\n\n/**\n * Fallback example policy path (from repository root)\n */\nconst EXAMPLE_POLICY_PATH = \"src/policy/policy_spec/lexmap.policy.json.example\";\n\n/**\n * Environment variable for custom policy path\n */\nconst POLICY_PATH_ENV = \"LEX_POLICY_PATH\";\n\n/**\n * Cached policy to avoid re-reading from disk\n */\nlet cachedPolicy: Policy | null = null;\n\n/**\n * Find repository root by looking for package.json\n */\nfunction findRepoRoot(startPath: string): string {\n  let currentPath = startPath;\n\n  while (currentPath !== dirname(currentPath)) {\n    const packageJsonPath = join(currentPath, \"package.json\");\n    if (existsSync(packageJsonPath)) {\n      const packageJson = JSON.parse(readFileSync(packageJsonPath, \"utf-8\"));\n      // Check if this is the lex root package\n      if (packageJson.name === \"lex\") {\n        return currentPath;\n      }\n    }\n    currentPath = dirname(currentPath);\n  }\n\n  throw new Error('Could not find repository root (looking for package.json with name \"lex\")');\n}\n\n/**\n * Load policy from lexmap.policy.json\n *\n * @param path - Optional custom policy path (defaults to working file with fallback to example)\n * @returns Policy object\n * @throws Error if policy file cannot be read or parsed\n *\n * Policy loading precedence:\n * 1. LEX_POLICY_PATH environment variable (explicit override)\n * 2. Custom path parameter (if provided)\n * 3. .smartergpt.local/lex/lexmap.policy.json (working file)\n * 4. src/policy/policy_spec/lexmap.policy.json.example (example template)\n *\n * @example\n * ```typescript\n * const policy = loadPolicy();\n * console.log(Object.keys(policy.modules)); // ['indexer', 'ts', 'php', 'mcp']\n * ```\n *\n * @example With custom path\n * ```typescript\n * const policy = loadPolicy('/custom/path/policy.json');\n * ```\n *\n * @example With environment variable\n * ```typescript\n * process.env.LEX_POLICY_PATH = '/custom/path/policy.json';\n * const policy = loadPolicy();\n * ```\n */\nexport function loadPolicy(path?: string): Policy {\n  // Return cached policy if available and no custom path specified\n  if (cachedPolicy && !path) {\n    return cachedPolicy;\n  }\n\n  // Determine policy path with fallback chain\n  const envPath = process.env[POLICY_PATH_ENV];\n\n  try {\n    let resolvedPath: string;\n\n    if (envPath) {\n      // Priority 1: Environment variable (explicit override)\n      resolvedPath = resolve(envPath);\n    } else if (path) {\n      // Priority 2: Custom path parameter\n      resolvedPath = resolve(path);\n    } else {\n      // Priority 3-4: Try working file, then example\n      const repoRoot = findRepoRoot(process.cwd());\n\n      // Try working file first\n      const workingPath = join(repoRoot, DEFAULT_POLICY_PATH);\n      if (existsSync(workingPath)) {\n        resolvedPath = workingPath;\n      } else {\n        // Fallback to example file\n        const examplePath = join(repoRoot, EXAMPLE_POLICY_PATH);\n        if (existsSync(examplePath)) {\n          resolvedPath = examplePath;\n        } else {\n          throw new Error(\n            `Policy file not found. Tried:\\n` +\n              `  1. ${workingPath}\\n` +\n              `  2. ${examplePath}\\n\\n` +\n              `Run 'npm run setup-local' to initialize working files.`\n          );\n        }\n      }\n    }\n\n    // Read and parse policy file\n    const policyContent = readFileSync(resolvedPath, \"utf-8\");\n    const rawPolicy = JSON.parse(policyContent);\n\n    // Cast to Policy type (no transformation needed - all policies use modules format)\n    const policy = rawPolicy as Policy;\n\n    // Validate basic structure\n    if (!policy.modules || typeof policy.modules !== \"object\") {\n      throw new Error('Invalid policy structure: missing or invalid \"modules\" field');\n    }\n\n    // Cache policy if using default path (not env var or custom path)\n    if (!envPath && !path) {\n      cachedPolicy = policy;\n    }\n\n    return policy;\n  } catch (error: any) {\n    if (error.code === \"ENOENT\") {\n      throw new Error(\n        `Policy file not found: ${envPath || path || DEFAULT_POLICY_PATH}\\n` +\n          `Run 'npm run setup-local' to initialize working files.`\n      );\n    }\n    throw new Error(\n      `Failed to load policy from ${envPath || path || DEFAULT_POLICY_PATH}: ${error.message}`\n    );\n  }\n}\n\n/**\n * Clear cached policy (useful for testing)\n */\nexport function clearPolicyCache(): void {\n  cachedPolicy = null;\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/prompts/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/prompts/loader.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/prompts/renderer.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'strict' is defined but never used. Allowed unused args must match /^_/u.","line":252,"column":3,"nodeType":null,"messageId":"unusedVar","endLine":252,"endColumn":9},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'shouldEscape' is defined but never used. Allowed unused args must match /^_/u.","line":253,"column":3,"nodeType":null,"messageId":"unusedVar","endLine":253,"endColumn":15},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":316,"column":13,"nodeType":"VariableDeclarator","messageId":"anyAssignment","endLine":316,"endColumn":28},{"ruleId":"@typescript-eslint/no-unsafe-assignment","severity":1,"message":"Unsafe assignment of an `any` value.","line":319,"column":9,"nodeType":"Property","messageId":"anyAssignment","endLine":319,"endColumn":19}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Prompt Template Renderer\n * \n * Provides deterministic, strict rendering of prompt templates with:\n * - Variable substitution: {{variable}}\n * - Conditionals: {{#if condition}}...{{else}}...{{/if}}\n * - Loops: {{#each items}}...{{/each}}\n * - HTML escaping by default\n * - Raw output: {{{raw}}}\n * - Strict mode: throws on unknown variables\n */\n\nimport { createHash } from \"crypto\";\nimport {\n  RenderContext,\n  RenderOptions,\n  RenderError,\n  ValidationResult,\n  PromptTemplate,\n  RenderedPrompt,\n} from \"./types.js\";\n\n/**\n * HTML escape map for security\n */\nconst HTML_ESCAPE_MAP: Record<string, string> = {\n  \"&\": \"&amp;\",\n  \"<\": \"&lt;\",\n  \">\": \"&gt;\",\n  '\"': \"&quot;\",\n  \"'\": \"&#39;\",\n};\n\n/**\n * Escape HTML special characters\n */\nfunction escapeHtml(text: string): string {\n  return text.replace(/[&<>\"']/g, (char) => HTML_ESCAPE_MAP[char] || char);\n}\n\n/**\n * Compute SHA256 hash of a string\n */\nfunction computeHash(content: string): string {\n  return createHash(\"sha256\").update(content, \"utf-8\").digest(\"hex\");\n}\n\n/**\n * Extract all variable references from a template\n * Matches: {{var}}, {{{var}}}, {{#if var}}, {{#each var}}\n */\nfunction extractVariables(template: string): string[] {\n  const variables = new Set<string>();\n  \n  // Match control structures: {{#if var}} and {{#each var}}\n  const controlRegex = /\\{\\{#(if|each)\\s+([a-zA-Z_][a-zA-Z0-9_\\.]*)\\s*\\}\\}/g;\n  let match;\n  \n  while ((match = controlRegex.exec(template)) !== null) {\n    const varName = match[2];\n    variables.add(varName.split(\".\")[0]);\n  }\n  \n  // Match regular variables: {{var}} and {{{var}}}\n  // But NOT inside {{#each}}...{{/each}} blocks where {{this}} is valid\n  // Remove {{#each}} blocks first\n  let cleanedTemplate = template.replace(/\\{\\{#each\\s+[a-zA-Z_][a-zA-Z0-9_\\.]*\\s*\\}\\}[\\s\\S]*?\\{\\{\\/each\\}\\}/g, \"\");\n  \n  const varRegex = /\\{\\{[\\{]?\\s*([a-zA-Z_][a-zA-Z0-9_\\.]*)\\s*[\\}]?\\}\\}/g;\n  \n  while ((match = varRegex.exec(cleanedTemplate)) !== null) {\n    const varName = match[1];\n    \n    // Skip control keywords and special variables\n    if (varName.startsWith(\"#\") || varName.startsWith(\"/\") || \n        varName === \"else\" || varName === \"this\" || varName.startsWith(\"@\")) {\n      continue;\n    }\n    \n    variables.add(varName.split(\".\")[0]);\n  }\n  \n  return Array.from(variables).sort();\n}\n\n/**\n * Resolve a dot-notation path in context (e.g., \"user.name\")\n */\nfunction resolvePath(context: RenderContext, path: string): unknown {\n  const parts = path.split(\".\");\n  let current: unknown = context;\n  \n  for (const part of parts) {\n    if (current === null || current === undefined) {\n      return undefined;\n    }\n    if (typeof current === \"object\" && part in current) {\n      current = (current as Record<string, unknown>)[part];\n    } else {\n      return undefined;\n    }\n  }\n  \n  return current;\n}\n\n/**\n * Validate that all required variables are present in context\n */\nexport function validateContext(\n  template: string,\n  context: RenderContext\n): ValidationResult {\n  const variables = extractVariables(template);\n  const missing: string[] = [];\n  \n  for (const varName of variables) {\n    if (!(varName in context)) {\n      // Check if this variable is ONLY used in {{#if}} conditions\n      // {{#each}} variables are always required, {{#if}} variables are optional\n      const eachPattern = new RegExp(`\\\\{\\\\{#each\\\\s+${varName}(?:\\\\s|\\\\})`);\n      const ifConditionPattern = new RegExp(`\\\\{\\\\{#if\\\\s+${varName}(?:\\\\s|\\\\})`);\n      const otherUsagePattern = new RegExp(`\\\\{\\\\{[\\\\{]?\\\\s*${varName}(?:\\\\s|\\\\}|\\\\.)`, \"g\");\n      \n      // If used in {{#each}}, it's required\n      if (eachPattern.test(template)) {\n        missing.push(varName);\n        continue;\n      }\n      \n      const matches = template.match(otherUsagePattern) || [];\n      const ifMatches = template.match(ifConditionPattern) || [];\n      \n      // If all matches are {{#if varName}}, then it's optional\n      if (matches.length > ifMatches.length) {\n        missing.push(varName);\n      }\n    }\n  }\n  \n  return {\n    valid: missing.length === 0,\n    missing: missing.length > 0 ? missing : undefined,\n  };\n}\n\n/**\n * Render a prompt template with variable substitution and control structures\n * \n * @param template - Template string with {{}} syntax\n * @param context - Variables to substitute\n * @param options - Rendering options (strict mode, escaping)\n * @returns Rendered string\n * \n * @example\n * ```typescript\n * const result = renderPrompt(\"Hello {{name}}!\", { name: \"World\" });\n * // => \"Hello World!\"\n * ```\n * \n * @example Conditionals\n * ```typescript\n * const result = renderPrompt(\n *   \"{{#if hasError}}Error: {{error}}{{/if}}\",\n *   { hasError: true, error: \"Not found\" }\n * );\n * // => \"Error: Not found\"\n * ```\n * \n * @example Loops\n * ```typescript\n * const result = renderPrompt(\n *   \"{{#each items}}{{this}}, {{/each}}\",\n *   { items: [\"a\", \"b\", \"c\"] }\n * );\n * // => \"a, b, c, \"\n * ```\n */\nexport function renderPrompt(\n  template: string,\n  context: RenderContext,\n  options: RenderOptions = {}\n): string {\n  const { strict = true, escapeHtml: shouldEscape = true } = options;\n  \n  // Validate context in strict mode\n  if (strict) {\n    const validation = validateContext(template, context);\n    if (!validation.valid) {\n      throw new RenderError(\n        `Missing required variables: ${validation.missing?.join(\", \")}`,\n        \"MISSING_VARIABLES\",\n        { missing: validation.missing }\n      );\n    }\n  }\n  \n  let result = template;\n  \n  // Process control structures first (if/each)\n  result = processConditionals(result, context, strict, shouldEscape);\n  result = processLoops(result, context, strict, shouldEscape);\n  \n  // Process raw variables {{{var}}} (no escaping)\n  result = result.replace(\n    /\\{\\{\\{\\s*([a-zA-Z_][a-zA-Z0-9_\\.]*)\\s*\\}\\}\\}/g,\n    (match, varName) => {\n      const value = resolvePath(context, varName);\n      if (value === undefined || value === null) {\n        if (strict) {\n          throw new RenderError(\n            `Variable \"${varName}\" is undefined`,\n            \"UNDEFINED_VARIABLE\",\n            { variable: varName }\n          );\n        }\n        return \"\";\n      }\n      return String(value);\n    }\n  );\n  \n  // Process regular variables {{var}} (with escaping if enabled)\n  result = result.replace(\n    /\\{\\{\\s*([a-zA-Z_][a-zA-Z0-9_\\.]*)\\s*\\}\\}/g,\n    (match, varName) => {\n      const value = resolvePath(context, varName);\n      if (value === undefined || value === null) {\n        if (strict) {\n          throw new RenderError(\n            `Variable \"${varName}\" is undefined`,\n            \"UNDEFINED_VARIABLE\",\n            { variable: varName }\n          );\n        }\n        return \"\";\n      }\n      const strValue = String(value);\n      return shouldEscape ? escapeHtml(strValue) : strValue;\n    }\n  );\n  \n  return result;\n}\n\n/**\n * Process {{#if condition}}...{{else}}...{{/if}} blocks\n */\nfunction processConditionals(\n  template: string,\n  context: RenderContext,\n  strict: boolean,\n  shouldEscape: boolean\n): string {\n  // Match nested if/else/endif blocks\n  const ifRegex = /\\{\\{#if\\s+([a-zA-Z_][a-zA-Z0-9_\\.]*)\\s*\\}\\}([\\s\\S]*?)(?:\\{\\{else\\}\\}([\\s\\S]*?))?\\{\\{\\/if\\}\\}/g;\n  \n  let result = template;\n  let match;\n  let maxIterations = 100; // Prevent infinite loops\n  \n  // Process from innermost to outermost\n  while ((match = ifRegex.exec(result)) !== null && maxIterations-- > 0) {\n    const [fullMatch, varName, trueBlock, falseBlock] = match;\n    const value = resolvePath(context, varName);\n    \n    // Check truthiness (undefined is allowed in conditionals - it's falsy)\n    const isTruthy = Boolean(value);\n    const replacement = isTruthy ? (trueBlock || \"\") : (falseBlock || \"\");\n    \n    result = result.substring(0, match.index) + replacement + result.substring(match.index + fullMatch.length);\n    \n    // Reset regex to process nested blocks\n    ifRegex.lastIndex = 0;\n  }\n  \n  return result;\n}\n\n/**\n * Process {{#each items}}...{{/each}} blocks\n */\nfunction processLoops(\n  template: string,\n  context: RenderContext,\n  strict: boolean,\n  shouldEscape: boolean\n): string {\n  const eachRegex = /\\{\\{#each\\s+([a-zA-Z_][a-zA-Z0-9_\\.]*)\\s*\\}\\}([\\s\\S]*?)\\{\\{\\/each\\}\\}/g;\n  \n  let result = template;\n  let match;\n  let maxIterations = 100; // Prevent infinite loops\n  \n  while ((match = eachRegex.exec(result)) !== null && maxIterations-- > 0) {\n    const [fullMatch, varName, loopBody] = match;\n    const items = resolvePath(context, varName);\n    \n    if (!Array.isArray(items)) {\n      if (strict && items !== undefined && items !== null) {\n        throw new RenderError(\n          `Variable \"${varName}\" is not an array`,\n          \"NOT_ARRAY\",\n          { variable: varName, value: items }\n        );\n      }\n      // Replace with empty string if not an array\n      result = result.substring(0, match.index) + result.substring(match.index + fullMatch.length);\n      eachRegex.lastIndex = 0;\n      continue;\n    }\n    \n    // Render each item\n    let loopOutput = \"\";\n    for (let i = 0; i < items.length; i++) {\n      const item = items[i];\n      const itemContext = {\n        ...context,\n        this: item,\n        \"@index\": i,\n        \"@first\": i === 0,\n        \"@last\": i === items.length - 1,\n      };\n      \n      // Render loop body with item context\n      let itemOutput = loopBody;\n      \n      // Replace {{{this}}} with item value (no escaping) - MUST BE FIRST\n      itemOutput = itemOutput.replace(/\\{\\{\\{\\s*this\\s*\\}\\}\\}/g, () => {\n        return String(item);\n      });\n      \n      // Replace {{this}} with item value (with escaping)\n      itemOutput = itemOutput.replace(/\\{\\{\\s*this\\s*\\}\\}/g, () => {\n        const strValue = String(item);\n        return shouldEscape ? escapeHtml(strValue) : strValue;\n      });\n      \n      // Replace other variables in item context\n      itemOutput = itemOutput.replace(\n        /\\{\\{\\s*([a-zA-Z_@][a-zA-Z0-9_\\.]*)\\s*\\}\\}/g,\n        (m, v) => {\n          if (v === \"this\") return String(item); // Already handled but just in case\n          const val = resolvePath(itemContext, v);\n          if (val === undefined || val === null) {\n            if (strict && !(v in itemContext)) {\n              throw new RenderError(\n                `Variable \"${v}\" is undefined in loop context`,\n                \"UNDEFINED_VARIABLE\",\n                { variable: v }\n              );\n            }\n            return \"\";\n          }\n          const strValue = String(val);\n          return shouldEscape ? escapeHtml(strValue) : strValue;\n        }\n      );\n      \n      loopOutput += itemOutput;\n    }\n    \n    result = result.substring(0, match.index) + loopOutput + result.substring(match.index + fullMatch.length);\n    eachRegex.lastIndex = 0;\n  }\n  \n  return result;\n}\n\n/**\n * Render a prompt template with full metadata and hashing\n */\nexport function renderPromptTemplate(\n  template: PromptTemplate,\n  context: RenderContext,\n  options: RenderOptions = {}\n): RenderedPrompt {\n  const rendered = renderPrompt(template.content, context, options);\n  const hash = computeHash(rendered);\n  \n  return {\n    template,\n    rendered,\n    context,\n    hash,\n  };\n}\n\n/**\n * Compute content hash for a template\n */\nexport function computeContentHash(content: string): string {\n  return computeHash(content);\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/prompts/types.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/schemas/loader.ts","messages":[{"ruleId":"@typescript-eslint/no-unsafe-return","severity":1,"message":"Unsafe return of a value of type `any`.","line":82,"column":7,"nodeType":"ReturnStatement","messageId":"unsafeReturn","endLine":82,"endColumn":57},{"ruleId":"@typescript-eslint/no-unsafe-return","severity":1,"message":"Unsafe return of a value of type `any`.","line":90,"column":5,"nodeType":"ReturnStatement","messageId":"unsafeReturn","endLine":90,"endColumn":57},{"ruleId":"@typescript-eslint/no-unsafe-return","severity":1,"message":"Unsafe return of a value of type `any`.","line":97,"column":5,"nodeType":"ReturnStatement","messageId":"unsafeReturn","endLine":97,"endColumn":57}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Schema Loading Utility\n *\n * Loads schema files with precedence chain support:\n * 1. LEX_SCHEMAS_DIR (explicit environment override)\n * 2. .smartergpt.local/schemas/ (local overlay)\n * 3. Package canon (resolved from package installation)\n */\n\nimport { readFileSync, existsSync, readdirSync } from \"fs\";\nimport { resolve, dirname, join } from \"path\";\nimport { fileURLToPath } from \"url\";\n\n/**\n * Resolve package asset path for both dev and installed contexts\n *\n * @param type - Asset type ('prompts' or 'schemas')\n * @param name - Asset name/filename\n * @returns Resolved absolute path to the asset\n */\nfunction resolvePackageAsset(type: \"prompts\" | \"schemas\", name: string): string {\n  // When installed: node_modules/lex/prompts/ or node_modules/lex/schemas/\n  // When local dev: <repo>/prompts/ or <repo>/schemas/\n  const currentFile = fileURLToPath(import.meta.url);\n  let pkgRoot = dirname(currentFile);\n  \n  // Walk up until we find package.json or reach a dist/ or src/ boundary\n  // In dist: /home/runner/work/lex/lex/dist/shared/schemas/loader.js -> /home/runner/work/lex/lex\n  // In src:  /home/runner/work/lex/lex/src/shared/schemas/loader.ts -> /home/runner/work/lex/lex\n  while (pkgRoot !== dirname(pkgRoot)) {\n    const pkgJsonPath = join(pkgRoot, \"package.json\");\n    if (existsSync(pkgJsonPath)) {\n      // Found package.json - this is the package root\n      return join(pkgRoot, type, name);\n    }\n    pkgRoot = dirname(pkgRoot);\n  }\n  \n  // Fallback: shouldn't reach here in normal use\n  throw new Error(`Could not resolve package root from ${currentFile}`);\n}\n\n/**\n * Load schema file with precedence chain\n *\n * @param schemaName - Name of the schema file (e.g., \"cli-output.v1.schema.json\")\n * @returns Parsed schema object\n * @throws Error if schema file cannot be found in any location\n *\n * Precedence chain:\n * 1. LEX_SCHEMAS_DIR (explicit environment override)\n * 2. .smartergpt.local/schemas/ (local overlay - untracked)\n * 3. Package canon (resolve from package installation)\n *\n * @example\n * ```typescript\n * const schema = loadSchema('cli-output.v1.schema.json');\n * console.log(schema); // Parsed JSON schema object\n * ```\n *\n * @example With environment variable override\n * ```typescript\n * process.env.LEX_SCHEMAS_DIR = '/custom/schemas';\n * const schema = loadSchema('cli-output.v1.schema.json');\n * ```\n *\n * @example Local overlay (create .smartergpt.local/schemas/my-schema.json to override)\n * ```typescript\n * // If .smartergpt.local/schemas/my-schema.json exists, it takes precedence\n * const schema = loadSchema('my-schema.json');\n * ```\n */\nexport function loadSchema(schemaName: string): object {\n  const attemptedPaths: string[] = [];\n\n  // Priority 1: LEX_SCHEMAS_DIR (explicit env override)\n  const envDir = process.env.LEX_SCHEMAS_DIR;\n  if (envDir) {\n    const envPath = resolve(envDir, schemaName);\n    attemptedPaths.push(envPath);\n    if (existsSync(envPath)) {\n      return JSON.parse(readFileSync(envPath, \"utf-8\"));\n    }\n  }\n\n  // Priority 2: .smartergpt.local/schemas/ (local overlay)\n  const localPath = join(process.cwd(), \".smartergpt.local\", \"schemas\", schemaName);\n  attemptedPaths.push(localPath);\n  if (existsSync(localPath)) {\n    return JSON.parse(readFileSync(localPath, \"utf-8\"));\n  }\n\n  // Priority 3: Package canon (resolve from package installation)\n  const canonPath = resolvePackageAsset(\"schemas\", schemaName);\n  attemptedPaths.push(canonPath);\n  if (existsSync(canonPath)) {\n    return JSON.parse(readFileSync(canonPath, \"utf-8\"));\n  }\n\n  throw new Error(\n    `Schema file '${schemaName}' not found. Tried:\\n` +\n      attemptedPaths.map((p, i) => `  ${i + 1}. ${p}`).join(\"\\n\")\n  );\n}\n\n/**\n * Get the path where a schema would be loaded from (without loading it)\n *\n * @param schemaName - Name of the schema file\n * @returns Resolved path or null if not found\n *\n * @example\n * ```typescript\n * const path = getSchemaPath('cli-output.v1.schema.json');\n * console.log(path); // '/repo/schemas/cli-output.v1.schema.json'\n * ```\n */\nexport function getSchemaPath(schemaName: string): string | null {\n  // Priority 1: LEX_SCHEMAS_DIR\n  const envDir = process.env.LEX_SCHEMAS_DIR;\n  if (envDir) {\n    const envPath = resolve(envDir, schemaName);\n    if (existsSync(envPath)) {\n      return envPath;\n    }\n  }\n\n  // Priority 2: Local overlay\n  const localPath = join(process.cwd(), \".smartergpt.local\", \"schemas\", schemaName);\n  if (existsSync(localPath)) {\n    return localPath;\n  }\n\n  // Priority 3: Package canon\n  const canonPath = resolvePackageAsset(\"schemas\", schemaName);\n  if (existsSync(canonPath)) {\n    return canonPath;\n  }\n\n  return null;\n}\n\n/**\n * List all available schemas across all precedence levels\n *\n * @returns Array of unique schema names (deduplicated)\n *\n * @example\n * ```typescript\n * const schemas = listSchemas();\n * console.log(schemas); // ['cli-output.v1.schema.json', ...]\n * ```\n */\nexport function listSchemas(): string[] {\n  const schemas = new Set<string>();\n\n  // Collect from package canon\n  try {\n    const canonPath = resolvePackageAsset(\"schemas\", \"\");\n    if (existsSync(canonPath)) {\n      const files = readdirSync(canonPath);\n      files.forEach((file: string) => {\n        if (file.endsWith(\".json\") || file.endsWith(\".schema.json\")) {\n          schemas.add(file);\n        }\n      });\n    }\n  } catch {\n    // Ignore errors when reading package canon\n  }\n\n  // Collect from local (overlay)\n  const localPath = join(process.cwd(), \".smartergpt.local\", \"schemas\");\n  if (existsSync(localPath)) {\n    try {\n      const files = readdirSync(localPath);\n      files.forEach((file: string) => {\n        if (file.endsWith(\".json\") || file.endsWith(\".schema.json\")) {\n          schemas.add(file);\n        }\n      });\n    } catch {\n      // Ignore errors when reading local overlay\n    }\n  }\n\n  // Collect from LEX_SCHEMAS_DIR (if specified)\n  const envDir = process.env.LEX_SCHEMAS_DIR;\n  if (envDir && existsSync(envDir)) {\n    try {\n      const files = readdirSync(envDir);\n      files.forEach((file: string) => {\n        if (file.endsWith(\".json\") || file.endsWith(\".schema.json\")) {\n          schemas.add(file);\n        }\n      });\n    } catch {\n      // Ignore errors when reading env dir\n    }\n  }\n\n  return Array.from(schemas).sort();\n}\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/types/frame.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/types/index.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/types/policy.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/src/shared/types/validation.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/helpers/validate-cli-event.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/api-ingestion.perf.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/benchmarks.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/integration.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/mcp_server/alias-benchmarks.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'after' is defined but never used. Allowed unused vars must match /^_/u.","line":22,"column":34,"nodeType":null,"messageId":"unusedVar","endLine":22,"endColumn":39},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'mkdtempSync' is defined but never used. Allowed unused vars must match /^_/u.","line":26,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":26,"endColumn":21},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'rmSync' is defined but never used. Allowed unused vars must match /^_/u.","line":26,"column":23,"nodeType":null,"messageId":"unusedVar","endLine":26,"endColumn":29},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'writeFileSync' is defined but never used. Allowed unused vars must match /^_/u.","line":26,"column":31,"nodeType":null,"messageId":"unusedVar","endLine":26,"endColumn":44},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'join' is defined but never used. Allowed unused vars must match /^_/u.","line":27,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":27,"endColumn":14},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'tmpdir' is defined but never used. Allowed unused vars must match /^_/u.","line":28,"column":10,"nodeType":null,"messageId":"unusedVar","endLine":28,"endColumn":16},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'error' is defined but never used.","line":57,"column":12,"nodeType":null,"messageId":"unusedVar","endLine":57,"endColumn":17}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":7,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Performance Benchmarks for Alias Resolution\n *\n * Measures the performance impact of module ID validation with fuzzy matching.\n *\n * Target: < 5% performance regression on average case\n *\n * Before (Exact Match Only):\n * - Validation time: ~0.5ms per module ID\n * - Atlas Frame generation: ~10ms\n * - Memory overhead: None\n *\n * After (With Fuzzy Matching):\n * - Exact match path: ~0.5ms (unchanged)\n * - Fuzzy fallback: ~2ms worst case (only on mismatch)\n * - Atlas Frame generation: ~10ms (unchanged)\n * - Memory overhead: ~10KB (policy cache)\n *\n * Run with: npm run build && node --test dist/alias-benchmarks.test.js\n */\n\nimport { test, describe, before, after } from \"node:test\";\nimport assert from \"node:assert\";\n// @ts-ignore\nimport { validateModuleIds } from \"@app/shared/module_ids/validator.js\";\nimport { mkdtempSync, rmSync, writeFileSync } from \"fs\";\nimport { join } from \"path\";\nimport { tmpdir } from \"os\";\n\n// Mock policy for benchmarking\nconst createTestPolicy = (moduleCount: number) => {\n  const modules: Record<string, any> = {};\n\n  // Add realistic module names\n  for (let i = 0; i < moduleCount; i++) {\n    modules[`services/module-${i}`] = { owns_paths: [`services/module-${i}/**`] };\n  }\n\n  // Add common modules matching the actual policy structure\n  modules[\"policy/scanners\"] = { owns_paths: [\"src/policy/scanners/**\"] };\n  modules[\"shared/types\"] = { owns_paths: [\"src/shared/types/**\"] };\n  modules[\"memory/mcp\"] = { owns_paths: [\"src/memory/mcp_server/**\"] };\n  modules[\"services/auth-core\"] = { owns_paths: [\"services/auth/**\"] };\n  modules[\"ui/main-panel\"] = { owns_paths: [\"ui/main/**\"] };\n  modules[\"api/user-access\"] = { owns_paths: [\"api/user/**\"] };\n\n  return { modules };\n};\n\n/**\n * Measure execution time for async function\n */\nasync function measureTime(fn: () => Promise<void>): Promise<number> {\n  const start = performance.now();\n  try {\n    await fn();\n  } catch (error) {\n    // Still record timing even if function throws\n    // This ensures we measure actual execution time\n  }\n  const end = performance.now();\n  return end - start;\n}\n\n/**\n * Run benchmark multiple times and return average\n */\nasync function benchmark(\n  name: string,\n  iterations: number,\n  fn: () => Promise<void>\n): Promise<number> {\n  const times: number[] = [];\n\n  // Warmup\n  for (let i = 0; i < 5; i++) {\n    await fn();\n  }\n\n  // Actual measurements\n  for (let i = 0; i < iterations; i++) {\n    times.push(await measureTime(fn));\n  }\n\n  const avg = times.reduce((a, b) => a + b, 0) / times.length;\n  const min = Math.min(...times);\n  const max = Math.max(...times);\n\n  console.log(`  ${name}:`);\n  console.log(`    Average: ${avg.toFixed(3)}ms`);\n  console.log(`    Min: ${min.toFixed(3)}ms`);\n  console.log(`    Max: ${max.toFixed(3)}ms`);\n\n  return avg;\n}\n\ndescribe(\"Alias Resolution Performance Benchmarks\", () => {\n  let policy10: any;\n  let policy100: any;\n  let policy1000: any;\n\n  before(() => {\n    // Create fresh policy objects before each test suite\n    // This ensures consistent performance measurements\n    policy10 = createTestPolicy(10);\n    policy100 = createTestPolicy(100);\n    policy1000 = createTestPolicy(1000);\n  });\n\n  describe(\"Performance Regression Check\", () => {\n    // Run regression test FIRST, before other tests warm up caches\n    test(\"should have reasonable overhead for fuzzy matching support\", async () => {\n      // NOTE: This benchmark compares exact-match validation against a synchronous\n      // Set.has() baseline. The validateModuleIds function is async to support\n      // fuzzy matching and alias resolution on mismatch.\n      //\n      // The \"regression\" here actually represents the cost of:\n      // 1. Async function overhead (~0.1-0.2ms per call)\n      // 2. Promise creation and resolution\n      // 3. Type safety and validation framework\n      //\n      // This is EXPECTED and ACCEPTABLE because:\n      // - Module validation is not in the hot path (happens at Frame store time, not runtime)\n      // - The overhead is negligible for interactive use\n      // - Exact matches take <0.3ms (well below human perception threshold)\n      // - Fuzzy matching fallback is only triggered on mismatches (error cases)\n\n      // WARMUP: Let JIT and caches initialize\n      for (let i = 0; i < 100; i++) {\n        await validateModuleIds([\"policy/scanners\"], policy100);\n      }\n\n      // Measure exact match validation (fast path)\n      const fastPathTime = await benchmark(\"Exact match validation (fast path)\", 1000, async () => {\n        await validateModuleIds([\"policy/scanners\"], policy100);\n      });\n\n      console.log(`  Exact match performance:`);\n      console.log(`    Time per validation: ${fastPathTime.toFixed(3)}ms`);\n      console.log(`    Operations per second: ${(1000 / fastPathTime).toFixed(0)}`);\n\n      // Fast path should complete in under 0.5ms per validation\n      // (negligible overhead for non-hot-path operation)\n      assert.ok(\n        fastPathTime < 0.5,\n        `Exact match validation took ${fastPathTime.toFixed(3)}ms, expected <0.5ms`\n      );\n    });\n  });\n\n  describe(\"Exact Match Path (Best Case)\", () => {\n    test(\"should validate exact matches very quickly (<0.5ms)\", async () => {\n      const avgTime = await benchmark(\n        \"Exact match validation (10 modules policy)\",\n        1000,\n        async () => {\n          await validateModuleIds([\"policy/scanners\", \"shared/types\", \"memory/mcp\"], policy10);\n        }\n      );\n\n      assert.ok(avgTime < 0.5, `Exact match took ${avgTime.toFixed(3)}ms, expected <0.5ms`);\n    });\n\n    test(\"should scale with policy size (O(1) hash lookup)\", async () => {\n      // The scaling test is inherently flaky on first run due to:\n      // 1. JIT warmup of validateModuleIds\n      // 2. Cache initialization in policyModuleIdsCache\n      // 3. Node.js garbage collection timing\n      //\n      // We measure but use generous thresholds on first run\n      // (subsequent runs should be much tighter)\n\n      const time10 = await benchmark(\"Exact match with 10 modules policy\", 1000, async () => {\n        await validateModuleIds([\"policy/scanners\"], policy10);\n      });\n\n      const time100 = await benchmark(\"Exact match with 100 modules policy\", 1000, async () => {\n        await validateModuleIds([\"policy/scanners\"], policy100);\n      });\n\n      const time1000 = await benchmark(\"Exact match with 1000 modules policy\", 1000, async () => {\n        await validateModuleIds([\"policy/scanners\"], policy1000);\n      });\n\n      // Hash table lookup should be O(1), so times should be similar\n      console.log(`  Scaling comparison:`);\n      console.log(`    10 modules: ${time10.toFixed(3)}ms`);\n      console.log(`    100 modules: ${time100.toFixed(3)}ms`);\n      console.log(`    1000 modules: ${time1000.toFixed(3)}ms`);\n\n      // Should not degrade significantly with policy size\n      // Using generous threshold (3x) to account for JIT warmup on first run\n      // Should tighten to 1.2x on subsequent runs once caches are warm\n      assert.ok(\n        time1000 < time10 * 3,\n        `1000-module policy should not be > 3x slower than 10-module (was ${(time1000 / time10).toFixed(1)}x)`\n      );\n    });\n\n    test(\"should handle multiple exact matches efficiently\", async () => {\n      const avgTime = await benchmark(\"Multiple exact matches (6 modules)\", 1000, async () => {\n        await validateModuleIds(\n          [\n            \"policy/scanners\",\n            \"shared/types\",\n            \"shared/policy\",\n            \"memory/mcp\",\n            \"services/auth-core\",\n            \"ui/main-panel\",\n          ],\n          policy100\n        );\n      });\n\n      assert.ok(\n        avgTime < 1.0,\n        `Multiple exact matches took ${avgTime.toFixed(3)}ms, expected <1.0ms`\n      );\n    });\n  });\n\n  describe(\"Fuzzy Match Path (Worst Case)\", () => {\n    test(\"should handle typos with fuzzy matching (<2ms)\", async () => {\n      const avgTime = await benchmark(\"Fuzzy match for typo\", 1000, async () => {\n        await validateModuleIds([\"indexr\"], policy10); // Typo: \"indexr\" instead of \"policy/scanners\"\n      });\n\n      console.log(`  Note: Result is invalid, but fuzzy matching provides suggestions`);\n\n      assert.ok(avgTime < 2.0, `Fuzzy matching took ${avgTime.toFixed(3)}ms, expected <2.0ms`);\n    });\n\n    test(\"should handle completely invalid input (<3ms)\", async () => {\n      const avgTime = await benchmark(\"Fuzzy match for invalid module\", 1000, async () => {\n        await validateModuleIds([\"nonexistent-module-xyz\"], policy10);\n      });\n\n      assert.ok(\n        avgTime < 3.0,\n        `Invalid module handling took ${avgTime.toFixed(3)}ms, expected <3.0ms`\n      );\n    });\n\n    test(\"should not degrade badly with large policy\", async () => {\n      const avgTime = await benchmark(\n        \"Fuzzy match with 1000 module policy\",\n        100, // Fewer iterations since this is slower\n        async () => {\n          await validateModuleIds([\"indexr\"], policy1000);\n        }\n      );\n\n      // Fuzzy matching needs to check all modules, so O(n)\n      // But should still be reasonably fast\n      assert.ok(\n        avgTime < 10.0,\n        `Fuzzy matching with 1000 modules took ${avgTime.toFixed(3)}ms, expected <10ms`\n      );\n    });\n  });\n\n  describe(\"Mixed Case (Realistic Workload)\", () => {\n    test(\"should handle mix of valid and invalid efficiently\", async () => {\n      const avgTime = await benchmark(\"Mixed valid/invalid modules\", 1000, async () => {\n        // 2 valid, 1 invalid - realistic typo scenario\n        await validateModuleIds([\"policy/scanners\", \"shared/types\", \"invalidmodule\"], policy100);\n      });\n\n      assert.ok(avgTime < 2.0, `Mixed validation took ${avgTime.toFixed(3)}ms, expected <2.0ms`);\n    });\n\n    test(\"should validate empty module scope instantly\", async () => {\n      const avgTime = await benchmark(\"Empty module scope validation\", 10000, async () => {\n        await validateModuleIds([], policy100);\n      });\n\n      assert.ok(avgTime < 0.1, `Empty validation took ${avgTime.toFixed(3)}ms, expected <0.1ms`);\n    });\n  });\n\n  describe(\"Memory Overhead\", () => {\n    test(\"should report policy cache size\", () => {\n      const policyJson = JSON.stringify(policy100);\n      const sizeKB = Buffer.byteLength(policyJson) / 1024;\n\n      console.log(`  Policy cache size (100 modules): ${sizeKB.toFixed(2)}KB`);\n\n      assert.ok(sizeKB < 50, `Policy cache of ${sizeKB.toFixed(2)}KB exceeds 50KB limit`);\n    });\n\n    test(\"should report large policy cache size\", () => {\n      const policyJson = JSON.stringify(policy1000);\n      const sizeKB = Buffer.byteLength(policyJson) / 1024;\n\n      console.log(`  Policy cache size (1000 modules): ${sizeKB.toFixed(2)}KB`);\n\n      assert.ok(sizeKB < 500, `Large policy cache of ${sizeKB.toFixed(2)}KB exceeds 500KB limit`);\n    });\n  });\n\n  describe(\"Summary\", () => {\n    test(\"should print performance summary\", () => {\n      console.log(\"\\n  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\");\n      console.log(\"  Alias Resolution Performance Summary\");\n      console.log(\"  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\");\n      console.log(\"  âœ“ Exact match: <0.5ms (unchanged from baseline)\");\n      console.log(\"  âœ“ Fuzzy matching: <2ms (only on mismatch)\");\n      console.log(\"  âœ“ Large policy (1000 modules): <10ms fuzzy\");\n      console.log(\"  âœ“ Performance regression: Minimal on happy path\");\n      console.log(\"  âœ“ Memory overhead: <10KB typical, <500KB max\");\n      console.log(\"  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\");\n\n      assert.ok(true, \"Summary displayed\");\n    });\n  });\n});\n\nconsole.log(\"\\nâœ… Alias Resolution Benchmarks - Performance targets met\\n\");\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/mcp_server/alias-integration.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'before' is defined but never used. Allowed unused vars must match /^_/u.","line":15,"column":26,"nodeType":null,"messageId":"unusedVar","endLine":15,"endColumn":32},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'after' is defined but never used. Allowed unused vars must match /^_/u.","line":15,"column":34,"nodeType":null,"messageId":"unusedVar","endLine":15,"endColumn":39},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":59,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":59,"endColumn":17}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Alias Resolution Integration Tests for MCP Server\n *\n * Tests the full MCP /remember flow with module ID validation and fuzzy matching.\n * These tests verify:\n * - Exact matches work without warnings\n * - Typos trigger helpful suggestions\n * - Substring matching (future: could suggest modules)\n * - Ambiguous matches are rejected\n * - Strict mode (CI) only allows exact matches\n *\n * Run with: npm run build && node --test dist/alias-integration.test.js\n */\n\nimport { test, describe, before, after } from \"node:test\";\nimport assert from \"node:assert\";\nimport { MCPServer } from \"@app/memory/mcp_server/server.js\";\nimport { mkdtempSync, mkdirSync, rmSync, writeFileSync } from \"fs\";\nimport { join } from \"path\";\nimport { tmpdir } from \"os\";\n\ndescribe(\"MCP Server Alias Resolution Integration Tests\", () => {\n  let server: MCPServer;\n  let testDbPath: string;\n  let testRepoRoot: string;\n\n  function setup() {\n    const tmpDir = mkdtempSync(join(tmpdir(), \"mcp-alias-test-\"));\n    testDbPath = join(tmpDir, \"alias-test.db\");\n    testRepoRoot = tmpDir;\n\n    // Create minimal test policy structure\n    const policyDir = join(tmpDir, \"policy\", \"policy_spec\");\n    mkdirSync(policyDir, { recursive: true });\n\n    const testPolicy = {\n      modules: {\n        \"policy/scanners\": { owns_paths: [\"src/policy/scanners/**\"] },\n        \"shared/types\": { owns_paths: [\"src/shared/types/**\"] },\n        \"memory/mcp\": { owns_paths: [\"src/memory/mcp_server/**\"] },\n        \"services/auth-core\": { owns_paths: [\"services/auth/**\"] },\n        \"ui/main-panel\": { owns_paths: [\"ui/main/**\"] },\n      },\n    };\n\n    writeFileSync(join(policyDir, \"lexmap.policy.json\"), JSON.stringify(testPolicy, null, 2));\n\n    server = new MCPServer(testDbPath, testRepoRoot);\n    return server;\n  }\n\n  function teardown() {\n    if (server) {\n      server.close();\n    }\n    if (testRepoRoot) {\n      try {\n        rmSync(testRepoRoot, { force: true, recursive: true });\n      } catch (e) {\n        // Ignore cleanup errors\n      }\n    }\n  }\n\n  describe(\"Test 1: Exact Match (Baseline)\", () => {\n    test(\"should accept exact module ID without warnings\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"Testing exact match\",\n              summary_caption: \"Exact module ID match test\",\n              status_snapshot: {\n                next_action: \"Verify no warnings\",\n              },\n              module_scope: [\"services/auth-core\"], // Exact match\n            },\n          },\n        });\n\n        assert.ok(response.content, \"Should succeed with exact match\");\n        assert.ok(response.content[0].text.includes(\"âœ… Frame stored\"), \"Should confirm storage\");\n\n        // Exact matches should not produce warnings\n        assert.ok(\n          !response.content[0].text.toLowerCase().includes(\"warning\"),\n          \"Should not have warnings for exact match\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should accept multiple exact matches\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"Multiple exact modules\",\n              summary_caption: \"Testing multiple exact matches\",\n              status_snapshot: {\n                next_action: \"Continue\",\n              },\n              module_scope: [\"policy/scanners\", \"shared/types\", \"services/auth-core\"],\n            },\n          },\n        });\n\n        assert.ok(response.content, \"Should succeed with multiple exact matches\");\n        assert.ok(response.content[0].text.includes(\"âœ… Frame stored\"), \"Should confirm storage\");\n      } finally {\n        teardown();\n      }\n    });\n  });\n\n  describe(\"Test 2: Typo Correction\", () => {\n    test(\"should reject typo with helpful suggestion\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"Testing typo correction\",\n              summary_caption: \"Typo in module ID\",\n              status_snapshot: {\n                next_action: \"Fix typo\",\n              },\n              module_scope: [\"policy/scannrs\"], // Typo: should be \"policy/scanners\"\n            },\n          },\n        });\n\n        assert.ok(response.error, \"Should return error for typo\");\n        assert.ok(response.error.message.includes(\"scannrs\"), \"Error should mention the typo\");\n        assert.ok(response.error.message.includes(\"Did you mean\"), \"Should provide suggestion\");\n        assert.ok(\n          response.error.message.includes(\"policy/scanners\"),\n          \"Should suggest 'policy/scanners'\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should suggest closest match for common typos\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"Testing fuzzy matching\",\n              summary_caption: \"Common typo test\",\n              status_snapshot: {\n                next_action: \"Use suggested module\",\n              },\n              module_scope: [\"servcies/auth-core\"], // Typo: should be \"services/auth-core\"\n            },\n          },\n        });\n\n        assert.ok(response.error, \"Should return error for typo\");\n        assert.ok(response.error.message.includes(\"Did you mean\"), \"Should provide suggestion\");\n        assert.ok(\n          response.error.message.includes(\"services/auth-core\"),\n          \"Should suggest correct module\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n  });\n\n  describe(\"Test 3: Substring/Shorthand Matching\", () => {\n    test(\"should reject substring without exact match\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"Testing substring\",\n              summary_caption: \"Substring module reference\",\n              status_snapshot: {\n                next_action: \"Use full module ID\",\n              },\n              module_scope: [\"auth\"], // Substring of \"services/auth-core\"\n            },\n          },\n        });\n\n        assert.ok(response.error, \"Should reject substring match\");\n        assert.ok(response.error.message.includes(\"auth\"), \"Error should mention the input\");\n        // Future: Could suggest \"services/auth-core\" as it contains \"auth\"\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should handle shorthand notation as error\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"Testing shorthand\",\n              summary_caption: \"Shorthand module ID\",\n              status_snapshot: {\n                next_action: \"Use canonical ID\",\n              },\n              module_scope: [\"auth-core\"], // Shorthand, missing \"services/\" prefix\n            },\n          },\n        });\n\n        assert.ok(response.error, \"Should reject shorthand notation\");\n        assert.ok(\n          response.error.message.includes(\"auth-core\"),\n          \"Error should mention shorthand input\"\n        );\n        // May or may not suggest the full path depending on edit distance\n      } finally {\n        teardown();\n      }\n    });\n  });\n\n  describe(\"Test 4: Ambiguous Matches\", () => {\n    test(\"should reject very short ambiguous inputs\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"Testing ambiguous input\",\n              summary_caption: \"Ambiguous module reference\",\n              status_snapshot: {\n                next_action: \"Be more specific\",\n              },\n              module_scope: [\"t\"], // Could match \"shared/types\" or part of others\n            },\n          },\n        });\n\n        assert.ok(response.error, \"Should reject ambiguous input\");\n        assert.ok(\n          response.error.message.includes(\"Available modules\"),\n          \"Should list available modules\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should list available modules on error\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"Testing module list\",\n              summary_caption: \"Invalid module test\",\n              status_snapshot: {\n                next_action: \"Check available modules\",\n              },\n              module_scope: [\"nonexistent\"],\n            },\n          },\n        });\n\n        assert.ok(response.error, \"Should return error\");\n        assert.ok(\n          response.error.message.includes(\"Available modules\"),\n          \"Should list available modules\"\n        );\n        assert.ok(\n          response.error.message.includes(\"policy/scanners\"),\n          \"Should include 'policy/scanners' in available modules\"\n        );\n        assert.ok(\n          response.error.message.includes(\"services/auth-core\"),\n          \"Should include 'services/auth-core' in available modules\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n  });\n\n  describe(\"Test 5: Mixed Valid/Invalid Modules\", () => {\n    test(\"should report all invalid modules in one error\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"Testing mixed modules\",\n              summary_caption: \"Mix of valid and invalid\",\n              status_snapshot: {\n                next_action: \"Fix invalid modules\",\n              },\n              module_scope: [\"policy/scanners\", \"invalid1\", \"shared/types\", \"invalid2\"],\n            },\n          },\n        });\n\n        assert.ok(response.error, \"Should return error for invalid modules\");\n        assert.ok(\n          response.error.message.includes(\"invalid1\"),\n          \"Should mention first invalid module\"\n        );\n        assert.ok(\n          response.error.message.includes(\"invalid2\"),\n          \"Should mention second invalid module\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n  });\n\n  describe(\"Performance Validation\", () => {\n    test(\"should validate modules quickly (<10ms)\", async () => {\n      const srv = setup();\n      try {\n        const start = performance.now();\n\n        await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"Performance test\",\n              summary_caption: \"Testing validation performance\",\n              status_snapshot: {\n                next_action: \"Measure time\",\n              },\n              module_scope: [\"policy/scanners\", \"shared/types\", \"memory/mcp\"],\n            },\n          },\n        });\n\n        const elapsed = performance.now() - start;\n\n        console.log(`  Module validation time: ${elapsed.toFixed(2)}ms`);\n        // Allow up to 50ms (generous threshold for CI/test environments with GC variance)\n        // Typical runs are <10ms, but first runs may be slower due to JIT warmup\n        assert.ok(elapsed < 50, `Validation took ${elapsed.toFixed(2)}ms, expected <50ms`);\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should handle large module scopes efficiently\", async () => {\n      const srv = setup();\n      try {\n        const start = performance.now();\n\n        await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"Large scope test\",\n              summary_caption: \"Testing with many modules\",\n              status_snapshot: {\n                next_action: \"Continue\",\n              },\n              module_scope: [\n                \"policy/scanners\",\n                \"shared/types\",\n                \"shared/policy\",\n                \"memory/mcp\",\n                \"services/auth-core\",\n                \"ui/main-panel\",\n              ],\n            },\n          },\n        });\n\n        const elapsed = performance.now() - start;\n\n        console.log(`  Large scope validation time: ${elapsed.toFixed(2)}ms`);\n        assert.ok(\n          elapsed < 15,\n          `Large scope validation took ${elapsed.toFixed(2)}ms, expected <15ms`\n        );\n      } finally {\n        teardown();\n      }\n    });\n  });\n\n  describe(\"End-to-End Flow\", () => {\n    test(\"should complete full /remember â†’ recall cycle with validation\", async () => {\n      const srv = setup();\n      try {\n        // Step 1: Remember with valid modules\n        const rememberResponse = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"E2E test with validation\",\n              summary_caption: \"End-to-end alias flow\",\n              status_snapshot: {\n                next_action: \"Recall and verify\",\n              },\n              module_scope: [\"services/auth-core\", \"ui/main-panel\"],\n              keywords: [\"e2e\", \"validation\"],\n            },\n          },\n        });\n\n        assert.ok(rememberResponse.content, \"Remember should succeed\");\n\n        // Step 2: Recall the frame\n        const recallResponse = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.recall\",\n            arguments: {\n              reference_point: \"E2E test\",\n            },\n          },\n        });\n\n        assert.ok(recallResponse.content, \"Recall should succeed\");\n        assert.ok(\n          recallResponse.content[0].text.includes(\"E2E test with validation\"),\n          \"Should find the frame\"\n        );\n        assert.ok(\n          recallResponse.content[0].text.includes(\"services/auth-core\"),\n          \"Should include module scope\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n  });\n});\n\nconsole.log(\"\\nâœ… Alias Resolution Integration Tests - Module validation flow\\n\");\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/mcp_server/frames.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/mcp_server/integration.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'before' is defined but never used. Allowed unused vars must match /^_/u.","line":14,"column":26,"nodeType":null,"messageId":"unusedVar","endLine":14,"endColumn":32},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'after' is defined but never used. Allowed unused vars must match /^_/u.","line":14,"column":34,"nodeType":null,"messageId":"unusedVar","endLine":14,"endColumn":39},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":39,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":39,"endColumn":17}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Integration tests for MCP Server\n *\n * Tests the full MCP protocol integration:\n * - Full request/response cycle\n * - Real validation and error handling\n * - FTS5 search integration\n * - Frame filtering\n * - Module validation integration\n *\n * Run with: npm run build && node --test dist/integration.test.js\n */\n\nimport { test, describe, before, after } from \"node:test\";\nimport assert from \"node:assert\";\nimport { MCPServer } from \"@app/memory/mcp_server/server.js\";\nimport { mkdtempSync, rmSync } from \"fs\";\nimport { join } from \"path\";\nimport { tmpdir } from \"os\";\n\ndescribe(\"MCP Server Integration Tests\", () => {\n  let server: MCPServer;\n  let testDbPath: string;\n\n  function setup() {\n    const tmpDir = mkdtempSync(join(tmpdir(), \"mcp-integration-\"));\n    testDbPath = join(tmpDir, \"integration-test.db\");\n    server = new MCPServer(testDbPath);\n    return server;\n  }\n\n  function teardown() {\n    if (server) {\n      server.close();\n    }\n    if (testDbPath) {\n      try {\n        rmSync(testDbPath, { force: true });\n      } catch (e) {\n        // Ignore cleanup errors\n      }\n    }\n  }\n\n  describe(\"Full Request/Response Cycle\", () => {\n    test(\"should complete full remember â†’ recall cycle\", async () => {\n      const srv = setup();\n      try {\n        // Step 1: Create a Frame via lex.remember\n        const rememberArgs = {\n          reference_point: \"integration cycle test\",\n          summary_caption: \"Testing full MCP cycle\",\n          status_snapshot: {\n            next_action: \"Verify recall works\",\n            blockers: [],\n          },\n          module_scope: [\"policy/scanners\"],\n          keywords: [\"integration\", \"memory/mcp\", \"cycle\"],\n        };\n\n        const rememberResponse = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: rememberArgs,\n          },\n        });\n\n        assert.ok(rememberResponse.content, \"Remember should succeed\");\n        assert.ok(\n          rememberResponse.content[0].text.includes(\"âœ… Frame stored\"),\n          \"Should confirm storage\"\n        );\n\n        // Step 2: Recall the Frame\n        const recallResponse = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.recall\",\n            arguments: {\n              reference_point: \"integration cycle\",\n            },\n          },\n        });\n\n        assert.ok(recallResponse.content, \"Recall should succeed\");\n        assert.ok(\n          recallResponse.content[0].text.includes(\"Found 1 Frame\"),\n          \"Should find the Frame\"\n        );\n        assert.ok(\n          recallResponse.content[0].text.includes(\"integration cycle test\"),\n          \"Should include reference point\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should handle create â†’ list â†’ recall â†’ delete cycle\", async () => {\n      const srv = setup();\n      try {\n        // Create multiple frames\n        const frames = [\n          {\n            reference_point: \"first frame\",\n            summary_caption: \"First test frame\",\n            status_snapshot: { next_action: \"Test\" },\n            module_scope: [\"policy/scanners\"],\n          },\n          {\n            reference_point: \"second frame\",\n            summary_caption: \"Second test frame\",\n            status_snapshot: { next_action: \"Test\" },\n            module_scope: [\"shared/types\"],\n          },\n        ];\n\n        for (const frame of frames) {\n          await srv.handleRequest({\n            method: \"tools/call\",\n            params: {\n              name: \"lex.remember\",\n              arguments: frame,\n            },\n          });\n        }\n\n        // List frames\n        const listResponse = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.list_frames\",\n            arguments: { limit: 10 },\n          },\n        });\n\n        assert.ok(listResponse.content, \"List should succeed\");\n        assert.ok(\n          listResponse.content[0].text.includes(\"Recent Frames (2)\"),\n          \"Should list both frames\"\n        );\n\n        // Recall specific frame\n        const recallResponse = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.recall\",\n            arguments: {\n              reference_point: \"first frame\",\n            },\n          },\n        });\n\n        assert.ok(recallResponse.content, \"Response should have content\");\n        assert.ok(\n          recallResponse.content[0].text.includes(\"first frame\"),\n          \"Should find specific frame\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n  });\n\n  describe(\"Module Validation Integration\", () => {\n    test(\"should reject invalid module IDs with helpful error\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"invalid module test\",\n              summary_caption: \"Testing validation\",\n              status_snapshot: { next_action: \"Should fail\" },\n              module_scope: [\"invalid-module-xyz\"],\n            },\n          },\n        });\n\n        assert.ok(response.error, \"Should return error\");\n        assert.ok(\n          response.error.message.includes(\"Invalid module IDs\"),\n          \"Should indicate invalid modules\"\n        );\n        assert.ok(\n          response.error.message.includes(\"invalid-module-xyz\"),\n          \"Should mention the invalid module\"\n        );\n        assert.ok(\n          response.error.message.includes(\"Available modules\"),\n          \"Should list available modules\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should suggest similar modules for typos\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"typo test\",\n              summary_caption: \"Testing fuzzy matching\",\n              status_snapshot: { next_action: \"Test\" },\n              module_scope: [\"indexr\"], // Typo: should be \"policy/scanners\"\n            },\n          },\n        });\n\n        assert.ok(response.error, \"Should return error\");\n        assert.ok(response.error.message.includes(\"Did you mean\"), \"Should provide suggestions\");\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should accept all valid modules\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"all valid modules\",\n              summary_caption: \"Testing with all valid modules\",\n              status_snapshot: { next_action: \"Test\" },\n              module_scope: [\"policy/scanners\", \"shared/types\", \"memory/mcp\"],\n            },\n          },\n        });\n\n        assert.ok(response.content, \"Should succeed with valid modules\");\n        assert.ok(response.content[0].text.includes(\"âœ… Frame stored\"), \"Should confirm storage\");\n      } finally {\n        teardown();\n      }\n    });\n  });\n\n  describe(\"FTS5 Search Integration\", () => {\n    test(\"should find Frames using full-text search on reference_point\", async () => {\n      const srv = setup();\n      try {\n        // Create frames with different content\n        await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"authentication refactoring work\",\n              summary_caption: \"Refactored auth system\",\n              status_snapshot: { next_action: \"Test\" },\n              module_scope: [\"policy/scanners\"],\n            },\n          },\n        });\n\n        // Search should find it\n        const searchResponse = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.recall\",\n            arguments: {\n              reference_point: \"authentication refactoring\",\n            },\n          },\n        });\n\n        assert.ok(searchResponse.content, \"Search should succeed\");\n        assert.ok(\n          searchResponse.content[0].text.includes(\"authentication refactoring work\"),\n          \"Should find frame via FTS5\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should search across summary_caption and keywords\", async () => {\n      const srv = setup();\n      try {\n        await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"payment system\",\n              summary_caption: \"Stripe integration for payment processing\",\n              status_snapshot: { next_action: \"Deploy\" },\n              module_scope: [\"policy/scanners\"],\n              keywords: [\"payment\", \"stripe\", \"integration\"],\n            },\n          },\n        });\n\n        // Search by keyword\n        const keywordSearch = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.recall\",\n            arguments: {\n              reference_point: \"stripe\",\n            },\n          },\n        });\n\n        assert.ok(keywordSearch.content, \"Keyword search should have content\");\n        assert.ok(\n          keywordSearch.content[0].text.includes(\"payment system\"),\n          \"Should find via keyword search\"\n        );\n\n        // Search by summary\n        const summarySearch = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.recall\",\n            arguments: {\n              reference_point: \"integration processing\",\n            },\n          },\n        });\n\n        assert.ok(summarySearch.content, \"Summary search should have content\");\n        assert.ok(\n          summarySearch.content[0].text.includes(\"payment system\"),\n          \"Should find via summary search\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should handle fuzzy search with wildcards\", async () => {\n      const srv = setup();\n      try {\n        await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"database optimization\",\n              summary_caption: \"Optimized database queries\",\n              status_snapshot: { next_action: \"Benchmark\" },\n              module_scope: [\"policy/scanners\"],\n              keywords: [\"database\", \"performance\"],\n            },\n          },\n        });\n\n        // Wildcard search\n        const wildcardSearch = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.recall\",\n            arguments: {\n              reference_point: \"datab*\",\n            },\n          },\n        });\n\n        assert.ok(wildcardSearch.content, \"Wildcard search should have content\");\n        assert.ok(\n          wildcardSearch.content[0].text.includes(\"database optimization\"),\n          \"Should support wildcard search\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n  });\n\n  describe(\"Frame Filtering\", () => {\n    test(\"should filter frames by module scope\", async () => {\n      const srv = setup();\n      try {\n        // Create frames with different modules\n        await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"indexer work\",\n              summary_caption: \"Indexer module\",\n              status_snapshot: { next_action: \"Test\" },\n              module_scope: [\"policy/scanners\"],\n            },\n          },\n        });\n\n        await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"typescript work\",\n              summary_caption: \"TS module\",\n              status_snapshot: { next_action: \"Test\" },\n              module_scope: [\"shared/types\"],\n            },\n          },\n        });\n\n        // Filter by module\n        const filterResponse = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.list_frames\",\n            arguments: {\n              module: \"policy/scanners\",\n              limit: 10,\n            },\n          },\n        });\n\n        assert.ok(filterResponse.content, \"Filter response should have content\");\n        assert.ok(\n          filterResponse.content[0].text.includes(\"indexer work\"),\n          \"Should include indexer frame\"\n        );\n        assert.ok(\n          !filterResponse.content[0].text.includes(\"typescript work\"),\n          \"Should not include ts frame\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should limit results when requested\", async () => {\n      const srv = setup();\n      try {\n        // Create multiple frames\n        for (let i = 0; i < 5; i++) {\n          await srv.handleRequest({\n            method: \"tools/call\",\n            params: {\n              name: \"lex.remember\",\n              arguments: {\n                reference_point: `frame ${i}`,\n                summary_caption: `Frame ${i}`,\n                status_snapshot: { next_action: \"Test\" },\n                module_scope: [\"policy/scanners\"],\n              },\n            },\n          });\n        }\n\n        // Request limited results\n        const limitedResponse = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.list_frames\",\n            arguments: {\n              limit: 3,\n            },\n          },\n        });\n\n        assert.ok(limitedResponse.content, \"Limited response should have content\");\n        assert.ok(\n          limitedResponse.content[0].text.includes(\"Recent Frames (3)\"),\n          \"Should respect limit parameter\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n  });\n\n  describe(\"Error Handling\", () => {\n    test(\"should handle missing required fields gracefully\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.remember\",\n            arguments: {\n              reference_point: \"incomplete\",\n              // Missing: summary_caption, status_snapshot, module_scope\n            },\n          },\n        });\n\n        assert.ok(response.error, \"Should return error\");\n        assert.ok(\n          response.error.message.includes(\"Missing required fields\"),\n          \"Should indicate missing fields\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should handle empty search results\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.recall\",\n            arguments: {\n              reference_point: \"zzz-nonexistent-query-zzz\",\n            },\n          },\n        });\n\n        assert.ok(response.content, \"Should return content\");\n        assert.ok(\n          response.content[0].text.includes(\"No matching Frames found\"),\n          \"Should indicate no results\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should require at least one search parameter\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.recall\",\n            arguments: {},\n          },\n        });\n\n        assert.ok(response.error, \"Should return error\");\n        assert.ok(\n          response.error.message.includes(\"At least one search parameter required\"),\n          \"Should require search parameters\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should handle unknown methods\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"unknown/method\",\n        });\n\n        assert.ok(response.error, \"Should return error\");\n        assert.ok(\n          response.error.message.includes(\"Unknown method\"),\n          \"Should indicate unknown method\"\n        );\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should handle unknown tools\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/call\",\n          params: {\n            name: \"lex.unknown_tool\",\n            arguments: {},\n          },\n        });\n\n        assert.ok(response.error, \"Should return error\");\n        assert.ok(response.error.message.includes(\"Unknown tool\"), \"Should indicate unknown tool\");\n      } finally {\n        teardown();\n      }\n    });\n  });\n\n  describe(\"Protocol Compliance\", () => {\n    test(\"should list all available tools\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/list\",\n        });\n\n        assert.ok(response.tools, \"Should return tools array\");\n        assert.strictEqual(response.tools.length, 3, \"Should have 3 tools\");\n\n        const toolNames = response.tools.map((t) => t.name);\n        assert.ok(toolNames.includes(\"lex.remember\"));\n        assert.ok(toolNames.includes(\"lex.recall\"));\n        assert.ok(toolNames.includes(\"lex.list_frames\"));\n      } finally {\n        teardown();\n      }\n    });\n\n    test(\"should include tool schemas in tools/list\", async () => {\n      const srv = setup();\n      try {\n        const response = await srv.handleRequest({\n          method: \"tools/list\",\n        });\n\n        const rememberTool = response.tools?.find((t) => t.name === \"lex.remember\");\n        assert.ok(rememberTool, \"Should include lex.remember\");\n        assert.ok(rememberTool.inputSchema, \"Should include input schema\");\n        assert.ok(rememberTool.inputSchema.properties, \"Schema should have properties\");\n      } finally {\n        teardown();\n      }\n    });\n  });\n});\n\nconsole.log(\"\\nâœ… MCP Server Integration Tests - Full protocol coverage\\n\");\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/mcp_server/server.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":35,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":35,"endColumn":17}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Tests for Frame MCP Server\n *\n * Tests the MCP protocol implementation for Frame storage and recall.\n * Uses Node.js built-in test runner (node:test) - no external dependencies.\n */\n\nimport { test, describe } from \"node:test\";\nimport assert from \"node:assert\";\nimport { MCPServer } from \"@app/memory/mcp_server/server.js\";\nimport { mkdtempSync, rmSync } from \"fs\";\nimport { join } from \"path\";\nimport { tmpdir } from \"os\";\n\ndescribe(\"MCP Server - Protocol\", () => {\n  let server: MCPServer;\n  let testDbPath: string;\n\n  // Setup: create test database in temp directory\n  function setup() {\n    const tmpDir = mkdtempSync(join(tmpdir(), \"lex-test-\"));\n    testDbPath = join(tmpDir, \"test-frames.db\");\n    server = new MCPServer(testDbPath);\n    return server;\n  }\n\n  // Teardown: close database and cleanup\n  function teardown() {\n    if (server) {\n      server.close();\n    }\n    if (testDbPath) {\n      try {\n        rmSync(testDbPath, { force: true });\n      } catch (e) {\n        // Ignore cleanup errors\n      }\n    }\n  }\n\n  test(\"tools/list returns all available tools\", async () => {\n    const srv = setup();\n    try {\n      const response = await srv.handleRequest({ method: \"tools/list\" });\n\n      assert.ok(response.tools, \"Response should have tools array\");\n      assert.strictEqual(response.tools.length, 3, \"Should have 3 tools\");\n\n      const toolNames = response.tools.map((t) => t.name);\n      assert.ok(toolNames.includes(\"lex.remember\"), \"Should include lex.remember\");\n      assert.ok(toolNames.includes(\"lex.recall\"), \"Should include lex.recall\");\n      assert.ok(toolNames.includes(\"lex.list_frames\"), \"Should include lex.list_frames\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.remember creates a Frame with valid data\", async () => {\n    const srv = setup();\n    try {\n      const args = {\n        reference_point: \"test memory\",\n        summary_caption: \"Testing Frame creation\",\n        status_snapshot: {\n          next_action: \"Verify storage\",\n          blockers: [],\n        },\n        module_scope: [\"policy/scanners\"],\n      };\n\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: args,\n        },\n      });\n\n      assert.ok(response.content, \"Response should have content\");\n      assert.ok(\n        response.content[0].text.includes(\"âœ… Frame stored\"),\n        \"Should confirm Frame storage\"\n      );\n      assert.ok(response.content[0].text.includes(\"test memory\"), \"Should include reference point\");\n      assert.ok(response.content[0].text.includes(\"Atlas Frame\"), \"Should include Atlas Frame\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.remember fails with missing required fields\", async () => {\n    const srv = setup();\n    try {\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: {\n            reference_point: \"incomplete data\",\n            // Missing: summary_caption, status_snapshot, module_scope\n          },\n        },\n      });\n\n      assert.ok(response.error, \"Should return error\");\n      assert.ok(\n        response.error.message.includes(\"Missing required fields\"),\n        \"Error should mention missing fields\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.recall finds stored Frames by reference_point\", async () => {\n    const srv = setup();\n    try {\n      // First, create a Frame\n      await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: {\n            reference_point: \"authentication refactoring\",\n            summary_caption: \"Extracted password validation\",\n            status_snapshot: {\n              next_action: \"Add unit tests\",\n              blockers: [],\n            },\n            module_scope: [\"shared/types\"],\n          },\n        },\n      });\n\n      // Then, recall it\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.recall\",\n          arguments: {\n            reference_point: \"authentication\",\n          },\n        },\n      });\n\n      assert.ok(response.content, \"Response should have content\");\n      assert.ok(response.content[0].text.includes(\"Found 1 Frame\"), \"Should find 1 Frame\");\n      assert.ok(\n        response.content[0].text.includes(\"authentication refactoring\"),\n        \"Should include reference point\"\n      );\n      assert.ok(response.content[0].text.includes(\"Atlas Frame\"), \"Should include Atlas Frame\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.recall returns empty result for non-existent query\", async () => {\n    const srv = setup();\n    try {\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.recall\",\n          arguments: {\n            reference_point: \"nonexistent work\",\n          },\n        },\n      });\n\n      assert.ok(response.content, \"Response should have content\");\n      assert.ok(\n        response.content[0].text.includes(\"No matching Frames found\"),\n        \"Should indicate no results\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.recall fails without search parameters\", async () => {\n    const srv = setup();\n    try {\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.recall\",\n          arguments: {}, // No search parameters\n        },\n      });\n\n      assert.ok(response.error, \"Should return error\");\n      assert.ok(\n        response.error.message.includes(\"At least one search parameter required\"),\n        \"Error should mention missing parameters\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.list_frames returns recent Frames\", async () => {\n    const srv = setup();\n    try {\n      // Create two Frames\n      await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: {\n            reference_point: \"frame one\",\n            summary_caption: \"First test frame\",\n            status_snapshot: { next_action: \"Test\" },\n            module_scope: [\"policy/scanners\"],\n          },\n        },\n      });\n\n      await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: {\n            reference_point: \"frame two\",\n            summary_caption: \"Second test frame\",\n            status_snapshot: { next_action: \"Test\" },\n            module_scope: [\"shared/types\"],\n          },\n        },\n      });\n\n      // List frames\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.list_frames\",\n          arguments: { limit: 10 },\n        },\n      });\n\n      assert.ok(response.content, \"Response should have content\");\n      assert.ok(response.content[0].text.includes(\"Recent Frames (2)\"), \"Should list 2 frames\");\n      assert.ok(response.content[0].text.includes(\"frame one\"), \"Should include first frame\");\n      assert.ok(response.content[0].text.includes(\"frame two\"), \"Should include second frame\");\n      assert.ok(response.content[0].text.includes(\"Atlas Frame\"), \"Should include Atlas Frames\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.list_frames filters by module\", async () => {\n    const srv = setup();\n    try {\n      // Create two Frames with different modules\n      await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: {\n            reference_point: \"auth work\",\n            summary_caption: \"Auth module work\",\n            status_snapshot: { next_action: \"Test\" },\n            module_scope: [\"policy/scanners\"],\n          },\n        },\n      });\n\n      await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: {\n            reference_point: \"ui work\",\n            summary_caption: \"UI module work\",\n            status_snapshot: { next_action: \"Test\" },\n            module_scope: [\"memory/mcp\"],\n          },\n        },\n      });\n\n      // List only auth module frames\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.list_frames\",\n          arguments: { module: \"policy/scanners\", limit: 10 },\n        },\n      });\n\n      assert.ok(response.content, \"Response should have content\");\n      assert.ok(response.content[0].text.includes(\"Recent Frames (1)\"), \"Should list 1 frame\");\n      assert.ok(response.content[0].text.includes(\"auth work\"), \"Should include auth frame\");\n      assert.ok(!response.content[0].text.includes(\"ui work\"), \"Should not include ui frame\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"unknown method returns error\", async () => {\n    const srv = setup();\n    try {\n      const response = await srv.handleRequest({\n        method: \"unknown/method\",\n      });\n\n      assert.ok(response.error, \"Should return error\");\n      assert.ok(\n        response.error.message.includes(\"Unknown method\"),\n        \"Error should mention unknown method\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"unknown tool returns error\", async () => {\n    const srv = setup();\n    try {\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.unknown_tool\",\n          arguments: {},\n        },\n      });\n\n      assert.ok(response.error, \"Should return error\");\n      assert.ok(\n        response.error.message.includes(\"Unknown tool\"),\n        \"Error should mention unknown tool\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  // Image attachment tests (PR #27)\n  test(\"lex.remember stores Frame with image attachments\", async () => {\n    const srv = setup();\n    try {\n      // Create a small test image (base64-encoded PNG)\n      const testImageData = Buffer.from(\"fake-png-data\").toString(\"base64\");\n\n      const args = {\n        reference_point: \"test with images\",\n        summary_caption: \"Testing image attachment\",\n        status_snapshot: {\n          next_action: \"Verify image storage\",\n        },\n        module_scope: [\"policy/scanners\"], // Use valid module from policy\n        images: [\n          {\n            data: testImageData,\n            mime_type: \"image/png\",\n          },\n        ],\n      };\n\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: args,\n        },\n      });\n\n      assert.ok(response.content, \"Response should have content\");\n      assert.ok(\n        response.content[0].text.includes(\"âœ… Frame stored\"),\n        \"Should confirm Frame storage\"\n      );\n      assert.ok(\n        response.content[0].text.includes(\"ðŸ–¼ï¸  Images: 1 attached\"),\n        \"Should indicate image attachment\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.remember stores Frame with multiple image attachments\", async () => {\n    const srv = setup();\n    try {\n      const image1 = Buffer.from(\"png-data\").toString(\"base64\");\n      const image2 = Buffer.from(\"jpeg-data\").toString(\"base64\");\n\n      const args = {\n        reference_point: \"test with multiple images\",\n        summary_caption: \"Testing multiple image attachments\",\n        status_snapshot: {\n          next_action: \"Verify multi-image storage\",\n        },\n        module_scope: [\"shared/types\"], // Use valid module from policy\n        images: [\n          { data: image1, mime_type: \"image/png\" },\n          { data: image2, mime_type: \"image/jpeg\" },\n        ],\n      };\n\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: args,\n        },\n      });\n\n      assert.ok(response.content, \"Response should have content\");\n      assert.ok(\n        response.content[0].text.includes(\"ðŸ–¼ï¸  Images: 2 attached\"),\n        \"Should indicate 2 images attached\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.remember fails with invalid image MIME type\", async () => {\n    const srv = setup();\n    try {\n      const testImageData = Buffer.from(\"fake-data\").toString(\"base64\");\n\n      const args = {\n        reference_point: \"test with invalid image\",\n        summary_caption: \"Testing invalid image type\",\n        status_snapshot: {\n          next_action: \"Should fail\",\n        },\n        module_scope: [\"policy/scanners\"], // Use valid module from policy\n        images: [\n          {\n            data: testImageData,\n            mime_type: \"application/pdf\", // Invalid MIME type\n          },\n        ],\n      };\n\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: args,\n        },\n      });\n\n      assert.ok(response.error, \"Should return error\");\n      assert.ok(\n        response.error.message.includes(\"Failed to store image\"),\n        \"Error should mention image storage failure\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.remember fails with oversized image\", async () => {\n    const srv = setup();\n    try {\n      // Create base64 of a buffer larger than 10MB\n      const largeBuffer = Buffer.alloc(11 * 1024 * 1024);\n      const testImageData = largeBuffer.toString(\"base64\");\n\n      const args = {\n        reference_point: \"test with oversized image\",\n        summary_caption: \"Testing oversized image\",\n        status_snapshot: {\n          next_action: \"Should fail\",\n        },\n        module_scope: [\"memory/mcp\"], // Use valid module from policy\n        images: [\n          {\n            data: testImageData,\n            mime_type: \"image/png\",\n          },\n        ],\n      };\n\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: args,\n        },\n      });\n\n      assert.ok(response.error, \"Should return error\");\n      assert.ok(\n        response.error.message.includes(\"exceeds maximum\"),\n        \"Error should mention size limit\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  // Integration tests for module ID validation (THE CRITICAL RULE) - PR #28\n  test(\"lex.remember validates module IDs - rejects invalid module\", async () => {\n    const srv = setup();\n    try {\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: {\n            reference_point: \"invalid module test\",\n            summary_caption: \"Testing validation\",\n            status_snapshot: { next_action: \"Test\" },\n            module_scope: [\"invalid-module\"],\n          },\n        },\n      });\n\n      assert.ok(response.error, \"Should return error for invalid module\");\n      assert.ok(\n        response.error.message.includes(\"Invalid module IDs\"),\n        \"Error should mention invalid module IDs\"\n      );\n      assert.ok(\n        response.error.message.includes(\"invalid-module\"),\n        \"Error should mention the specific invalid module\"\n      );\n      assert.ok(\n        response.error.message.includes(\"Available modules\"),\n        \"Error should list available modules\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.remember validates module IDs - suggests similar modules\", async () => {\n    const srv = setup();\n    try {\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: {\n            reference_point: \"typo test\",\n            summary_caption: \"Testing fuzzy matching\",\n            status_snapshot: { next_action: \"Test\" },\n            module_scope: [\"indexr\"], // Typo: should be \"policy/scanners\"\n          },\n        },\n      });\n\n      assert.ok(response.error, \"Should return error for typo\");\n      assert.ok(response.error.message.includes(\"indexr\"), \"Error should mention the typo\");\n      assert.ok(\n        response.error.message.includes(\"Did you mean\"),\n        \"Error should provide suggestions\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.remember validates module IDs - reports multiple invalid modules\", async () => {\n    const srv = setup();\n    try {\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: {\n            reference_point: \"multiple errors test\",\n            summary_caption: \"Testing multiple validation errors\",\n            status_snapshot: { next_action: \"Test\" },\n            module_scope: [\"invalid1\", \"invalid2\", \"invalid3\"],\n          },\n        },\n      });\n\n      assert.ok(response.error, \"Should return error for invalid modules\");\n      assert.ok(\n        response.error.message.includes(\"invalid1\"),\n        \"Error should mention first invalid module\"\n      );\n      assert.ok(\n        response.error.message.includes(\"invalid2\"),\n        \"Error should mention second invalid module\"\n      );\n      assert.ok(\n        response.error.message.includes(\"invalid3\"),\n        \"Error should mention third invalid module\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.remember validates module IDs - mix of valid and invalid\", async () => {\n    const srv = setup();\n    try {\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: {\n            reference_point: \"mixed validity test\",\n            summary_caption: \"Testing mixed valid/invalid modules\",\n            status_snapshot: { next_action: \"Test\" },\n            module_scope: [\"policy/scanners\", \"invalid-module\", \"shared/types\"],\n          },\n        },\n      });\n\n      assert.ok(response.error, \"Should return error when any module is invalid\");\n      assert.ok(\n        response.error.message.includes(\"invalid-module\"),\n        \"Error should mention the invalid module\"\n      );\n      // Valid modules should only appear in \"Available modules\" list, not as errors\n      const errorLines = response.error.message.split(\"\\n\").filter((line) => line.includes(\"â€¢\"));\n      const hasValidModuleError = errorLines.some(\n        (line) => line.includes(\"policy/scanners\") || line.includes(\"shared/types\")\n      );\n      assert.ok(!hasValidModuleError, \"Error should not flag valid modules as invalid\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.remember validates module IDs - accepts all valid modules\", async () => {\n    const srv = setup();\n    try {\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: {\n            reference_point: \"all valid modules\",\n            summary_caption: \"Testing with all policy modules\",\n            status_snapshot: { next_action: \"Test\" },\n            module_scope: [\"policy/scanners\", \"shared/types\", \"memory/mcp\"],\n          },\n        },\n      });\n\n      assert.ok(response.content, \"Should succeed with all valid modules\");\n      assert.ok(\n        response.content[0].text.includes(\"âœ… Frame stored\"),\n        \"Should confirm Frame storage\"\n      );\n      assert.ok(\n        response.content[0].text.includes(\"policy/scanners\") &&\n          response.content[0].text.includes(\"shared/types\") &&\n          response.content[0].text.includes(\"memory/mcp\"),\n        \"Should include all modules\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  // Branch detection tests (PR #29)\n  test(\"lex.remember auto-detects git branch when not provided\", async () => {\n    const srv = setup();\n    try {\n      const args = {\n        reference_point: \"branch detection test\",\n        summary_caption: \"Testing auto-detection\",\n        status_snapshot: {\n          next_action: \"Verify branch detection\",\n          blockers: [],\n        },\n        module_scope: [\"policy/scanners\"],\n      };\n\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: args,\n        },\n      });\n\n      assert.ok(response.content, \"Response should have content\");\n      const text = response.content[0].text;\n      assert.ok(text.includes(\"ðŸŒ¿ Branch:\"), \"Should include branch info\");\n      assert.ok(!text.includes(\"Branch: main\"), \"Should not hardcode main\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"lex.remember respects provided branch over auto-detection\", async () => {\n    const srv = setup();\n    try {\n      const args = {\n        reference_point: \"manual branch test\",\n        summary_caption: \"Testing manual branch override\",\n        status_snapshot: {\n          next_action: \"Verify manual branch\",\n          blockers: [],\n        },\n        module_scope: [\"policy/scanners\"],\n        branch: \"custom-branch-name\",\n      };\n\n      const response = await srv.handleRequest({\n        method: \"tools/call\",\n        params: {\n          name: \"lex.remember\",\n          arguments: args,\n        },\n      });\n\n      assert.ok(response.content, \"Response should have content\");\n      assert.ok(\n        response.content[0].text.includes(\"ðŸŒ¿ Branch: custom-branch-name\"),\n        \"Should use provided branch name\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n});\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/renderer/card.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'err' is defined but never used.","line":237,"column":12,"nodeType":null,"messageId":"unusedVar","endLine":237,"endColumn":15}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Test suite for memory card rendering\n * Run with: node --loader tsx memory/renderer/card.test.ts\n */\n\nimport { renderMemoryCard, renderMemoryCardWithOptions } from \"@app/memory/renderer/card.js\";\nimport type { Frame } from \"@app/memory/frames/types.js\";\nimport { writeFileSync, mkdirSync } from \"fs\";\nimport { join } from \"path\";\n\n// Test output directory\nconst TEST_OUTPUT_DIR = \"/tmp/memory-card-tests\";\n\n/**\n * Test helper to create a minimal Frame\n */\nfunction createMinimalFrame(): Frame {\n  return {\n    id: \"frame-minimal-001\",\n    timestamp: new Date().toISOString(),\n    branch: \"main\",\n    module_scope: [\"memory/renderer\"],\n    summary_caption: \"Minimal test frame\",\n    reference_point: \"Basic rendering test\",\n    status_snapshot: {\n      next_action: \"Verify minimal frame renders correctly\",\n    },\n  };\n}\n\n/**\n * Test helper to create a full Frame with all optional fields\n */\nfunction createFullFrame(): Frame {\n  return {\n    id: \"frame-full-002\",\n    timestamp: new Date().toISOString(),\n    branch: \"feature/memory-card-rendering\",\n    jira: \"LEX-123\",\n    module_scope: [\"memory/renderer\", \"memory/frames\", \"memory/store\"],\n    summary_caption:\n      \"Full featured test frame with all optional fields populated to test rendering capabilities\",\n    reference_point: \"Complete frame with blockers, keywords, and atlas reference\",\n    status_snapshot: {\n      next_action:\n        \"Continue implementing memory card visual rendering with canvas library and ensure all fields are properly displayed\",\n      blockers: [\"Canvas library installation pending\", \"Test infrastructure needs setup\"],\n      merge_blockers: [\"PR review required\", \"Integration tests failing\"],\n      tests_failing: [\n        \"test_memory_card_minimal\",\n        \"test_memory_card_full\",\n        \"test_long_text_handling\",\n      ],\n    },\n    keywords: [\"memory\", \"rendering\", \"canvas\", \"visual\", \"testing\", \"frames\"],\n    atlas_frame_id: \"atlas-frame-xyz789\",\n    feature_flags: [\"enable-visual-rendering\"],\n    permissions: [\"read\", \"write\"],\n  };\n}\n\n/**\n * Test helper to create a Frame with very long text\n */\nfunction createLongTextFrame(): Frame {\n  return {\n    id: \"frame-longtext-003\",\n    timestamp: new Date().toISOString(),\n    branch: \"test/long-text-handling\",\n    module_scope: [\"memory/renderer\"],\n    summary_caption:\n      \"This is a very long summary caption that should be truncated or wrapped properly to fit within the card boundaries without overflowing or breaking the layout. It contains many words and should demonstrate text handling capabilities.\",\n    reference_point:\n      \"Testing extremely long reference point text that needs to be handled gracefully with either truncation or wrapping mechanisms\",\n    status_snapshot: {\n      next_action:\n        \"Test the memory card renderer with various edge cases including very long text strings that might exceed the normal display boundaries and need to be wrapped across multiple lines or truncated with ellipsis to maintain readability and visual consistency throughout the rendered card image.\",\n      blockers: [\n        \"This is a very long blocker description that should be truncated because it exceeds the maximum allowed length for a single blocker item in the display\",\n      ],\n    },\n    keywords: Array(15)\n      .fill(\"keyword\")\n      .map((k, i) => `${k}${i}`),\n  };\n}\n\n/**\n * Test 1: Render minimal Frame\n */\nasync function testMinimalFrame() {\n  console.log(\"Test 1: Rendering minimal Frame...\");\n  const frame = createMinimalFrame();\n  const buffer = await renderMemoryCard(frame);\n\n  // Verify buffer is valid\n  if (!Buffer.isBuffer(buffer)) {\n    throw new Error(\"Output is not a Buffer\");\n  }\n\n  // Check PNG signature\n  const pngSignature = Buffer.from([0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a]);\n  if (!buffer.subarray(0, 8).equals(pngSignature)) {\n    throw new Error(\"Output is not a valid PNG\");\n  }\n\n  // Save for manual inspection\n  const outputPath = join(TEST_OUTPUT_DIR, \"test-minimal-frame.png\");\n  writeFileSync(outputPath, buffer);\n\n  console.log(`âœ“ Minimal frame rendered successfully (${buffer.length} bytes)`);\n  console.log(`  Saved to: ${outputPath}`);\n}\n\n/**\n * Test 2: Render full Frame with all optional fields\n */\nasync function testFullFrame() {\n  console.log(\"Test 2: Rendering full Frame...\");\n  const frame = createFullFrame();\n  const buffer = await renderMemoryCard(frame);\n\n  // Verify buffer is valid\n  if (!Buffer.isBuffer(buffer)) {\n    throw new Error(\"Output is not a Buffer\");\n  }\n\n  // Check PNG signature\n  const pngSignature = Buffer.from([0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a]);\n  if (!buffer.subarray(0, 8).equals(pngSignature)) {\n    throw new Error(\"Output is not a valid PNG\");\n  }\n\n  // Should be larger than minimal due to more content\n  const outputPath = join(TEST_OUTPUT_DIR, \"test-full-frame.png\");\n  writeFileSync(outputPath, buffer);\n\n  console.log(`âœ“ Full frame rendered successfully (${buffer.length} bytes)`);\n  console.log(`  Saved to: ${outputPath}`);\n}\n\n/**\n * Test 3: Handle long text (truncation/wrapping)\n */\nasync function testLongTextHandling() {\n  console.log(\"Test 3: Testing long text handling...\");\n  const frame = createLongTextFrame();\n  const buffer = await renderMemoryCard(frame);\n\n  // Verify buffer is valid\n  if (!Buffer.isBuffer(buffer)) {\n    throw new Error(\"Output is not a Buffer\");\n  }\n\n  const outputPath = join(TEST_OUTPUT_DIR, \"test-long-text.png\");\n  writeFileSync(outputPath, buffer);\n\n  console.log(`âœ“ Long text handled successfully (${buffer.length} bytes)`);\n  console.log(`  Saved to: ${outputPath}`);\n}\n\n/**\n * Test 4: Render with raw context\n */\nasync function testRawContext() {\n  console.log(\"Test 4: Testing raw context rendering...\");\n  const frame = createMinimalFrame();\n  const rawContext = `\nRecent logs:\n[2024-11-02 17:00:00] Starting memory card rendering\n[2024-11-02 17:00:01] Canvas initialized\n[2024-11-02 17:00:02] Frame data loaded\n[2024-11-02 17:00:03] Rendering complete\n\nRecent changes:\n+ Added renderMemoryCard function to card.ts\n+ Implemented canvas-based image generation\n+ Created test suite with 5+ test cases\n  `;\n\n  const buffer = await renderMemoryCard(frame, rawContext);\n\n  // Verify buffer is valid\n  if (!Buffer.isBuffer(buffer)) {\n    throw new Error(\"Output is not a Buffer\");\n  }\n\n  const outputPath = join(TEST_OUTPUT_DIR, \"test-raw-context.png\");\n  writeFileSync(outputPath, buffer);\n\n  console.log(`âœ“ Raw context rendered successfully (${buffer.length} bytes)`);\n  console.log(`  Saved to: ${outputPath}`);\n}\n\n/**\n * Test 5: Verify output is readable at various sizes\n */\nasync function testReadabilityAtSizes() {\n  console.log(\"Test 5: Testing readability at various sizes...\");\n  const frame = createFullFrame();\n\n  // Test with custom dimensions\n  const sizes = [\n    { width: 600, height: 800, name: \"small\" },\n    { width: 800, height: 1000, name: \"medium\" },\n    { width: 1000, height: 1200, name: \"large\" },\n  ];\n\n  for (const size of sizes) {\n    const buffer = await renderMemoryCardWithOptions(frame, {\n      dimensions: {\n        width: size.width,\n        height: size.height,\n        padding: 40,\n        lineHeight: 24,\n      },\n    });\n\n    const outputPath = join(TEST_OUTPUT_DIR, `test-size-${size.name}.png`);\n    writeFileSync(outputPath, buffer);\n\n    console.log(`  âœ“ ${size.name} size (${size.width}x${size.height}): ${buffer.length} bytes`);\n  }\n\n  console.log(\"âœ“ All size variations rendered successfully\");\n}\n\n/**\n * Run all tests\n */\nasync function runTests() {\n  console.log(\"=== Memory Card Renderer Test Suite ===\\n\");\n\n  // Create output directory\n  try {\n    mkdirSync(TEST_OUTPUT_DIR, { recursive: true });\n  } catch (err) {\n    // Directory already exists\n  }\n\n  try {\n    await testMinimalFrame();\n    console.log();\n\n    await testFullFrame();\n    console.log();\n\n    await testLongTextHandling();\n    console.log();\n\n    await testRawContext();\n    console.log();\n\n    await testReadabilityAtSizes();\n    console.log();\n\n    console.log(\"=== All Tests Passed âœ“ ===\");\n    console.log(`\\nTest outputs saved to: ${TEST_OUTPUT_DIR}`);\n    console.log(\"Open the PNG files to visually verify rendering quality.\");\n  } catch (error) {\n    console.error(\"\\n=== Test Failed âœ— ===\");\n    console.error(error);\n    process.exit(1);\n  }\n}\n\n// Run tests if this file is executed directly\nrunTests();\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/renderer/diff.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/renderer/graph.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/renderer/syntax.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/renderer/timeline.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/store/images.perf.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'_e' is defined but never used.","line":31,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":31,"endColumn":18}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { test, describe } from \"node:test\";\nimport assert from \"node:assert\";\nimport { createDatabase } from \"@app/memory/store/db.js\";\nimport { saveFrame } from \"@app/memory/store/queries.js\";\nimport { ImageManager } from \"@app/memory/store/images.js\";\nimport { mkdtempSync, rmSync } from \"fs\";\nimport { join } from \"path\";\nimport { tmpdir } from \"os\";\nimport type Database from \"better-sqlite3\";\n\ndescribe(\"Image Manager - Performance\", () => {\n  let db: Database.Database;\n  let imageManager: ImageManager;\n  let testDbPath: string;\n\n  function setup() {\n    const tmpDir = mkdtempSync(join(tmpdir(), \"lex-perf-test-\"));\n    testDbPath = join(tmpDir, \"test-perf.db\");\n    db = createDatabase(testDbPath);\n    imageManager = new ImageManager(db);\n    return { db, imageManager };\n  }\n\n  function teardown() {\n    if (db) {\n      db.close();\n    }\n    if (testDbPath) {\n      try {\n        rmSync(testDbPath, { force: true });\n      } catch (_e) {\n        // Ignore cleanup errors\n      }\n    }\n  }\n\n  function createTestFrame(id: string) {\n    const frame = {\n      id,\n      timestamp: new Date().toISOString(),\n      branch: \"main\",\n      module_scope: [\"test/module\"],\n      summary_caption: \"Test frame\",\n      reference_point: \"test reference\",\n      status_snapshot: {\n        next_action: \"Test action\",\n      },\n    };\n    saveFrame(db, frame);\n    return frame;\n  }\n\n  test(\"store and retrieve 100 images efficiently\", () => {\n    const { imageManager } = setup();\n    try {\n      const imageCount = 100;\n      const imageSize = 1024; // 1KB per image\n      const imageIds: string[] = [];\n\n      // Create 10 frames with 10 images each\n      const startStore = Date.now();\n      for (let f = 0; f < 10; f++) {\n        const frame = createTestFrame(`frame-${f}`);\n\n        for (let i = 0; i < 10; i++) {\n          const imageData = Buffer.alloc(imageSize, `img-${f}-${i}`);\n          const imageId = imageManager.storeImage(frame.id, imageData, \"image/png\");\n          imageIds.push(imageId);\n        }\n      }\n      const storeTime = Date.now() - startStore;\n\n      console.log(\n        `  Stored ${imageCount} images in ${storeTime}ms (${(storeTime / imageCount).toFixed(2)}ms per image)`\n      );\n\n      // Verify all images were stored\n      const totalCount = imageManager.getImageCount();\n      assert.strictEqual(totalCount, imageCount, `Should have ${imageCount} images`);\n\n      // Retrieve all images\n      const startRetrieve = Date.now();\n      for (const imageId of imageIds) {\n        const retrieved = imageManager.getImage(imageId);\n        assert.ok(retrieved, `Image ${imageId} should be retrievable`);\n      }\n      const retrieveTime = Date.now() - startRetrieve;\n\n      console.log(\n        `  Retrieved ${imageCount} images in ${retrieveTime}ms (${(retrieveTime / imageCount).toFixed(2)}ms per image)`\n      );\n\n      // Performance assertions\n      assert.ok(storeTime < 5000, \"Storing 100 images should take less than 5 seconds\");\n      assert.ok(retrieveTime < 2000, \"Retrieving 100 images should take less than 2 seconds\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"list images for frames with many attachments\", () => {\n    const { imageManager } = setup();\n    try {\n      const imagesPerFrame = 20;\n      const frameCount = 10;\n\n      // Create frames with many images\n      const startSetup = Date.now();\n      for (let f = 0; f < frameCount; f++) {\n        const frame = createTestFrame(`frame-${f}`);\n\n        for (let i = 0; i < imagesPerFrame; i++) {\n          const imageData = Buffer.alloc(512, `data-${f}-${i}`);\n          imageManager.storeImage(frame.id, imageData, \"image/png\");\n        }\n      }\n      const setupTime = Date.now() - startSetup;\n      console.log(\n        `  Setup ${frameCount} frames with ${imagesPerFrame} images each in ${setupTime}ms`\n      );\n\n      // List images for each frame\n      const startList = Date.now();\n      for (let f = 0; f < frameCount; f++) {\n        const images = imageManager.listFrameImages(`frame-${f}`);\n        assert.strictEqual(\n          images.length,\n          imagesPerFrame,\n          `Frame ${f} should have ${imagesPerFrame} images`\n        );\n\n        // Verify metadata\n        for (const img of images) {\n          assert.strictEqual(img.frame_id, `frame-${f}`, \"Frame ID should match\");\n          assert.strictEqual(img.mime_type, \"image/png\", \"MIME type should match\");\n          assert.ok(img.size > 0, \"Size should be positive\");\n          assert.ok(img.created_at > 0, \"Created timestamp should be set\");\n        }\n      }\n      const listTime = Date.now() - startList;\n\n      console.log(\n        `  Listed images for ${frameCount} frames in ${listTime}ms (${(listTime / frameCount).toFixed(2)}ms per frame)`\n      );\n\n      // Performance assertion\n      assert.ok(listTime < 1000, \"Listing images for 10 frames should take less than 1 second\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"delete operations with large datasets\", () => {\n    const { imageManager } = setup();\n    try {\n      const imageCount = 50;\n      const frame = createTestFrame(\"delete-test-frame\");\n      const imageIds: string[] = [];\n\n      // Store images\n      for (let i = 0; i < imageCount; i++) {\n        const imageData = Buffer.alloc(256, `data-${i}`);\n        const imageId = imageManager.storeImage(frame.id, imageData, \"image/png\");\n        imageIds.push(imageId);\n      }\n\n      assert.strictEqual(imageManager.getImageCount(), imageCount, \"Should have all images\");\n\n      // Delete images individually\n      const startDelete = Date.now();\n      let deleteCount = 0;\n      for (const imageId of imageIds) {\n        const deleted = imageManager.deleteImage(imageId);\n        if (deleted) deleteCount++;\n      }\n      const deleteTime = Date.now() - startDelete;\n\n      console.log(\n        `  Deleted ${deleteCount} images in ${deleteTime}ms (${(deleteTime / deleteCount).toFixed(2)}ms per image)`\n      );\n\n      assert.strictEqual(deleteCount, imageCount, \"Should have deleted all images\");\n      assert.strictEqual(imageManager.getImageCount(), 0, \"Should have no images left\");\n\n      // Performance assertion\n      assert.ok(deleteTime < 2000, \"Deleting 50 images should take less than 2 seconds\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"total storage size calculation with many images\", () => {\n    const { imageManager } = setup();\n    try {\n      const imageSize = 2048; // 2KB per image\n      const imageCount = 100;\n      let expectedTotal = 0;\n\n      // Store images of varying sizes\n      for (let i = 0; i < imageCount; i++) {\n        const frameId = `size-frame-${i}`;\n        const frame = createTestFrame(frameId);\n        const size = imageSize + i * 10; // Gradually increasing size\n        const imageData = Buffer.alloc(size, `data-${i}`);\n        imageManager.storeImage(frame.id, imageData, \"image/png\");\n        expectedTotal += size;\n      }\n\n      const actualTotal = imageManager.getTotalImageSize();\n      assert.strictEqual(actualTotal, expectedTotal, \"Total size should match sum of all images\");\n\n      console.log(\n        `  Total storage: ${(actualTotal / 1024 / 1024).toFixed(2)} MB for ${imageCount} images`\n      );\n      console.log(`  Average size: ${(actualTotal / imageCount / 1024).toFixed(2)} KB per image`);\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"cascading delete performance with many images\", () => {\n    const { imageManager } = setup();\n    try {\n      const framesCount = 5;\n      const imagesPerFrame = 20;\n\n      // Create frames with images\n      for (let f = 0; f < framesCount; f++) {\n        const frame = createTestFrame(`cascade-frame-${f}`);\n\n        for (let i = 0; i < imagesPerFrame; i++) {\n          const imageData = Buffer.alloc(128, `data-${f}-${i}`);\n          imageManager.storeImage(frame.id, imageData, \"image/png\");\n        }\n      }\n\n      const totalImages = framesCount * imagesPerFrame;\n      assert.strictEqual(imageManager.getImageCount(), totalImages, \"Should have all images\");\n\n      // Delete frames (should cascade to images)\n      const startCascade = Date.now();\n      for (let f = 0; f < framesCount; f++) {\n        const deleteStmt = db.prepare(\"DELETE FROM frames WHERE id = ?\");\n        deleteStmt.run(`cascade-frame-${f}`);\n      }\n      const cascadeTime = Date.now() - startCascade;\n\n      console.log(\n        `  Cascading delete of ${framesCount} frames (${totalImages} images) in ${cascadeTime}ms`\n      );\n\n      // Verify all images were deleted\n      assert.strictEqual(imageManager.getImageCount(), 0, \"All images should be deleted\");\n\n      // Performance assertion\n      assert.ok(cascadeTime < 1000, \"Cascading delete should take less than 1 second\");\n    } finally {\n      teardown();\n    }\n  });\n});\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/store/images.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'_e' is defined but never used.","line":40,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":40,"endColumn":18},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'imageId' is assigned a value but never used. Allowed unused vars must match /^_/u.","line":286,"column":13,"nodeType":null,"messageId":"unusedVar","endLine":286,"endColumn":20}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Tests for Image Manager\n *\n * Tests image storage, retrieval, validation, and management operations.\n * Uses Node.js built-in test runner (node:test) - no external dependencies.\n */\n\nimport { test, describe } from \"node:test\";\nimport assert from \"node:assert\";\nimport { createDatabase } from \"@app/memory/store/db.js\";\nimport { saveFrame } from \"@app/memory/store/queries.js\";\nimport { ImageManager, MAX_IMAGE_SIZE } from \"@app/memory/store/images.js\";\nimport { mkdtempSync, rmSync } from \"fs\";\nimport { join } from \"path\";\nimport { tmpdir } from \"os\";\nimport type Database from \"better-sqlite3\";\n\ndescribe(\"Image Manager\", () => {\n  let db: Database.Database;\n  let imageManager: ImageManager;\n  let testDbPath: string;\n\n  // Setup: create test database in temp directory\n  function setup() {\n    const tmpDir = mkdtempSync(join(tmpdir(), \"lex-img-test-\"));\n    testDbPath = join(tmpDir, \"test-images.db\");\n    db = createDatabase(testDbPath);\n    imageManager = new ImageManager(db);\n    return { db, imageManager };\n  }\n\n  // Teardown: close database and cleanup\n  function teardown() {\n    if (db) {\n      db.close();\n    }\n    if (testDbPath) {\n      try {\n        rmSync(testDbPath, { force: true });\n      } catch (_e) {\n        // Ignore cleanup errors\n      }\n    }\n  }\n\n  // Helper to create a test Frame\n  function createTestFrame(frameId: string = \"test-frame-001\") {\n    const frame = {\n      id: frameId,\n      timestamp: new Date().toISOString(),\n      branch: \"main\",\n      module_scope: [\"test/module\"],\n      summary_caption: \"Test frame\",\n      reference_point: \"test reference\",\n      status_snapshot: {\n        next_action: \"Test action\",\n      },\n    };\n    saveFrame(db, frame);\n    return frame;\n  }\n\n  test(\"storeImage stores a PNG image successfully\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const imageData = Buffer.from(\"fake-png-data\");\n      const mimeType = \"image/png\";\n\n      const imageId = imageManager.storeImage(frame.id, imageData, mimeType);\n\n      assert.ok(imageId, \"Image ID should be returned\");\n      assert.ok(imageId.startsWith(\"img-\"), \"Image ID should have correct prefix\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"storeImage stores a JPEG image successfully\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const imageData = Buffer.from(\"fake-jpeg-data\");\n      const mimeType = \"image/jpeg\";\n\n      const imageId = imageManager.storeImage(frame.id, imageData, mimeType);\n\n      assert.ok(imageId, \"Image ID should be returned\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"getImage retrieves stored PNG image\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const imageData = Buffer.from(\"fake-png-data\");\n      const mimeType = \"image/png\";\n\n      const imageId = imageManager.storeImage(frame.id, imageData, mimeType);\n      const retrieved = imageManager.getImage(imageId);\n\n      assert.ok(retrieved, \"Image should be retrieved\");\n      assert.strictEqual(retrieved!.mimeType, mimeType, \"MIME type should match\");\n      assert.deepStrictEqual(retrieved!.data, imageData, \"Image data should match\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"getImage retrieves stored JPEG image\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const imageData = Buffer.from(\"fake-jpeg-data\");\n      const mimeType = \"image/jpeg\";\n\n      const imageId = imageManager.storeImage(frame.id, imageData, mimeType);\n      const retrieved = imageManager.getImage(imageId);\n\n      assert.ok(retrieved, \"Image should be retrieved\");\n      assert.strictEqual(retrieved!.mimeType, mimeType, \"MIME type should match\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"storeImage rejects image exceeding 10MB size limit\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      // Create buffer larger than 10MB\n      const imageData = Buffer.alloc(MAX_IMAGE_SIZE + 1);\n      const mimeType = \"image/png\";\n\n      assert.throws(\n        () => imageManager.storeImage(frame.id, imageData, mimeType),\n        /exceeds maximum/,\n        \"Should reject oversized image\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"storeImage rejects invalid MIME type\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const imageData = Buffer.from(\"fake-data\");\n      const invalidMimeType = \"application/pdf\";\n\n      assert.throws(\n        () => imageManager.storeImage(frame.id, imageData, invalidMimeType),\n        /Invalid MIME type/,\n        \"Should reject invalid MIME type\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"storeImage rejects image for non-existent Frame\", () => {\n    const { imageManager } = setup();\n    try {\n      const imageData = Buffer.from(\"fake-png-data\");\n      const mimeType = \"image/png\";\n\n      assert.throws(\n        () => imageManager.storeImage(\"nonexistent-frame\", imageData, mimeType),\n        /Frame not found/,\n        \"Should reject image for non-existent frame\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"listFrameImages returns all images for a Frame\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const imageData1 = Buffer.from(\"image-1\");\n      const imageData2 = Buffer.from(\"image-2\");\n\n      const imageId1 = imageManager.storeImage(frame.id, imageData1, \"image/png\");\n      const imageId2 = imageManager.storeImage(frame.id, imageData2, \"image/jpeg\");\n\n      const images = imageManager.listFrameImages(frame.id);\n\n      assert.strictEqual(images.length, 2, \"Should return 2 images\");\n      assert.ok(\n        images.some((img) => img.image_id === imageId1),\n        \"Should include first image\"\n      );\n      assert.ok(\n        images.some((img) => img.image_id === imageId2),\n        \"Should include second image\"\n      );\n      assert.strictEqual(images[0].frame_id, frame.id, \"Frame ID should match\");\n      assert.strictEqual(images[0].mime_type, \"image/png\", \"First MIME type should be PNG\");\n      assert.strictEqual(images[1].mime_type, \"image/jpeg\", \"Second MIME type should be JPEG\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"listFrameImages returns empty array for Frame with no images\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const images = imageManager.listFrameImages(frame.id);\n\n      assert.strictEqual(images.length, 0, \"Should return empty array\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"deleteImage removes image from storage\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const imageData = Buffer.from(\"fake-png-data\");\n\n      const imageId = imageManager.storeImage(frame.id, imageData, \"image/png\");\n\n      const deleted = imageManager.deleteImage(imageId);\n      assert.strictEqual(deleted, true, \"Should return true for successful deletion\");\n\n      const retrieved = imageManager.getImage(imageId);\n      assert.strictEqual(retrieved, null, \"Image should no longer exist\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"deleteImage returns false for non-existent image\", () => {\n    const { imageManager } = setup();\n    try {\n      const deleted = imageManager.deleteImage(\"nonexistent-image-id\");\n      assert.strictEqual(deleted, false, \"Should return false for non-existent image\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"multiple images per Frame are supported\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const imageIds: string[] = [];\n\n      // Store 5 images\n      for (let i = 0; i < 5; i++) {\n        const imageData = Buffer.from(`image-data-${i}`);\n        const imageId = imageManager.storeImage(\n          frame.id,\n          imageData,\n          i % 2 === 0 ? \"image/png\" : \"image/jpeg\"\n        );\n        imageIds.push(imageId);\n      }\n\n      const images = imageManager.listFrameImages(frame.id);\n      assert.strictEqual(images.length, 5, \"Should have 5 images\");\n\n      // Verify all images can be retrieved\n      for (const imageId of imageIds) {\n        const retrieved = imageManager.getImage(imageId);\n        assert.ok(retrieved, `Image ${imageId} should be retrievable`);\n      }\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"image metadata includes size and created_at\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const imageData = Buffer.from(\"test-image-data\");\n\n      const beforeTime = Date.now();\n      const imageId = imageManager.storeImage(frame.id, imageData, \"image/png\");\n      const afterTime = Date.now();\n\n      const images = imageManager.listFrameImages(frame.id);\n      assert.strictEqual(images.length, 1, \"Should have 1 image\");\n\n      const metadata = images[0];\n      assert.strictEqual(metadata.size, imageData.length, \"Size should match\");\n      assert.ok(\n        metadata.created_at >= beforeTime && metadata.created_at <= afterTime,\n        \"created_at should be within expected range\"\n      );\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"getImageCount returns total number of images\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame1 = createTestFrame(\"frame-1\");\n      const frame2 = createTestFrame(\"frame-2\");\n\n      assert.strictEqual(imageManager.getImageCount(), 0, \"Should start with 0 images\");\n\n      imageManager.storeImage(frame1.id, Buffer.from(\"img1\"), \"image/png\");\n      assert.strictEqual(imageManager.getImageCount(), 1, \"Should have 1 image\");\n\n      imageManager.storeImage(frame2.id, Buffer.from(\"img2\"), \"image/jpeg\");\n      assert.strictEqual(imageManager.getImageCount(), 2, \"Should have 2 images\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"getTotalImageSize returns sum of all image sizes\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n\n      const img1 = Buffer.from(\"image-1\"); // 7 bytes\n      const img2 = Buffer.from(\"image-22\"); // 8 bytes\n\n      imageManager.storeImage(frame.id, img1, \"image/png\");\n      imageManager.storeImage(frame.id, img2, \"image/jpeg\");\n\n      const totalSize = imageManager.getTotalImageSize();\n      assert.strictEqual(totalSize, img1.length + img2.length, \"Total size should match\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"SVG images are supported\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const svgData = Buffer.from('<svg><circle r=\"10\"/></svg>');\n\n      const imageId = imageManager.storeImage(frame.id, svgData, \"image/svg+xml\");\n      const retrieved = imageManager.getImage(imageId);\n\n      assert.ok(retrieved, \"SVG should be stored and retrieved\");\n      assert.strictEqual(retrieved!.mimeType, \"image/svg+xml\", \"MIME type should be SVG\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"image with exactly 10MB is accepted\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const imageData = Buffer.alloc(MAX_IMAGE_SIZE); // Exactly 10MB\n\n      const imageId = imageManager.storeImage(frame.id, imageData, \"image/png\");\n      assert.ok(imageId, \"10MB image should be accepted\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"cascading delete removes images when Frame is deleted\", () => {\n    const { imageManager } = setup();\n    try {\n      const frame = createTestFrame();\n      const imageData = Buffer.from(\"test-image\");\n\n      const imageId = imageManager.storeImage(frame.id, imageData, \"image/png\");\n\n      // Verify image exists\n      let retrieved = imageManager.getImage(imageId);\n      assert.ok(retrieved, \"Image should exist\");\n\n      // Delete the Frame (this should cascade to images via foreign key)\n      const deleteStmt = db.prepare(\"DELETE FROM frames WHERE id = ?\");\n      deleteStmt.run(frame.id);\n\n      // Verify image was deleted\n      retrieved = imageManager.getImage(imageId);\n      assert.strictEqual(retrieved, null, \"Image should be deleted with Frame\");\n    } finally {\n      teardown();\n    }\n  });\n});\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/memory/store/store.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'createDatabase' is defined but never used. Allowed unused vars must match /^_/u.","line":25,"column":3,"nodeType":null,"messageId":"unusedVar","endLine":25,"endColumn":17}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Tests for Frame storage\n *\n * Run with: npm test\n * Or directly with tsx: npx tsx --test store.test.ts\n */\n\nimport { test, describe, before, after } from \"node:test\";\nimport assert from \"node:assert\";\nimport { unlinkSync, existsSync } from \"fs\";\nimport { tmpdir } from \"os\";\nimport { join } from \"path\";\nimport {\n  getDb,\n  closeDb,\n  saveFrame,\n  getFrameById,\n  searchFrames,\n  getFramesByBranch,\n  getFramesByJira,\n  getFramesByModuleScope,\n  getAllFrames,\n  deleteFrame,\n  getFrameCount,\n  createDatabase,\n} from \"@app/memory/store/index.js\";\nimport type { Frame } from \"../frames/types.js\";\n\n// Test database path\nconst TEST_DB_PATH = join(tmpdir(), `test-frames-${Date.now()}.db`);\n\n// Sample test frames\nconst testFrame1: Frame = {\n  id: \"frame-001\",\n  timestamp: \"2025-11-01T16:04:12-05:00\",\n  branch: \"feature/auth-fix\",\n  jira: \"TICKET-123\",\n  module_scope: [\"ui/user-admin-panel\", \"services/auth-core\"],\n  summary_caption: \"Auth handshake timeout; Add User button disabled\",\n  reference_point: \"that auth deadlock\",\n  status_snapshot: {\n    next_action: \"Reroute user-admin-panel to call user-access-api\",\n    merge_blockers: [\"Direct call to auth-core forbidden by policy\"],\n  },\n  keywords: [\"auth\", \"timeout\", \"policy-violation\"],\n  atlas_frame_id: \"atlas-001\",\n  feature_flags: [\"beta_user_admin\"],\n  permissions: [\"can_manage_users\"],\n};\n\nconst testFrame2: Frame = {\n  id: \"frame-002\",\n  timestamp: \"2025-11-02T10:30:00-05:00\",\n  branch: \"feature/payment-integration\",\n  jira: \"TICKET-456\",\n  module_scope: [\"services/payment-gateway\", \"ui/checkout\"],\n  summary_caption: \"Payment gateway integration with Stripe\",\n  reference_point: \"stripe webhook handler\",\n  status_snapshot: {\n    next_action: \"Add webhook signature verification\",\n    blockers: [\"Missing Stripe API keys in env\"],\n  },\n  keywords: [\"payment\", \"stripe\", \"webhook\"],\n};\n\nconst testFrame3: Frame = {\n  id: \"frame-003\",\n  timestamp: \"2025-11-03T14:15:00-05:00\",\n  branch: \"feature/auth-fix\",\n  module_scope: [\"services/auth-core\", \"lib/crypto\"],\n  summary_caption: \"Fixed auth token expiration bug\",\n  reference_point: \"token expiration issue\",\n  status_snapshot: {\n    next_action: \"Deploy to staging\",\n  },\n  keywords: [\"auth\", \"bug-fix\", \"tokens\"],\n};\n\ndescribe(\"Frame Storage Tests\", () => {\n  let db: ReturnType<typeof getDb>;\n\n  before(() => {\n    // Clean up any existing test database\n    if (existsSync(TEST_DB_PATH)) {\n      unlinkSync(TEST_DB_PATH);\n    }\n    db = getDb(TEST_DB_PATH);\n  });\n\n  after(() => {\n    closeDb();\n    // Clean up test database\n    if (existsSync(TEST_DB_PATH)) {\n      unlinkSync(TEST_DB_PATH);\n    }\n  });\n\n  describe(\"Database Initialization\", () => {\n    test(\"should create database file on first use\", () => {\n      assert.ok(existsSync(TEST_DB_PATH), \"Database file should exist\");\n    });\n\n    test(\"should have frames table\", () => {\n      const tables = db\n        .prepare(\"SELECT name FROM sqlite_master WHERE type='table' AND name='frames'\")\n        .all();\n      assert.strictEqual(tables.length, 1, \"frames table should exist\");\n    });\n\n    test(\"should have FTS5 virtual table\", () => {\n      const tables = db\n        .prepare(\"SELECT name FROM sqlite_master WHERE type='table' AND name='frames_fts'\")\n        .all();\n      assert.strictEqual(tables.length, 1, \"frames_fts table should exist\");\n    });\n\n    test(\"should have schema_version table for migrations\", () => {\n      const tables = db\n        .prepare(\"SELECT name FROM sqlite_master WHERE type='table' AND name='schema_version'\")\n        .all();\n      assert.strictEqual(tables.length, 1, \"schema_version table should exist\");\n    });\n  });\n\n  describe(\"CRUD Operations\", () => {\n    test(\"should save a Frame successfully\", async () => {\n      saveFrame(db, testFrame1);\n      const count = getFrameCount(db);\n      assert.strictEqual(count, 1, \"Frame count should be 1 after insert\");\n    });\n\n    test(\"should retrieve Frame by ID\", async () => {\n      const frame = getFrameById(db, \"frame-001\");\n      assert.ok(frame, \"Frame should be found\");\n      assert.strictEqual(frame!.id, testFrame1.id);\n      assert.strictEqual(frame!.reference_point, testFrame1.reference_point);\n      assert.deepStrictEqual(frame!.module_scope, testFrame1.module_scope);\n      assert.deepStrictEqual(frame!.keywords, testFrame1.keywords);\n    });\n\n    test(\"should return null for non-existent Frame ID\", async () => {\n      const frame = getFrameById(db, \"non-existent\");\n      assert.strictEqual(frame, null, \"Should return null for non-existent ID\");\n    });\n\n    test(\"should update existing Frame (upsert)\", async () => {\n      const updatedFrame = {\n        ...testFrame1,\n        summary_caption: \"Updated caption\",\n      };\n      saveFrame(db, updatedFrame);\n      const frame = getFrameById(db, \"frame-001\");\n      assert.strictEqual(frame!.summary_caption, \"Updated caption\");\n      const count = getFrameCount(db);\n      assert.strictEqual(count, 1, \"Frame count should still be 1 after update\");\n    });\n\n    test(\"should delete Frame by ID\", async () => {\n      saveFrame(db, testFrame2);\n      const deleted = deleteFrame(db, \"frame-002\");\n      assert.strictEqual(deleted, true, \"Delete should return true\");\n      const frame = getFrameById(db, \"frame-002\");\n      assert.strictEqual(frame, null, \"Frame should not exist after delete\");\n    });\n\n    test(\"should handle all optional fields correctly\", async () => {\n      const minimalFrame: Frame = {\n        id: \"frame-minimal\",\n        timestamp: \"2025-11-04T12:00:00Z\",\n        branch: \"main\",\n        module_scope: [\"core\"],\n        summary_caption: \"Minimal frame\",\n        reference_point: \"minimal test\",\n        status_snapshot: {\n          next_action: \"nothing\",\n        },\n      };\n      saveFrame(db, minimalFrame);\n      const retrieved = getFrameById(db, \"frame-minimal\");\n      assert.ok(retrieved);\n      assert.strictEqual(retrieved!.jira, undefined);\n      assert.strictEqual(retrieved!.keywords, undefined);\n      assert.strictEqual(retrieved!.atlas_frame_id, undefined);\n      deleteFrame(db, \"frame-minimal\");\n    });\n  });\n\n  describe(\"Search and Query Operations\", () => {\n    before(async () => {\n      // Clean slate for search tests\n      const frames = getAllFrames(db);\n      for (const frame of frames) {\n        deleteFrame(db, frame.id);\n      }\n      // Insert test frames\n      saveFrame(db, testFrame1);\n      saveFrame(db, testFrame2);\n      saveFrame(db, testFrame3);\n    });\n\n    test(\"should search Frames with FTS5 (reference_point match)\", async () => {\n      const result = searchFrames(db, \"auth deadlock\");\n      assert.ok(result.frames.length > 0, \"Should find frames matching 'auth deadlock'\");\n      assert.ok(\n        result.frames.some((f) => f.id === \"frame-001\"),\n        \"Should find frame-001\"\n      );\n    });\n\n    test(\"should search Frames with FTS5 (keywords match)\", async () => {\n      const result = searchFrames(db, \"payment\");\n      assert.ok(result.frames.length > 0, \"Should find frames matching 'payment'\");\n      assert.ok(\n        result.frames.some((f) => f.id === \"frame-002\"),\n        \"Should find frame-002\"\n      );\n    });\n\n    test(\"should search Frames with FTS5 (summary_caption match)\", async () => {\n      const result = searchFrames(db, \"Stripe\");\n      assert.ok(result.frames.length > 0, \"Should find frames matching 'Stripe'\");\n      assert.ok(\n        result.frames.some((f) => f.id === \"frame-002\"),\n        \"Should find frame-002\"\n      );\n    });\n\n    test(\"should get Frames by branch\", async () => {\n      const results = getFramesByBranch(db, \"feature/auth-fix\");\n      assert.strictEqual(results.length, 2, \"Should find 2 frames on feature/auth-fix\");\n      assert.ok(\n        results.some((f) => f.id === \"frame-001\"),\n        \"Should include frame-001\"\n      );\n      assert.ok(\n        results.some((f) => f.id === \"frame-003\"),\n        \"Should include frame-003\"\n      );\n    });\n\n    test(\"should get Frames by Jira ID\", async () => {\n      const results = getFramesByJira(db, \"TICKET-123\");\n      assert.strictEqual(results.length, 1, \"Should find 1 frame for TICKET-123\");\n      assert.strictEqual(results[0].id, \"frame-001\");\n    });\n\n    test(\"should get Frames by module scope\", async () => {\n      const results = getFramesByModuleScope(db, \"services/auth-core\");\n      assert.ok(results.length >= 2, \"Should find at least 2 frames touching services/auth-core\");\n      assert.ok(\n        results.some((f) => f.id === \"frame-001\"),\n        \"Should include frame-001\"\n      );\n      assert.ok(\n        results.some((f) => f.id === \"frame-003\"),\n        \"Should include frame-003\"\n      );\n    });\n\n    test(\"should get all Frames in descending timestamp order\", async () => {\n      const results = getAllFrames(db);\n      assert.strictEqual(results.length, 3, \"Should get all 3 frames\");\n      // Frames should be ordered newest first\n      assert.ok(\n        results[0].timestamp >= results[1].timestamp,\n        \"Results should be in descending timestamp order\"\n      );\n      assert.ok(\n        results[1].timestamp >= results[2].timestamp,\n        \"Results should be in descending timestamp order\"\n      );\n    });\n\n    test(\"should limit results when requested\", async () => {\n      const results = getAllFrames(db, 2);\n      assert.strictEqual(results.length, 2, \"Should return only 2 frames\");\n    });\n\n    test(\"should return empty array for non-matching searches\", async () => {\n      const result = searchFrames(db, \"zzzznonexistent\");\n      assert.strictEqual(result.frames.length, 0, \"Should return empty array for no matches\");\n      assert.strictEqual(\n        result.hint,\n        undefined,\n        \"Should not have hint for normal non-matching search\"\n      );\n    });\n  });\n\n  describe(\"Concurrent Access\", () => {\n    test(\"should handle concurrent writes\", async () => {\n      const concurrentFrames: Frame[] = Array.from({ length: 10 }, (_, i) => ({\n        id: `concurrent-${i}`,\n        timestamp: new Date().toISOString(),\n        branch: \"test-branch\",\n        module_scope: [\"test\"],\n        summary_caption: `Concurrent frame ${i}`,\n        reference_point: `concurrent ${i}`,\n        status_snapshot: {\n          next_action: `action ${i}`,\n        },\n      }));\n\n      // Save all frames concurrently\n      await Promise.all(concurrentFrames.map((f) => saveFrame(db, f)));\n\n      const count = getFrameCount(db);\n      assert.ok(count >= 10, \"All concurrent frames should be saved\");\n\n      // Clean up\n      for (const frame of concurrentFrames) {\n        deleteFrame(db, frame.id);\n      }\n    });\n  });\n\n  describe(\"FTS5 Fuzzy Search\", () => {\n    test(\"should support fuzzy matching with wildcards\", async () => {\n      const result = searchFrames(db, \"auth*\");\n      assert.ok(result.frames.length > 0, \"Should find frames with auth prefix\");\n    });\n\n    test(\"should support multiple search terms\", async () => {\n      const result = searchFrames(db, \"auth timeout\");\n      assert.ok(result.frames.length > 0, \"Should find frames matching multiple terms\");\n    });\n  });\n\n  describe(\"FTS5 Special Character Handling\", () => {\n    test(\"should handle period (.) without throwing error\", async () => {\n      const result = searchFrames(db, \"0.3.0\");\n      assert.strictEqual(result.frames.length, 0, \"Should return empty results\");\n      assert.ok(result.hint, \"Should provide a hint\");\n      assert.ok(\n        result.hint.includes(\"special characters\"),\n        \"Hint should mention special characters\"\n      );\n    });\n\n    test(\"should handle colon (:) without throwing error\", async () => {\n      const result = searchFrames(db, \"TICKET-123:\");\n      assert.strictEqual(result.frames.length, 0, \"Should return empty results\");\n      assert.ok(result.hint, \"Should provide a hint\");\n    });\n\n    test(\"should handle asterisk at start without throwing error\", async () => {\n      const result = searchFrames(db, \"*test\");\n      assert.strictEqual(result.frames.length, 0, \"Should return empty results\");\n      assert.ok(result.hint, \"Should provide a hint\");\n    });\n\n    test(\"should handle hyphen (-) at start without throwing error\", async () => {\n      const result = searchFrames(db, \"-test\");\n      assert.strictEqual(result.frames.length, 0, \"Should return empty results\");\n      assert.ok(result.hint, \"Should provide a hint\");\n    });\n\n    test(\"should suggest simplified query in hint\", async () => {\n      const result = searchFrames(db, \"v0.3.0 release\");\n      assert.strictEqual(result.frames.length, 0, \"Should return empty results\");\n      assert.ok(result.hint, \"Should provide a hint\");\n      assert.ok(\n        result.hint.includes(\"v0 3 0 release\") || result.hint.includes(\"release\"),\n        \"Hint should suggest simplified query\"\n      );\n    });\n  });\n\n  describe(\"Frame Schema v2: Merge-Weave Metadata\", () => {\n    test(\"should save and retrieve Frame with merge-weave metadata\", async () => {\n      const frameWithMergeWeave: Frame = {\n        id: \"frame-mw-001\",\n        timestamp: \"2025-11-09T12:00:00Z\",\n        branch: \"feat/merge-weave\",\n        module_scope: [\"core\"],\n        summary_caption: \"Merge-weave test frame\",\n        reference_point: \"merge weave test\",\n        status_snapshot: {\n          next_action: \"Complete merge-weave\",\n        },\n        runId: \"lexrunner-20251109-abc123\",\n        planHash: \"sha256:7f8c9d1234567890abcdef\",\n        spend: {\n          prompts: 3,\n          tokens_estimated: 1500,\n        },\n      };\n\n      saveFrame(db, frameWithMergeWeave);\n      const retrieved = getFrameById(db, \"frame-mw-001\");\n\n      assert.ok(retrieved, \"Frame should be retrieved\");\n      assert.strictEqual(retrieved!.runId, \"lexrunner-20251109-abc123\", \"runId should match\");\n      assert.strictEqual(\n        retrieved!.planHash,\n        \"sha256:7f8c9d1234567890abcdef\",\n        \"planHash should match\"\n      );\n      assert.ok(retrieved!.spend, \"spend should be present\");\n      assert.strictEqual(retrieved!.spend!.prompts, 3, \"spend.prompts should match\");\n      assert.strictEqual(\n        retrieved!.spend!.tokens_estimated,\n        1500,\n        \"spend.tokens_estimated should match\"\n      );\n\n      deleteFrame(db, \"frame-mw-001\");\n    });\n\n    test(\"should handle partial merge-weave metadata\", async () => {\n      const framePartial: Frame = {\n        id: \"frame-mw-002\",\n        timestamp: \"2025-11-09T12:10:00Z\",\n        branch: \"feat/merge-weave\",\n        module_scope: [\"core\"],\n        summary_caption: \"Partial merge-weave metadata\",\n        reference_point: \"partial test\",\n        status_snapshot: {\n          next_action: \"Test partial fields\",\n        },\n        runId: \"lexrunner-20251109-def456\",\n        // planHash and spend are omitted\n      };\n\n      saveFrame(db, framePartial);\n      const retrieved = getFrameById(db, \"frame-mw-002\");\n\n      assert.ok(retrieved, \"Frame should be retrieved\");\n      assert.strictEqual(retrieved!.runId, \"lexrunner-20251109-def456\", \"runId should match\");\n      assert.strictEqual(retrieved!.planHash, undefined, \"planHash should be undefined\");\n      assert.strictEqual(retrieved!.spend, undefined, \"spend should be undefined\");\n\n      deleteFrame(db, \"frame-mw-002\");\n    });\n\n    test(\"should handle spend with only one field\", async () => {\n      const framePartialSpend: Frame = {\n        id: \"frame-mw-003\",\n        timestamp: \"2025-11-09T12:20:00Z\",\n        branch: \"feat/merge-weave\",\n        module_scope: [\"core\"],\n        summary_caption: \"Partial spend metadata\",\n        reference_point: \"partial spend\",\n        status_snapshot: {\n          next_action: \"Test partial spend\",\n        },\n        spend: {\n          prompts: 5,\n          // tokens_estimated is omitted\n        },\n      };\n\n      saveFrame(db, framePartialSpend);\n      const retrieved = getFrameById(db, \"frame-mw-003\");\n\n      assert.ok(retrieved, \"Frame should be retrieved\");\n      assert.ok(retrieved!.spend, \"spend should be present\");\n      assert.strictEqual(retrieved!.spend!.prompts, 5, \"spend.prompts should match\");\n      assert.strictEqual(\n        retrieved!.spend!.tokens_estimated,\n        undefined,\n        \"spend.tokens_estimated should be undefined\"\n      );\n\n      deleteFrame(db, \"frame-mw-003\");\n    });\n\n    test(\"should maintain backward compatibility with legacy frames\", async () => {\n      const legacyFrame: Frame = {\n        id: \"frame-legacy-001\",\n        timestamp: \"2025-11-09T12:30:00Z\",\n        branch: \"main\",\n        module_scope: [\"core\"],\n        summary_caption: \"Legacy frame without v2 fields\",\n        reference_point: \"legacy test\",\n        status_snapshot: {\n          next_action: \"Test backward compatibility\",\n        },\n        // No merge-weave fields\n      };\n\n      saveFrame(db, legacyFrame);\n      const retrieved = getFrameById(db, \"frame-legacy-001\");\n\n      assert.ok(retrieved, \"Legacy frame should be retrieved\");\n      assert.strictEqual(retrieved!.id, \"frame-legacy-001\", \"id should match\");\n      assert.strictEqual(retrieved!.runId, undefined, \"runId should be undefined for legacy frame\");\n      assert.strictEqual(\n        retrieved!.planHash,\n        undefined,\n        \"planHash should be undefined for legacy frame\"\n      );\n      assert.strictEqual(retrieved!.spend, undefined, \"spend should be undefined for legacy frame\");\n\n      deleteFrame(db, \"frame-legacy-001\");\n    });\n\n    test(\"should allow updating frame from v1 to v2\", async () => {\n      const v1Frame: Frame = {\n        id: \"frame-upgrade-001\",\n        timestamp: \"2025-11-09T12:40:00Z\",\n        branch: \"main\",\n        module_scope: [\"core\"],\n        summary_caption: \"Frame to upgrade\",\n        reference_point: \"upgrade test\",\n        status_snapshot: {\n          next_action: \"Upgrade to v2\",\n        },\n      };\n\n      saveFrame(db, v1Frame);\n      let retrieved = getFrameById(db, \"frame-upgrade-001\");\n      assert.strictEqual(retrieved!.runId, undefined, \"Should start without runId\");\n\n      // Update with v2 fields\n      const v2Frame: Frame = {\n        ...v1Frame,\n        runId: \"lexrunner-20251109-ghi789\",\n        planHash: \"sha256:updated\",\n        spend: {\n          prompts: 2,\n          tokens_estimated: 800,\n        },\n      };\n\n      saveFrame(db, v2Frame);\n      retrieved = getFrameById(db, \"frame-upgrade-001\");\n\n      assert.strictEqual(retrieved!.runId, \"lexrunner-20251109-ghi789\", \"runId should be updated\");\n      assert.strictEqual(retrieved!.planHash, \"sha256:updated\", \"planHash should be updated\");\n      assert.ok(retrieved!.spend, \"spend should be present\");\n      assert.strictEqual(retrieved!.spend!.prompts, 2, \"spend should be updated\");\n\n      deleteFrame(db, \"frame-upgrade-001\");\n    });\n  });\n});\n\n// Summary message\nconsole.log(\n  \"\\nâœ… Frame Storage Tests - covering CRUD, FTS5 search, queries, concurrent access, and Frame Schema v2\\n\"\n);\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/merge-weave/state-machine.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/policy/check/check.test.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/policy/check/reporter.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/policy/integration.test.mjs","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'merged' is assigned a value but never used. Allowed unused vars must match /^_/u.","line":282,"column":13,"nodeType":null,"messageId":"unusedVar","endLine":282,"endColumn":19}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Integration tests for Policy Check Pipeline\n *\n * Tests the full policy check integration:\n * - Scanner â†’ merge â†’ check pipeline\n * - Violation detection with real policy\n *\n * Note: This requires policy modules to be built first:\n *   npm run build:merge && npm run build:check\n *\n * Run with: node policy/integration.test.mjs\n */\n\nimport { strict as assert } from \"assert\";\nimport { test, describe } from \"node:test\";\n// Adjusted import path to built dist output\nimport { mergeScans } from \"../../dist/policy/merge/merge.js\";\n\ndescribe(\"Policy Integration Tests\", () => {\n  describe(\"Scanner â†’ Merge Pipeline\", () => {\n    test(\"should complete scan â†’ merge workflow\", () => {\n      // Step 1: Simulate scanner outputs\n      const typescriptScan = {\n        language: \"typescript\",\n        files: [\n          {\n            path: \"src/ui/admin/UserPanel.tsx\",\n            declarations: [{ type: \"component\", name: \"UserPanel\" }],\n            imports: [{ from: \"src/services/auth/AuthCore\", type: \"import_statement\" }],\n            feature_flags: [],\n            permissions: [],\n            warnings: [],\n          },\n        ],\n      };\n\n      const phpScan = {\n        language: \"php\",\n        files: [\n          {\n            path: \"app/Controllers/UserController.php\",\n            declarations: [{ type: \"class\", name: \"UserController\" }],\n            imports: [{ from: \"App\\\\Services\\\\AuthService\", type: \"import_statement\" }],\n            feature_flags: [],\n            permissions: [],\n            warnings: [],\n          },\n        ],\n      };\n\n      // Step 2: Merge scanner outputs\n      const merged = mergeScans([typescriptScan, phpScan]);\n      assert.ok(merged, \"Should merge scanner outputs\");\n      assert.equal(merged.sources.length, 2, \"Should include both sources\");\n      assert.equal(merged.files.length, 2, \"Should include both files\");\n      assert.ok(merged.sources.includes(\"typescript\"));\n      assert.ok(merged.sources.includes(\"php\"));\n    });\n\n    test(\"should pass clean pipeline with no violations\", () => {\n      const scan = {\n        language: \"typescript\",\n        files: [\n          {\n            path: \"src/ui/components/Button.tsx\",\n            declarations: [{ type: \"component\", name: \"Button\" }],\n            imports: [{ from: \"src/services/api/ButtonApi\", type: \"import_statement\" }],\n            feature_flags: [],\n            permissions: [],\n            warnings: [],\n          },\n        ],\n      };\n\n      const merged = mergeScans([scan]);\n      assert.ok(merged, \"Should merge scanner output\");\n      assert.equal(merged.files.length, 1);\n      assert.equal(merged.sources[0], \"typescript\");\n    });\n\n    test(\"should handle multi-language pipeline\", () => {\n      const scans = [\n        {\n          language: \"typescript\",\n          files: [\n            {\n              path: \"frontend/src/App.tsx\",\n              declarations: [],\n              imports: [{ from: \"api/client\", type: \"import_statement\" }],\n              feature_flags: [],\n              permissions: [],\n              warnings: [],\n            },\n          ],\n        },\n        {\n          language: \"python\",\n          files: [\n            {\n              path: \"backend/api/views.py\",\n              declarations: [],\n              imports: [{ from: \"database.models\", type: \"import_statement\" }],\n              feature_flags: [],\n              permissions: [],\n              warnings: [],\n            },\n          ],\n        },\n        {\n          language: \"php\",\n          files: [\n            {\n              path: \"legacy/api/endpoints.php\",\n              declarations: [],\n              imports: [],\n              feature_flags: [],\n              permissions: [],\n              warnings: [],\n            },\n          ],\n        },\n      ];\n\n      const merged = mergeScans(scans);\n      assert.equal(merged.sources.length, 3, \"Should merge all languages\");\n      assert.equal(merged.files.length, 3, \"Should include all files\");\n      assert.ok(merged.sources.includes(\"typescript\"));\n      assert.ok(merged.sources.includes(\"python\"));\n      assert.ok(merged.sources.includes(\"php\"));\n    });\n\n    test(\"should deduplicate edges across scans\", () => {\n      const scan1 = {\n        language: \"typescript\",\n        files: [\n          {\n            path: \"src/auth.ts\",\n            declarations: [],\n            imports: [\n              { from: \"./utils\", type: \"import_statement\" },\n              { from: \"./config\", type: \"import_statement\" },\n            ],\n            feature_flags: [],\n            permissions: [],\n            warnings: [],\n          },\n        ],\n      };\n\n      const scan2 = {\n        language: \"typescript\",\n        files: [\n          {\n            path: \"src/admin.ts\",\n            declarations: [],\n            imports: [{ from: \"./utils\", type: \"import_statement\" }],\n            feature_flags: [],\n            permissions: [],\n            warnings: [],\n          },\n        ],\n      };\n\n      const merged = mergeScans([scan1, scan2]);\n\n      // Should have 3 unique edges (auth->utils, auth->config, admin->utils)\n      assert.equal(merged.edges.length, 3);\n\n      const edgeKeys = merged.edges.map((e) => `${e.from}->${e.to}`);\n      assert.ok(edgeKeys.includes(\"src/auth.ts->./utils\"));\n      assert.ok(edgeKeys.includes(\"src/auth.ts->./config\"));\n      assert.ok(edgeKeys.includes(\"src/admin.ts->./utils\"));\n    });\n\n    test(\"should sort files in merged output\", () => {\n      const scan = {\n        language: \"typescript\",\n        files: [\n          {\n            path: \"src/z.ts\",\n            declarations: [],\n            imports: [],\n            feature_flags: [],\n            permissions: [],\n            warnings: [],\n          },\n          {\n            path: \"src/a.ts\",\n            declarations: [],\n            imports: [],\n            feature_flags: [],\n            permissions: [],\n            warnings: [],\n          },\n          {\n            path: \"src/m.ts\",\n            declarations: [],\n            imports: [],\n            feature_flags: [],\n            permissions: [],\n            warnings: [],\n          },\n        ],\n      };\n\n      const merged = mergeScans([scan]);\n\n      // Files should be sorted alphabetically\n      assert.equal(merged.files[0].path, \"src/a.ts\");\n      assert.equal(merged.files[1].path, \"src/m.ts\");\n      assert.equal(merged.files[2].path, \"src/z.ts\");\n    });\n\n    test(\"should handle empty scanner output\", () => {\n      const scan = {\n        language: \"typescript\",\n        files: [],\n      };\n\n      const merged = mergeScans([scan]);\n      assert.equal(merged.files.length, 0);\n      assert.equal(merged.sources.length, 1);\n      assert.ok(merged.sources.includes(\"typescript\"));\n    });\n\n    test(\"should include version in merged output\", () => {\n      const scan = {\n        language: \"typescript\",\n        files: [],\n      };\n\n      const merged = mergeScans([scan]);\n      assert.ok(merged.version, \"Should have version\");\n      assert.equal(merged.version, \"1.0.0\");\n    });\n\n    test(\"should preserve file metadata through merge\", () => {\n      const scan = {\n        language: \"typescript\",\n        files: [\n          {\n            path: \"src/test.ts\",\n            declarations: [{ type: \"function\", name: \"test\" }],\n            imports: [{ from: \"assert\", type: \"import_statement\" }],\n            feature_flags: [\"test_mode\"],\n            permissions: [\"can_test\"],\n            warnings: [\"test warning\"],\n          },\n        ],\n      };\n\n      const merged = mergeScans([scan]);\n      const file = merged.files[0];\n\n      assert.equal(file.path, \"src/test.ts\");\n      assert.equal(file.declarations.length, 1);\n      assert.equal(file.declarations[0].name, \"test\");\n      assert.equal(file.imports.length, 1);\n      assert.equal(file.imports[0].from, \"assert\");\n      assert.ok(file.feature_flags.includes(\"test_mode\"));\n      assert.ok(file.permissions.includes(\"can_test\"));\n      assert.ok(file.warnings.includes(\"test warning\"));\n    });\n  });\n\n  describe(\"Frame Creation from Policy Results\", () => {\n    test(\"should create Frame structure from scan results\", () => {\n      const scan = {\n        language: \"typescript\",\n        files: [\n          {\n            path: \"src/features/beta/NewWidget.tsx\",\n            declarations: [],\n            imports: [],\n            feature_flags: [],\n            permissions: [],\n            warnings: [],\n          },\n        ],\n      };\n\n      const merged = mergeScans([scan]);\n\n      // Create a Frame from scan results\n      const frame = {\n        id: \"frame-policy-001\",\n        timestamp: new Date().toISOString(),\n        branch: \"feature/beta-ui\",\n        module_scope: [\"features/beta\"],\n        summary_caption: \"Policy scan completed\",\n        reference_point: \"beta feature scan\",\n        status_snapshot: {\n          next_action: \"Review scan results\",\n          blockers: [],\n        },\n        keywords: [\"policy\", \"scan\"],\n      };\n\n      // Verify Frame structure\n      assert.ok(frame, \"Should create Frame\");\n      assert.ok(frame.status_snapshot, \"Should have status snapshot\");\n      assert.ok(Array.isArray(frame.module_scope), \"Should have module scope array\");\n    });\n\n    test(\"should create Frame for successful scan\", () => {\n      const frame = {\n        id: \"frame-policy-002\",\n        timestamp: new Date().toISOString(),\n        branch: \"feature/compliant-code\",\n        module_scope: [\"ui/components\"],\n        summary_caption: \"All policy checks passed\",\n        reference_point: \"clean policy check\",\n        status_snapshot: {\n          next_action: \"Ready to merge\",\n          blockers: [],\n        },\n      };\n\n      // Verify Frame structure\n      assert.ok(frame, \"Should create Frame\");\n      assert.equal(frame.status_snapshot.next_action, \"Ready to merge\");\n      assert.equal(frame.status_snapshot.blockers.length, 0);\n    });\n  });\n\n  describe(\"Edge Cases and Error Handling\", () => {\n    test(\"should handle files outside known modules\", () => {\n      const scan = {\n        language: \"typescript\",\n        files: [\n          {\n            path: \"scripts/build.ts\",\n            declarations: [],\n            imports: [],\n            feature_flags: [],\n            permissions: [],\n            warnings: [],\n          },\n        ],\n      };\n\n      const merged = mergeScans([scan]);\n      assert.ok(merged, \"Should handle unknown files gracefully\");\n      assert.equal(merged.files.length, 1);\n    });\n\n    test(\"should merge scans with warnings\", () => {\n      const scan = {\n        language: \"typescript\",\n        files: [\n          {\n            path: \"src/legacy/OldCode.ts\",\n            declarations: [],\n            imports: [],\n            feature_flags: [],\n            permissions: [],\n            warnings: [\"deprecated pattern detected\"],\n          },\n        ],\n      };\n\n      const merged = mergeScans([scan]);\n      assert.equal(merged.files[0].warnings.length, 1);\n      assert.ok(merged.files[0].warnings[0].includes(\"deprecated\"));\n    });\n  });\n});\n\nconsole.log(\"\\nâœ… Policy Integration Tests - Merge pipeline coverage\\n\");\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/policy/merge/merge.test.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/schemas/round-trip.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'require' is assigned a value but never used. Allowed unused vars must match /^_/u.","line":20,"column":7,"nodeType":null,"messageId":"unusedVar","endLine":20,"endColumn":14}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { describe, it } from \"node:test\";\nimport { strict as assert } from \"node:assert\";\nimport Ajv from \"ajv\";\nimport addFormats from \"ajv-formats\";\nimport { readFileSync } from \"fs\";\nimport { join, dirname } from \"path\";\nimport { fileURLToPath } from \"url\";\nimport { createRequire } from \"module\";\n\nimport { ProfileSchema } from \"../../.smartergpt/schemas/profile.schema.js\";\n// NOTE: These schemas migrated to lex-pr-runner in PR #219\n// import { GatesSchema } from \"lex-pr-runner/schemas/gates\";\n// import { RunnerStackSchema } from \"lex-pr-runner/schemas/runner-stack\";\n// import { RunnerScopeSchema } from \"lex-pr-runner/schemas/runner-scope\";\nimport { FeatureSpecV0Schema } from \"../../.smartergpt/schemas/feature-spec-v0.js\";\n// import { ExecutionPlanV1Schema } from \"lex-pr-runner/schemas/execution-plan-v1\";\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = dirname(__filename);\nconst require = createRequire(import.meta.url);\n\ndescribe(\"Zod â†” JSON Schema Round-Trip\", () => {\n  const ajv = new Ajv({\n    strict: true,\n    allErrors: true,\n    validateSchema: false, // Disable meta-schema validation for draft-2020-12 compatibility\n  });\n  addFormats(ajv);\n\n  describe(\"ProfileSchema round-trip\", () => {\n    const jsonSchemaPath = join(__dirname, \"../../.smartergpt/schemas/profile.schema.json\");\n    const jsonSchema = JSON.parse(readFileSync(jsonSchemaPath, \"utf-8\"));\n    const validateJson = ajv.compile(jsonSchema);\n\n    it(\"should validate minimal profile through both Zod and JSON Schema\", () => {\n      const profile = {\n        role: \"development\" as const,\n      };\n\n      // Zod parse\n      const zodResult = ProfileSchema.parse(profile);\n\n      // JSON Schema validate\n      const jsonValid = validateJson(profile);\n      assert.ok(jsonValid, `JSON Schema validation failed: ${JSON.stringify(validateJson.errors)}`);\n\n      // Verify equivalence\n      assert.deepStrictEqual(zodResult, profile);\n    });\n\n    it(\"should validate complete profile through both Zod and JSON Schema\", () => {\n      const profile = {\n        role: \"development\" as const,\n        name: \"Test Profile\",\n        version: \"1.0.0\",\n        projectType: \"nodejs\" as const,\n        created: \"2025-11-09T12:00:00.000Z\",\n        owner: \"testuser\",\n      };\n\n      // Zod parse\n      const zodResult = ProfileSchema.parse(profile);\n\n      // JSON Schema validate\n      const jsonValid = validateJson(profile);\n      assert.ok(jsonValid, `JSON Schema validation failed: ${JSON.stringify(validateJson.errors)}`);\n\n      // Verify equivalence\n      assert.deepStrictEqual(zodResult, profile);\n    });\n\n    it(\"should reject additional properties in both Zod and JSON Schema\", () => {\n      const profile = {\n        role: \"development\",\n        extra: \"field\",\n      };\n\n      // Zod should throw\n      assert.throws(() => ProfileSchema.parse(profile), /unrecognized/i);\n\n      // JSON Schema should reject\n      const jsonValid = validateJson(profile);\n      assert.ok(!jsonValid, \"JSON Schema should reject additional properties\");\n    });\n\n    it(\"should reject invalid data in both Zod and JSON Schema\", () => {\n      const profile = {\n        role: \"invalid-role\",\n      };\n\n      // Zod should throw\n      assert.throws(() => ProfileSchema.parse(profile));\n\n      // JSON Schema should reject\n      const jsonValid = validateJson(profile);\n      assert.ok(!jsonValid, \"JSON Schema should reject invalid enum value\");\n    });\n  });\n\n  // NOTE: GatesSchema migrated to lex-pr-runner in PR #219\n  // Uncomment when lex-pr-runner is published and added as dependency\n  /*\n  describe(\"GatesSchema round-trip\", () => {\n    const jsonSchemaPath = join(\n      dirname(require.resolve(\"lex-pr-runner/package.json\")),\n      \".smartergpt/schemas/gates.schema.json\"\n    );\n    const jsonSchema = JSON.parse(readFileSync(jsonSchemaPath, \"utf-8\"));\n    const validateJson = ajv.compile(jsonSchema);\n\n    it(\"should validate gates configuration through both Zod and JSON Schema\", () => {\n      const gates = {\n        version: \"1.0.0\",\n        gates: [\n          {\n            id: \"gate-1\",\n            type: \"validation\" as const,\n            enabled: true,\n            description: \"Test gate\",\n            config: { timeout: 30, custom: \"value\" },\n          },\n        ],\n      };\n\n      // Zod parse\n      const zodResult = GatesSchema.parse(gates);\n\n      // JSON Schema validate\n      const jsonValid = validateJson(gates);\n      assert.ok(jsonValid, `JSON Schema validation failed: ${JSON.stringify(validateJson.errors)}`);\n\n      // Verify equivalence\n      assert.deepStrictEqual(zodResult, gates);\n    });\n\n    it(\"should allow loose config objects in both schemas\", () => {\n      const gates = {\n        gates: [\n          {\n            id: \"gate-1\",\n            type: \"validation\" as const,\n            enabled: true,\n            config: { anyKey: \"anyValue\", nested: { prop: true } },\n          },\n        ],\n      };\n\n      // Zod parse\n      const zodResult = GatesSchema.parse(gates);\n\n      // JSON Schema validate\n      const jsonValid = validateJson(gates);\n      assert.ok(jsonValid, `JSON Schema validation failed: ${JSON.stringify(validateJson.errors)}`);\n\n      // Verify equivalence\n      assert.deepStrictEqual(zodResult, gates);\n    });\n  });\n  */\n\n  // NOTE: RunnerStackSchema migrated to lex-pr-runner in PR #219\n  /*\n  describe(\"RunnerStackSchema round-trip\", () => {\n    const jsonSchemaPath = join(\n      dirname(require.resolve(\"lex-pr-runner/package.json\")),\n      \".smartergpt/schemas/runner.stack.schema.json\"\n    );\n    const jsonSchema = JSON.parse(readFileSync(jsonSchemaPath, \"utf-8\"));\n    const validateJson = ajv.compile(jsonSchema);\n\n    it(\"should validate stack configuration through both Zod and JSON Schema\", () => {\n      const stack = {\n        version: \"1.0.0\",\n        stack: [\n          {\n            name: \"runtime\",\n            type: \"nodejs\",\n            enabled: true,\n            config: { version: \"20\" },\n          },\n        ],\n        timeout: 300,\n        retries: 3,\n      };\n\n      // Zod parse\n      const zodResult = RunnerStackSchema.parse(stack);\n\n      // JSON Schema validate\n      const jsonValid = validateJson(stack);\n      assert.ok(jsonValid, `JSON Schema validation failed: ${JSON.stringify(validateJson.errors)}`);\n\n      // Verify equivalence\n      assert.deepStrictEqual(zodResult, stack);\n    });\n  });\n  */\n\n  // NOTE: RunnerScopeSchema migrated to lex-pr-runner in PR #219\n  /*\n  describe(\"RunnerScopeSchema round-trip\", () => {\n    const jsonSchemaPath = join(\n      dirname(require.resolve(\"lex-pr-runner/package.json\")),\n      \".smartergpt/schemas/runner.scope.schema.json\"\n    );\n    const jsonSchema = JSON.parse(readFileSync(jsonSchemaPath, \"utf-8\"));\n    const validateJson = ajv.compile(jsonSchema);\n\n    it(\"should validate scope configuration through both Zod and JSON Schema\", () => {\n      const scope = {\n        version: \"1.0.0\",\n        scope: {\n          modules: [\"module1\", \"module2\"],\n          directories: [\"src\", \"lib\"],\n          files: [\"index.ts\"],\n          exclude: [\"*.test.ts\"],\n        },\n        permissions: [\"read\", \"write\"],\n        limits: {\n          maxFiles: 100,\n          maxLines: 5000,\n          maxDuration: 300,\n        },\n      };\n\n      // Zod parse\n      const zodResult = RunnerScopeSchema.parse(scope);\n\n      // JSON Schema validate\n      const jsonValid = validateJson(scope);\n      assert.ok(jsonValid, `JSON Schema validation failed: ${JSON.stringify(validateJson.errors)}`);\n\n      // Verify equivalence\n      assert.deepStrictEqual(zodResult, scope);\n    });\n\n    it(\"should reject additional properties in nested objects\", () => {\n      const scope = {\n        limits: {\n          maxFiles: 100,\n          extra: \"field\",\n        },\n      };\n\n      // Zod should throw\n      assert.throws(() => RunnerScopeSchema.parse(scope), /unrecognized/i);\n\n      // JSON Schema should reject\n      const jsonValid = validateJson(scope);\n      assert.ok(!jsonValid, \"JSON Schema should reject additional properties\");\n    });\n  });\n  */\n\n  describe(\"FeatureSpecV0Schema round-trip\", () => {\n    const jsonSchemaPath = join(__dirname, \"../../.smartergpt/schemas/feature-spec-v0.json\");\n    const jsonSchema = JSON.parse(readFileSync(jsonSchemaPath, \"utf-8\"));\n    const validateJson = ajv.compile(jsonSchema);\n\n    it(\"should validate feature spec through both Zod and JSON Schema\", () => {\n      const spec = {\n        schemaVersion: \"0.1.0\",\n        title: \"Add dark mode support\",\n        description: \"Implement theme switcher with light/dark modes\",\n        acceptanceCriteria: [\"User can toggle between themes\", \"Theme persists\"],\n        technicalContext: \"Use CSS variables for theming\",\n        constraints: \"Must support IE11+\",\n        repo: \"owner/repo\",\n        createdAt: \"2025-11-09T14:30:00.000Z\",\n      };\n\n      // Zod parse\n      const zodResult = FeatureSpecV0Schema.parse(spec);\n\n      // JSON Schema validate\n      const jsonValid = validateJson(spec);\n      assert.ok(jsonValid, `JSON Schema validation failed: ${JSON.stringify(validateJson.errors)}`);\n\n      // Verify equivalence\n      assert.deepStrictEqual(zodResult, spec);\n    });\n\n    it(\"should validate minimal feature spec through both schemas\", () => {\n      const spec = {\n        schemaVersion: \"0.1.0\",\n        title: \"Test Feature\",\n        description: \"A test feature\",\n        repo: \"owner/repo\",\n      };\n\n      // Zod parse\n      const zodResult = FeatureSpecV0Schema.parse(spec);\n\n      // JSON Schema validate\n      const jsonValid = validateJson(spec);\n      assert.ok(jsonValid, `JSON Schema validation failed: ${JSON.stringify(validateJson.errors)}`);\n\n      // Verify equivalence\n      assert.deepStrictEqual(zodResult, spec);\n    });\n  });\n\n  // NOTE: ExecutionPlanV1Schema migrated to lex-pr-runner in PR #219\n  /*\n  describe(\"ExecutionPlanV1Schema round-trip\", () => {\n    const jsonSchemaPath = join(\n      dirname(require.resolve(\"lex-pr-runner/package.json\")),\n      \".smartergpt/schemas/execution-plan-v1.json\"\n    );\n    const jsonSchema = JSON.parse(readFileSync(jsonSchemaPath, \"utf-8\"));\n    const validateJson = ajv.compile(jsonSchema);\n\n    it(\"should validate execution plan through both Zod and JSON Schema\", () => {\n      const plan = {\n        schemaVersion: \"1.0.0\",\n        sourceSpec: {\n          schemaVersion: \"0.1.0\",\n          title: \"Add dark mode support\",\n          description: \"Implement theme switcher\",\n          acceptanceCriteria: [\"Toggle themes\"],\n          technicalContext: \"CSS variables\",\n          repo: \"owner/repo\",\n          createdAt: \"2025-11-09T14:30:00.000Z\",\n        },\n        epic: {\n          title: \"Dark Mode Epic\",\n          description: \"Implement dark mode\",\n          acceptanceCriteria: [\"Toggle themes\"],\n        },\n        subIssues: [\n          {\n            id: \"feature-impl\",\n            title: \"Implement feature\",\n            description: \"Core implementation\",\n            type: \"feature\" as const,\n            acceptanceCriteria: [\"CSS variables defined\"],\n            dependsOn: [],\n          },\n          {\n            id: \"tests\",\n            title: \"Add tests\",\n            description: \"Test coverage\",\n            type: \"testing\" as const,\n            dependsOn: [\"feature-impl\"],\n          },\n        ],\n        createdAt: \"2025-11-09T14:35:00.000Z\",\n      };\n\n      // Zod parse\n      const zodResult = ExecutionPlanV1Schema.parse(plan);\n\n      // JSON Schema validate\n      const jsonValid = validateJson(plan);\n      assert.ok(jsonValid, `JSON Schema validation failed: ${JSON.stringify(validateJson.errors)}`);\n\n      // Verify equivalence\n      assert.deepStrictEqual(zodResult, plan);\n    });\n\n    it(\"should validate minimal execution plan through both schemas\", () => {\n      const plan = {\n        schemaVersion: \"1.0.0\",\n        sourceSpec: {\n          schemaVersion: \"0.1.0\",\n          title: \"Test Feature\",\n          description: \"A test feature\",\n          repo: \"owner/repo\",\n        },\n        epic: {\n          title: \"Epic Title\",\n          description: \"Epic Description\",\n        },\n        subIssues: [],\n      };\n\n      // Zod parse\n      const zodResult = ExecutionPlanV1Schema.parse(plan);\n\n      // JSON Schema validate\n      const jsonValid = validateJson(plan);\n      assert.ok(jsonValid, `JSON Schema validation failed: ${JSON.stringify(validateJson.errors)}`);\n\n      // Verify equivalence\n      assert.deepStrictEqual(zodResult, plan);\n    });\n  });\n  */\n});\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/schemas/validation.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'require' is assigned a value but never used. Allowed unused vars must match /^_/u.","line":12,"column":7,"nodeType":null,"messageId":"unusedVar","endLine":12,"endColumn":14}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { describe, it } from \"node:test\";\nimport { strict as assert } from \"node:assert\";\nimport Ajv from \"ajv\";\nimport addFormats from \"ajv-formats\";\nimport { readFileSync } from \"fs\";\nimport { join, dirname } from \"path\";\nimport { fileURLToPath } from \"url\";\nimport { createRequire } from \"module\";\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = dirname(__filename);\nconst require = createRequire(import.meta.url);\n\ndescribe(\"JSON Schema Validation\", () => {\n  const ajv = new Ajv({\n    strict: true,\n    allErrors: true,\n    validateSchema: false, // Disable meta-schema validation for draft-2020-12 compatibility\n  });\n  addFormats(ajv);\n\n  describe(\"profile.schema.json\", () => {\n    const schemaPath = join(__dirname, \"../../.smartergpt/schemas/profile.schema.json\");\n    const schema = JSON.parse(readFileSync(schemaPath, \"utf-8\"));\n    const validate = ajv.compile(schema);\n\n    it(\"should validate a valid profile with required fields only\", () => {\n      const profile = { role: \"development\" };\n      const valid = validate(profile);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should validate a complete profile\", () => {\n      const profile = {\n        role: \"development\",\n        name: \"Test Profile\",\n        version: \"1.0.0\",\n        projectType: \"nodejs\",\n        created: \"2025-11-09T12:00:00.000Z\",\n        owner: \"testuser\",\n      };\n      const valid = validate(profile);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should reject profile without required role field\", () => {\n      const profile = { name: \"Test Profile\" };\n      const valid = validate(profile);\n      assert.ok(!valid, \"Should reject profile without role\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.message?.includes(\"required\")),\n        \"Should have required field error\"\n      );\n    });\n\n    it(\"should reject profile with invalid role\", () => {\n      const profile = { role: \"invalid\" };\n      const valid = validate(profile);\n      assert.ok(!valid, \"Should reject profile with invalid role\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"enum\"),\n        \"Should have enum validation error\"\n      );\n    });\n\n    it(\"should reject profile with additional properties\", () => {\n      const profile = { role: \"development\", unknown: \"value\" };\n      const valid = validate(profile);\n      assert.ok(!valid, \"Should reject profile with additional properties\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"additionalProperties\"),\n        \"Should have additionalProperties error\"\n      );\n    });\n\n    it(\"should reject profile with invalid date-time format\", () => {\n      const profile = { role: \"development\", created: \"invalid-date\" };\n      const valid = validate(profile);\n      assert.ok(!valid, \"Should reject profile with invalid date-time\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"format\"),\n        \"Should have format validation error\"\n      );\n    });\n\n    it(\"should reject profile with invalid projectType\", () => {\n      const profile = { role: \"development\", projectType: \"rust\" };\n      const valid = validate(profile);\n      assert.ok(!valid, \"Should reject profile with invalid projectType\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"enum\"),\n        \"Should have enum validation error\"\n      );\n    });\n  });\n\n  // NOTE: gates.schema.json migrated to lex-pr-runner in PR #219\n  /*\n  describe(\"gates.schema.json\", () => {\n    const schemaPath = join(\n      dirname(require.resolve(\"lex-pr-runner/package.json\")),\n      \".smartergpt/schemas/gates.schema.json\"\n    );\n    const schema = JSON.parse(readFileSync(schemaPath, \"utf-8\"));\n    const validate = ajv.compile(schema);\n\n    it(\"should validate an empty gates configuration\", () => {\n      const gates = {};\n      const valid = validate(gates);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should validate a complete gates configuration\", () => {\n      const gates = {\n        version: \"1.0.0\",\n        gates: [\n          {\n            id: \"gate-1\",\n            type: \"validation\",\n            enabled: true,\n            description: \"Test gate\",\n            config: { timeout: 30 },\n          },\n        ],\n      };\n      const valid = validate(gates);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should reject gates with additional properties at top level\", () => {\n      const gates = { version: \"1.0.0\", unknown: \"value\" };\n      const valid = validate(gates);\n      assert.ok(!valid, \"Should reject gates with additional properties\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"additionalProperties\"),\n        \"Should have additionalProperties error\"\n      );\n    });\n\n    it(\"should reject gate item without required fields\", () => {\n      const gates = {\n        gates: [{ id: \"gate-1\" }],\n      };\n      const valid = validate(gates);\n      assert.ok(!valid, \"Should reject gate without required fields\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.message?.includes(\"required\")),\n        \"Should have required field error\"\n      );\n    });\n\n    it(\"should reject gate item with invalid type\", () => {\n      const gates = {\n        gates: [{ id: \"gate-1\", type: \"invalid\", enabled: true }],\n      };\n      const valid = validate(gates);\n      assert.ok(!valid, \"Should reject gate with invalid type\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"enum\"),\n        \"Should have enum validation error\"\n      );\n    });\n\n    it(\"should reject gate item with additional properties\", () => {\n      const gates = {\n        gates: [{ id: \"gate-1\", type: \"validation\", enabled: true, extra: \"field\" }],\n      };\n      const valid = validate(gates);\n      assert.ok(!valid, \"Should reject gate with additional properties\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"additionalProperties\"),\n        \"Should have additionalProperties error\"\n      );\n    });\n\n    it(\"should allow config object with any properties (intentionally loose)\", () => {\n      const gates = {\n        gates: [\n          {\n            id: \"gate-1\",\n            type: \"validation\",\n            enabled: true,\n            config: { custom1: \"value\", custom2: 123, nested: { prop: true } },\n          },\n        ],\n      };\n      const valid = validate(gates);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n  });\n  */\n\n  // NOTE: runner.stack.schema.json migrated to lex-pr-runner in PR #219\n  /*\n  describe(\"runner.stack.schema.json\", () => {\n    const schemaPath = join(\n      dirname(require.resolve(\"lex-pr-runner/package.json\")),\n      \".smartergpt/schemas/runner.stack.schema.json\"\n    );\n    const schema = JSON.parse(readFileSync(schemaPath, \"utf-8\"));\n    const validate = ajv.compile(schema);\n\n    it(\"should validate an empty stack configuration\", () => {\n      const stack = {};\n      const valid = validate(stack);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should validate a complete stack configuration\", () => {\n      const stack = {\n        version: \"1.0.0\",\n        stack: [\n          {\n            name: \"runtime\",\n            type: \"nodejs\",\n            enabled: true,\n            config: { version: \"20\" },\n          },\n        ],\n        timeout: 300,\n        retries: 3,\n      };\n      const valid = validate(stack);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should reject stack with additional properties at top level\", () => {\n      const stack = { version: \"1.0.0\", unknown: \"value\" };\n      const valid = validate(stack);\n      assert.ok(!valid, \"Should reject stack with additional properties\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"additionalProperties\"),\n        \"Should have additionalProperties error\"\n      );\n    });\n\n    it(\"should reject stack item without required fields\", () => {\n      const stack = {\n        stack: [{ name: \"runtime\" }],\n      };\n      const valid = validate(stack);\n      assert.ok(!valid, \"Should reject stack item without required fields\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.message?.includes(\"required\")),\n        \"Should have required field error\"\n      );\n    });\n\n    it(\"should reject stack item with additional properties\", () => {\n      const stack = {\n        stack: [{ name: \"runtime\", type: \"nodejs\", extra: \"field\" }],\n      };\n      const valid = validate(stack);\n      assert.ok(!valid, \"Should reject stack item with additional properties\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"additionalProperties\"),\n        \"Should have additionalProperties error\"\n      );\n    });\n\n    it(\"should allow config object with any properties (intentionally loose)\", () => {\n      const stack = {\n        stack: [\n          {\n            name: \"runtime\",\n            type: \"nodejs\",\n            config: { version: \"20\", custom: true, nested: { prop: \"value\" } },\n          },\n        ],\n      };\n      const valid = validate(stack);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n  });\n  */\n\n  // NOTE: runner.scope.schema.json migrated to lex-pr-runner in PR #219\n  /*\n  describe(\"runner.scope.schema.json\", () => {\n    const schemaPath = join(\n      dirname(require.resolve(\"lex-pr-runner/package.json\")),\n      \".smartergpt/schemas/runner.scope.schema.json\"\n    );\n    const schema = JSON.parse(readFileSync(schemaPath, \"utf-8\"));\n    const validate = ajv.compile(schema);\n\n    it(\"should validate an empty scope configuration\", () => {\n      const scope = {};\n      const valid = validate(scope);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should validate a complete scope configuration\", () => {\n      const scope = {\n        version: \"1.0.0\",\n        scope: {\n          modules: [\"module1\", \"module2\"],\n          directories: [\"src\", \"lib\"],\n          files: [\"index.ts\"],\n          exclude: [\"*.test.ts\"],\n        },\n        permissions: [\"read\", \"write\"],\n        limits: {\n          maxFiles: 100,\n          maxLines: 5000,\n          maxDuration: 300,\n        },\n      };\n      const valid = validate(scope);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should reject scope with additional properties at top level\", () => {\n      const scope = { version: \"1.0.0\", unknown: \"value\" };\n      const valid = validate(scope);\n      assert.ok(!valid, \"Should reject scope with additional properties\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"additionalProperties\"),\n        \"Should have additionalProperties error\"\n      );\n    });\n\n    it(\"should reject scope object with additional properties\", () => {\n      const scope = {\n        scope: {\n          modules: [\"module1\"],\n          extra: \"field\",\n        },\n      };\n      const valid = validate(scope);\n      assert.ok(!valid, \"Should reject scope object with additional properties\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"additionalProperties\"),\n        \"Should have additionalProperties error\"\n      );\n    });\n\n    it(\"should reject limits object with additional properties\", () => {\n      const scope = {\n        limits: {\n          maxFiles: 100,\n          extra: \"field\",\n        },\n      };\n      const valid = validate(scope);\n      assert.ok(!valid, \"Should reject limits object with additional properties\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"additionalProperties\"),\n        \"Should have additionalProperties error\"\n      );\n    });\n  });\n  */\n\n  describe(\"feature-spec-v0.json\", () => {\n    const schemaPath = join(__dirname, \"../../.smartergpt/schemas/feature-spec-v0.json\");\n    const schema = JSON.parse(readFileSync(schemaPath, \"utf-8\"));\n    const validate = ajv.compile(schema);\n\n    it(\"should validate a minimal feature spec\", () => {\n      const spec = {\n        schemaVersion: \"0.1.0\",\n        title: \"Test Feature\",\n        description: \"A test feature\",\n        repo: \"owner/repo\",\n      };\n      const valid = validate(spec);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should validate a complete feature spec\", () => {\n      const spec = {\n        schemaVersion: \"0.1.0\",\n        title: \"Add dark mode support\",\n        description: \"Implement theme switcher with light/dark modes\",\n        acceptanceCriteria: [\"User can toggle between themes\", \"Theme persists\"],\n        technicalContext: \"Use CSS variables for theming\",\n        constraints: \"Must support IE11+\",\n        repo: \"owner/repo\",\n        createdAt: \"2025-11-09T14:30:00.000Z\",\n      };\n      const valid = validate(spec);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should reject spec without required fields\", () => {\n      const spec = { schemaVersion: \"0.1.0\", title: \"Test\" };\n      const valid = validate(spec);\n      assert.ok(!valid, \"Should reject spec without required fields\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.message?.includes(\"required\")),\n        \"Should have required field error\"\n      );\n    });\n\n    it(\"should reject spec with additional properties\", () => {\n      const spec = {\n        schemaVersion: \"0.1.0\",\n        title: \"Test\",\n        description: \"Test\",\n        repo: \"owner/repo\",\n        extra: \"field\",\n      };\n      const valid = validate(spec);\n      assert.ok(!valid, \"Should reject spec with additional properties\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"additionalProperties\"),\n        \"Should have additionalProperties error\"\n      );\n    });\n\n    it(\"should reject spec with invalid schemaVersion format\", () => {\n      const spec = {\n        schemaVersion: \"invalid\",\n        title: \"Test\",\n        description: \"Test\",\n        repo: \"owner/repo\",\n      };\n      const valid = validate(spec);\n      assert.ok(!valid, \"Should reject spec with invalid schemaVersion format\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"pattern\"),\n        \"Should have pattern validation error\"\n      );\n    });\n\n    it(\"should reject spec with invalid date-time format\", () => {\n      const spec = {\n        schemaVersion: \"0.1.0\",\n        title: \"Test\",\n        description: \"Test\",\n        repo: \"owner/repo\",\n        createdAt: \"invalid-date\",\n      };\n      const valid = validate(spec);\n      assert.ok(!valid, \"Should reject spec with invalid date-time\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"format\"),\n        \"Should have format validation error\"\n      );\n    });\n  });\n\n  // NOTE: execution-plan-v1.json migrated to lex-pr-runner in PR #219\n  /*\n  describe(\"execution-plan-v1.json\", () => {\n    const schemaPath = join(\n      dirname(require.resolve(\"lex-pr-runner/package.json\")),\n      \".smartergpt/schemas/execution-plan-v1.json\"\n    );\n    const schema = JSON.parse(readFileSync(schemaPath, \"utf-8\"));\n    const validate = ajv.compile(schema);\n\n    it(\"should validate a minimal execution plan\", () => {\n      const plan = {\n        schemaVersion: \"1.0.0\",\n        sourceSpec: {\n          schemaVersion: \"0.1.0\",\n          title: \"Test Feature\",\n          description: \"A test feature\",\n          repo: \"owner/repo\",\n        },\n        epic: {\n          title: \"Epic Title\",\n          description: \"Epic Description\",\n        },\n        subIssues: [],\n      };\n      const valid = validate(plan);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should validate a complete execution plan\", () => {\n      const plan = {\n        schemaVersion: \"1.0.0\",\n        sourceSpec: {\n          schemaVersion: \"0.1.0\",\n          title: \"Add dark mode support\",\n          description: \"Implement theme switcher\",\n          acceptanceCriteria: [\"Toggle themes\"],\n          technicalContext: \"CSS variables\",\n          repo: \"owner/repo\",\n          createdAt: \"2025-11-09T14:30:00.000Z\",\n        },\n        epic: {\n          title: \"Dark Mode Epic\",\n          description: \"Implement dark mode\",\n          acceptanceCriteria: [\"Toggle themes\"],\n        },\n        subIssues: [\n          {\n            id: \"feature-impl\",\n            title: \"Implement feature\",\n            description: \"Core implementation\",\n            type: \"feature\",\n            acceptanceCriteria: [\"CSS variables defined\"],\n            dependsOn: [],\n          },\n        ],\n        createdAt: \"2025-11-09T14:35:00.000Z\",\n      };\n      const valid = validate(plan);\n      assert.ok(valid, `Validation failed: ${JSON.stringify(validate.errors)}`);\n    });\n\n    it(\"should reject plan without required fields\", () => {\n      const plan = {\n        schemaVersion: \"1.0.0\",\n        epic: { title: \"Epic\", description: \"Desc\" },\n      };\n      const valid = validate(plan);\n      assert.ok(!valid, \"Should reject plan without required fields\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.message?.includes(\"required\")),\n        \"Should have required field error\"\n      );\n    });\n\n    it(\"should reject plan with additional properties\", () => {\n      const plan = {\n        schemaVersion: \"1.0.0\",\n        sourceSpec: {\n          schemaVersion: \"0.1.0\",\n          title: \"Test\",\n          description: \"Test\",\n          repo: \"owner/repo\",\n        },\n        epic: { title: \"Epic\", description: \"Desc\" },\n        subIssues: [],\n        extra: \"field\",\n      };\n      const valid = validate(plan);\n      assert.ok(!valid, \"Should reject plan with additional properties\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"additionalProperties\"),\n        \"Should have additionalProperties error\"\n      );\n    });\n\n    it(\"should reject sub-issue with invalid type\", () => {\n      const plan = {\n        schemaVersion: \"1.0.0\",\n        sourceSpec: {\n          schemaVersion: \"0.1.0\",\n          title: \"Test\",\n          description: \"Test\",\n          repo: \"owner/repo\",\n        },\n        epic: { title: \"Epic\", description: \"Desc\" },\n        subIssues: [\n          {\n            id: \"test\",\n            title: \"Test\",\n            description: \"Test\",\n            type: \"invalid\",\n            dependsOn: [],\n          },\n        ],\n      };\n      const valid = validate(plan);\n      assert.ok(!valid, \"Should reject sub-issue with invalid type\");\n      assert.ok(validate.errors);\n      assert.ok(\n        validate.errors.some((e) => e.keyword === \"enum\"),\n        \"Should have enum validation error\"\n      );\n    });\n  });\n  */\n});\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/aliases/case-sensitivity.spec.mjs","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'entry' is assigned a value but never used. Allowed unused vars must match /^_/u.","line":75,"column":22,"nodeType":null,"messageId":"unusedVar","endLine":75,"endColumn":27}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Tests for case sensitivity in alias resolution\n *\n * Tests case-sensitive behavior of aliases and provides\n * case normalization utilities and validation.\n *\n * Run with: node --test src/shared/aliases/case-sensitivity.spec.mjs\n */\n\nimport { strict as assert } from \"assert\";\nimport { test, describe } from \"node:test\";\nimport {\n  resolveModuleId,\n  clearAliasTableCache,\n} from \"../../../dist/shared/aliases/resolver.js\";\n\n// Sample policy for case sensitivity testing\nconst samplePolicy = {\n  modules: {\n    \"services/auth-core\": {\n      description: \"Core authentication service\",\n      owns_paths: [\"services/auth/**\"],\n    },\n    \"UI/AdminPanel\": {\n      description: \"Admin panel with mixed case\",\n      owns_paths: [\"web-ui/admin/**\"],\n    },\n    \"api/UserService\": {\n      description: \"User service API with PascalCase\",\n      owns_paths: [\"api/users/**\"],\n    },\n  },\n};\n\n/**\n * Normalize alias to lowercase with validation\n * \n * Best practice: All aliases should be lowercase for consistency\n * and to avoid confusion between \"Cli-Core\", \"cli-core\", \"CLI-CORE\"\n *\n * @param alias - The alias to normalize\n * @returns Normalized lowercase alias\n */\nexport function normalizeAlias(alias) {\n  if (typeof alias !== \"string\") {\n    throw new TypeError(\"Alias must be a string\");\n  }\n  return alias.toLowerCase().trim();\n}\n\n/**\n * Validate that an alias follows lowercase convention\n *\n * @param alias - The alias to validate\n * @returns true if alias is valid (lowercase), false otherwise\n */\nexport function validateAliasCase(alias) {\n  if (typeof alias !== \"string\" || alias.length === 0) {\n    return false;\n  }\n\n  const normalized = normalizeAlias(alias);\n  return alias === normalized;\n}\n\n/**\n * Lint an alias table for case sensitivity issues\n *\n * @param aliasTable - The alias table to lint\n * @returns Array of validation errors, empty if valid\n */\nexport function lintAliasTableCase(aliasTable) {\n  const errors = [];\n\n  for (const [alias, entry] of Object.entries(aliasTable.aliases)) {\n    if (!validateAliasCase(alias)) {\n      errors.push({\n        alias,\n        issue: \"non-lowercase\",\n        suggestion: normalizeAlias(alias),\n        message: `Alias \"${alias}\" should be lowercase: \"${normalizeAlias(alias)}\"`,\n      });\n    }\n\n    // Also check for potential collisions after normalization\n    const normalized = normalizeAlias(alias);\n    if (normalized !== alias) {\n      // Check if normalized version already exists\n      if (aliasTable.aliases[normalized]) {\n        errors.push({\n          alias,\n          issue: \"normalization-collision\",\n          normalized,\n          message: `Alias \"${alias}\" would collide with \"${normalized}\" after normalization`,\n        });\n      }\n    }\n  }\n\n  return errors;\n}\n\ndescribe(\"Case Sensitivity in Aliases\", () => {\n  test(\"alias 'Cli-Core' vs 'cli-core' are treated as distinct\", async () => {\n    clearAliasTableCache();\n\n    const aliasTable = {\n      aliases: {\n        \"Cli-Core\": {\n          canonical: \"services/auth-core\",\n          confidence: 1.0,\n          reason: \"mixed case alias\",\n        },\n        \"cli-core\": {\n          canonical: \"UI/AdminPanel\",\n          confidence: 1.0,\n          reason: \"lowercase alias\",\n        },\n      },\n    };\n\n    const result1 = await resolveModuleId(\"Cli-Core\", samplePolicy, aliasTable);\n    const result2 = await resolveModuleId(\"cli-core\", samplePolicy, aliasTable);\n\n    // They resolve to different modules (case-sensitive)\n    assert.equal(result1.canonical, \"services/auth-core\");\n    assert.equal(result2.canonical, \"UI/AdminPanel\");\n    assert.notEqual(result1.canonical, result2.canonical);\n  });\n\n  test(\"case mismatch in alias lookup returns no match\", async () => {\n    clearAliasTableCache();\n\n    const aliasTable = {\n      aliases: {\n        \"auth-core\": {\n          canonical: \"services/auth-core\",\n          confidence: 1.0,\n        },\n      },\n    };\n\n    // Try to resolve with different case\n    const result = await resolveModuleId(\"Auth-Core\", samplePolicy, aliasTable, {\n      noSubstring: true, // Disable substring matching to isolate alias behavior\n    });\n\n    // Should not find alias (case-sensitive), falls back to fuzzy\n    assert.equal(result.confidence, 0);\n    assert.equal(result.source, \"fuzzy\");\n  });\n\n  test(\"exact module ID match is case-sensitive\", async () => {\n    clearAliasTableCache();\n\n    const resultExact = await resolveModuleId(\"UI/AdminPanel\", samplePolicy);\n    const resultWrongCase = await resolveModuleId(\"ui/adminpanel\", samplePolicy);\n\n    // Exact case matches\n    assert.equal(resultExact.canonical, \"UI/AdminPanel\");\n    assert.equal(resultExact.source, \"exact\");\n    assert.equal(resultExact.confidence, 1.0);\n\n    // Wrong case doesn't match exactly, falls to substring/fuzzy\n    assert.notEqual(resultWrongCase.source, \"exact\");\n  });\n});\n\ndescribe(\"Case Normalization Function\", () => {\n  test(\"normalizeAlias converts to lowercase\", () => {\n    assert.equal(normalizeAlias(\"Cli-Core\"), \"cli-core\");\n    assert.equal(normalizeAlias(\"AUTH-CORE\"), \"auth-core\");\n    assert.equal(normalizeAlias(\"MixedCaseAlias\"), \"mixedcasealias\");\n  });\n\n  test(\"normalizeAlias handles already lowercase\", () => {\n    assert.equal(normalizeAlias(\"cli-core\"), \"cli-core\");\n    assert.equal(normalizeAlias(\"auth\"), \"auth\");\n  });\n\n  test(\"normalizeAlias trims whitespace\", () => {\n    assert.equal(normalizeAlias(\"  cli-core  \"), \"cli-core\");\n    assert.equal(normalizeAlias(\"\\tauth-core\\n\"), \"auth-core\");\n  });\n\n  test(\"normalizeAlias handles special characters\", () => {\n    assert.equal(normalizeAlias(\"Cli-Core_123\"), \"cli-core_123\");\n    assert.equal(normalizeAlias(\"Auth/Service\"), \"auth/service\");\n  });\n\n  test(\"normalizeAlias throws on non-string input\", () => {\n    assert.throws(() => normalizeAlias(null), TypeError);\n    assert.throws(() => normalizeAlias(undefined), TypeError);\n    assert.throws(() => normalizeAlias(123), TypeError);\n    assert.throws(() => normalizeAlias({}), TypeError);\n  });\n\n  test(\"normalizeAlias is idempotent\", () => {\n    const alias = \"Cli-Core\";\n    const normalized = normalizeAlias(alias);\n    assert.equal(normalizeAlias(normalized), normalized);\n  });\n});\n\ndescribe(\"Case Validation Function\", () => {\n  test(\"validateAliasCase accepts lowercase aliases\", () => {\n    assert.ok(validateAliasCase(\"cli-core\"));\n    assert.ok(validateAliasCase(\"auth-service\"));\n    assert.ok(validateAliasCase(\"user-api\"));\n  });\n\n  test(\"validateAliasCase rejects mixed case aliases\", () => {\n    assert.ok(!validateAliasCase(\"Cli-Core\"));\n    assert.ok(!validateAliasCase(\"Auth-Service\"));\n    assert.ok(!validateAliasCase(\"UserAPI\"));\n  });\n\n  test(\"validateAliasCase rejects uppercase aliases\", () => {\n    assert.ok(!validateAliasCase(\"CLI-CORE\"));\n    assert.ok(!validateAliasCase(\"AUTH\"));\n  });\n\n  test(\"validateAliasCase rejects empty string\", () => {\n    assert.ok(!validateAliasCase(\"\"));\n  });\n\n  test(\"validateAliasCase rejects whitespace-only\", () => {\n    assert.ok(!validateAliasCase(\"   \"));\n  });\n\n  test(\"validateAliasCase rejects non-string types\", () => {\n    assert.ok(!validateAliasCase(null));\n    assert.ok(!validateAliasCase(undefined));\n    assert.ok(!validateAliasCase(123));\n    assert.ok(!validateAliasCase({}));\n  });\n\n  test(\"validateAliasCase allows numbers and special chars if lowercase\", () => {\n    assert.ok(validateAliasCase(\"cli-core-123\"));\n    assert.ok(validateAliasCase(\"auth_service\"));\n    assert.ok(validateAliasCase(\"user/api\"));\n  });\n});\n\ndescribe(\"Alias Table Linting\", () => {\n  test(\"lintAliasTableCase detects non-lowercase aliases\", () => {\n    const aliasTable = {\n      aliases: {\n        \"Cli-Core\": {\n          canonical: \"services/cli-core\",\n          confidence: 1.0,\n        },\n        \"auth-service\": {\n          canonical: \"services/auth\",\n          confidence: 1.0,\n        },\n        \"UserAPI\": {\n          canonical: \"api/users\",\n          confidence: 1.0,\n        },\n      },\n    };\n\n    const errors = lintAliasTableCase(aliasTable);\n\n    assert.equal(errors.length, 2); // Two non-lowercase aliases\n    assert.ok(errors.some((e) => e.alias === \"Cli-Core\"));\n    assert.ok(errors.some((e) => e.alias === \"UserAPI\"));\n    assert.ok(!errors.some((e) => e.alias === \"auth-service\"));\n  });\n\n  test(\"lintAliasTableCase returns empty for valid table\", () => {\n    const aliasTable = {\n      aliases: {\n        \"cli-core\": {\n          canonical: \"services/cli-core\",\n          confidence: 1.0,\n        },\n        \"auth-service\": {\n          canonical: \"services/auth\",\n          confidence: 1.0,\n        },\n      },\n    };\n\n    const errors = lintAliasTableCase(aliasTable);\n    assert.equal(errors.length, 0);\n  });\n\n  test(\"lintAliasTableCase detects normalization collisions\", () => {\n    const aliasTable = {\n      aliases: {\n        \"cli-core\": {\n          canonical: \"services/cli-core\",\n          confidence: 1.0,\n        },\n        \"Cli-Core\": {\n          canonical: \"services/cli-core-v2\",\n          confidence: 1.0,\n        },\n      },\n    };\n\n    const errors = lintAliasTableCase(aliasTable);\n\n    // Should detect that \"Cli-Core\" would collide with \"cli-core\" after normalization\n    assert.ok(errors.length > 0);\n    const collisionError = errors.find((e) => e.issue === \"normalization-collision\");\n    assert.ok(collisionError);\n    assert.equal(collisionError.alias, \"Cli-Core\");\n    assert.equal(collisionError.normalized, \"cli-core\");\n  });\n\n  test(\"lintAliasTableCase provides suggestions\", () => {\n    const aliasTable = {\n      aliases: {\n        \"Auth-Core\": {\n          canonical: \"services/auth-core\",\n          confidence: 1.0,\n        },\n      },\n    };\n\n    const errors = lintAliasTableCase(aliasTable);\n\n    assert.equal(errors.length, 1);\n    assert.equal(errors[0].suggestion, \"auth-core\");\n    assert.ok(errors[0].message.includes(\"should be lowercase\"));\n  });\n});\n\ndescribe(\"Recommendation: Enforce Lowercase\", () => {\n  test(\"lowercase convention avoids confusion\", () => {\n    // This test documents the recommendation\n\n    const confusingAliases = [\"Cli-Core\", \"cli-core\", \"CLI-CORE\", \"cLi-CoRe\"];\n\n    // All of these are distinct in a case-sensitive system\n    // but could confuse users who expect case-insensitive matching\n\n    const uniqueNormalized = new Set(confusingAliases.map(normalizeAlias));\n    assert.equal(uniqueNormalized.size, 1); // All normalize to same value\n\n    // Therefore: enforce lowercase to prevent confusion\n  });\n\n  test(\"lowercase allows case-insensitive substring matching\", async () => {\n    clearAliasTableCache();\n\n    // Even though aliases are case-sensitive,\n    // substring matching is case-insensitive\n\n    const result1 = await resolveModuleId(\"auth\", samplePolicy);\n    const result2 = await resolveModuleId(\"AUTH\", samplePolicy);\n\n    // Both should match 'services/auth-core' via substring\n    assert.equal(result1.canonical, \"services/auth-core\");\n    assert.equal(result2.canonical, \"services/auth-core\");\n    assert.equal(result1.source, \"substring\");\n    assert.equal(result2.source, \"substring\");\n  });\n\n  test(\"mixed case in canonical IDs is preserved\", async () => {\n    clearAliasTableCache();\n\n    const aliasTable = {\n      aliases: {\n        \"admin\": {\n          canonical: \"UI/AdminPanel\", // Canonical has mixed case\n          confidence: 1.0,\n        },\n      },\n    };\n\n    const result = await resolveModuleId(\"admin\", samplePolicy, aliasTable);\n\n    // Canonical ID case is preserved exactly\n    assert.equal(result.canonical, \"UI/AdminPanel\");\n    assert.equal(result.source, \"alias\");\n  });\n});\n\ndescribe(\"Integration with Linter/Validator\", () => {\n  test(\"alias table with violations should fail validation\", () => {\n    const invalidAliasTable = {\n      aliases: {\n        \"Auth-Core\": {\n          canonical: \"services/auth-core\",\n          confidence: 1.0,\n        },\n      },\n    };\n\n    const errors = lintAliasTableCase(invalidAliasTable);\n\n    // In a CI pipeline, this would cause a failure\n    if (errors.length > 0) {\n      assert.ok(true, \"Linter detected violations\");\n    }\n  });\n\n  test(\"alias table linting is fast enough for CI\", () => {\n    // Generate large alias table\n    const largeAliasTable = {\n      aliases: {},\n    };\n\n    for (let i = 0; i < 1000; i++) {\n      largeAliasTable.aliases[`alias-${i}`] = {\n        canonical: `module-${i}`,\n        confidence: 1.0,\n      };\n    }\n\n    const startTime = Date.now();\n    const errors = lintAliasTableCase(largeAliasTable);\n    const duration = Date.now() - startTime;\n\n    // Should complete in reasonable time (< 100ms for 1000 aliases)\n    assert.ok(duration < 100, `Linting took ${duration}ms, should be < 100ms`);\n    assert.equal(errors.length, 0); // All valid lowercase\n  });\n});\n\ndescribe(\"Case Sensitivity Edge Cases\", () => {\n  test(\"unicode characters in aliases maintain case\", () => {\n    const aliases = [\"cafÃ©\", \"CAFÃ‰\", \"CafÃ©\"];\n\n    const normalized = aliases.map(normalizeAlias);\n\n    // All normalize to lowercase\n    assert.equal(normalized[0], \"cafÃ©\");\n    assert.equal(normalized[1], \"cafÃ©\");\n    assert.equal(normalized[2], \"cafÃ©\");\n  });\n\n  test(\"numbers and symbols don't have case\", () => {\n    assert.equal(normalizeAlias(\"module-123\"), \"module-123\");\n    assert.equal(normalizeAlias(\"api/v2\"), \"api/v2\");\n    assert.equal(normalizeAlias(\"core_service\"), \"core_service\");\n  });\n\n  test(\"empty or whitespace-only aliases are invalid\", () => {\n    assert.ok(!validateAliasCase(\"\"));\n    assert.ok(!validateAliasCase(\"   \"));\n    assert.ok(!validateAliasCase(\"\\t\\n\"));\n  });\n});\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/aliases/collision.spec.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/aliases/failure-modes.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/aliases/lexrunner.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/aliases/resolution.spec.mjs","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'assert' is defined but never used. Allowed unused vars must match /^_/u.","line":11,"column":20,"nodeType":null,"messageId":"unusedVar","endLine":11,"endColumn":26},{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'entry' is assigned a value but never used. Allowed unused vars must match /^_/u.","line":157,"column":24,"nodeType":null,"messageId":"unusedVar","endLine":157,"endColumn":29}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Snapshot tests for alias resolution\n *\n * Tests that verify the complete resolution output format,\n * useful for detecting breaking changes in the alias system.\n *\n * Run with: node --test src/shared/aliases/resolution.spec.mjs\n * Update snapshots with: LEX_UPDATE_SNAPSHOTS=1 node --test src/shared/aliases/resolution.spec.mjs\n */\n\nimport { strict as assert } from \"assert\";\nimport { test, describe } from \"node:test\";\nimport { readFileSync, writeFileSync, mkdirSync, existsSync } from \"fs\";\nimport { join, dirname } from \"path\";\nimport { fileURLToPath } from \"url\";\nimport {\n  resolveModuleId,\n  clearAliasTableCache,\n} from \"../../../dist/shared/aliases/resolver.js\";\n\n// Get directory for snapshots\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = dirname(__filename);\nconst SNAPSHOTS_DIR = join(__dirname, \"__snapshots__\");\nconst SNAPSHOT_FILE = join(SNAPSHOTS_DIR, \"resolution.spec.mjs.snap\");\n\n/**\n * Simple snapshot testing utility for Node.js test runner\n */\nclass SnapshotManager {\n  constructor(snapshotFile) {\n    this.snapshotFile = snapshotFile;\n    this.snapshots = {};\n    this.updateMode = process.env.LEX_UPDATE_SNAPSHOTS === \"1\";\n    this.dirty = false;\n    this.load();\n  }\n\n  load() {\n    try {\n      if (existsSync(this.snapshotFile)) {\n        const content = readFileSync(this.snapshotFile, \"utf-8\");\n        this.snapshots = JSON.parse(content);\n      }\n    } catch (error) {\n      console.warn(`Could not load snapshots: ${error.message}`);\n      this.snapshots = {};\n    }\n  }\n\n  save() {\n    if (!this.dirty) return;\n\n    try {\n      mkdirSync(dirname(this.snapshotFile), { recursive: true });\n      writeFileSync(this.snapshotFile, JSON.stringify(this.snapshots, null, 2), \"utf-8\");\n    } catch (error) {\n      console.error(`Could not save snapshots: ${error.message}`);\n    }\n  }\n\n  matchSnapshot(testName, value) {\n    const serialized = JSON.stringify(value, null, 2);\n\n    if (this.updateMode) {\n      this.snapshots[testName] = serialized;\n      this.dirty = true;\n      return true;\n    }\n\n    if (!this.snapshots[testName]) {\n      throw new Error(\n        `Snapshot for \"${testName}\" does not exist. Run with LEX_UPDATE_SNAPSHOTS=1 to create.`\n      );\n    }\n\n    const expected = this.snapshots[testName];\n    if (serialized !== expected) {\n      throw new Error(\n        `Snapshot mismatch for \"${testName}\":\\n\\nExpected:\\n${expected}\\n\\nReceived:\\n${serialized}`\n      );\n    }\n\n    return true;\n  }\n}\n\nconst snapshots = new SnapshotManager(SNAPSHOT_FILE);\n\n// Save snapshots after all tests\nprocess.on(\"exit\", () => {\n  snapshots.save();\n});\n\n// Sample policy for snapshot tests\nconst samplePolicy = {\n  modules: {\n    \"src/cli/flags.ts\": {\n      description: \"CLI flags module\",\n      owns_paths: [\"src/cli/flags.ts\"],\n    },\n    \"src/cli/commands.ts\": {\n      description: \"CLI commands module\",\n      owns_paths: [\"src/cli/commands.ts\"],\n    },\n    \"src/gates/runner.ts\": {\n      description: \"Gates runner module\",\n      owns_paths: [\"src/gates/runner.ts\"],\n    },\n    \"services/auth-core\": {\n      description: \"Authentication core service\",\n      owns_paths: [\"services/auth/**\"],\n    },\n    \"services/user-api\": {\n      description: \"User API service\",\n      owns_paths: [\"services/users/**\"],\n    },\n  },\n};\n\ndescribe(\"Snapshot Tests: Alias Resolution\", () => {\n  test(\"snapshot: complete alias map resolution\", async () => {\n    clearAliasTableCache();\n\n    const aliasTable = {\n      aliases: {\n        \"cli-flags\": {\n          canonical: \"src/cli/flags.ts\",\n          confidence: 1.0,\n          reason: \"shorthand\",\n        },\n        \"cli-commands\": {\n          canonical: \"src/cli/commands.ts\",\n          confidence: 1.0,\n          reason: \"shorthand\",\n        },\n        \"gates-runner\": {\n          canonical: \"src/gates/runner.ts\",\n          confidence: 1.0,\n          reason: \"shorthand\",\n        },\n        \"auth\": {\n          canonical: \"services/auth-core\",\n          confidence: 1.0,\n          reason: \"common shorthand\",\n        },\n        \"user\": {\n          canonical: \"services/user-api\",\n          confidence: 1.0,\n          reason: \"common shorthand\",\n        },\n      },\n    };\n\n    // Resolve all aliases\n    const aliasResolutionMap = {};\n    for (const [alias, entry] of Object.entries(aliasTable.aliases)) {\n      const result = await resolveModuleId(alias, samplePolicy, aliasTable);\n      aliasResolutionMap[alias] = result.canonical;\n    }\n\n    // Snapshot the complete resolution map\n    snapshots.matchSnapshot(\"alias-map-resolution\", aliasResolutionMap);\n  });\n\n  test(\"snapshot: Frame moduleScope after aliasing\", async () => {\n    clearAliasTableCache();\n\n    const aliasTable = {\n      aliases: {\n        \"cli-flags\": {\n          canonical: \"src/cli/flags.ts\",\n          confidence: 1.0,\n        },\n        \"gates-runner\": {\n          canonical: \"src/gates/runner.ts\",\n          confidence: 1.0,\n        },\n      },\n    };\n\n    // Simulate user input with aliases\n    const userInputModules = [\"cli-flags\", \"src/cli/commands.ts\", \"gates-runner\"];\n\n    // Resolve all inputs to canonical IDs (as would be stored in Frame)\n    const resolvedModuleScope = [];\n    for (const input of userInputModules) {\n      const result = await resolveModuleId(input, samplePolicy, aliasTable);\n      resolvedModuleScope.push(result.canonical);\n    }\n\n    // Snapshot the final moduleScope that would be stored in Frame\n    snapshots.matchSnapshot(\"frame-module-scope\", resolvedModuleScope);\n  });\n\n  test(\"snapshot: resolution with mixed sources\", async () => {\n    clearAliasTableCache();\n\n    const aliasTable = {\n      aliases: {\n        \"auth\": {\n          canonical: \"services/auth-core\",\n          confidence: 1.0,\n        },\n      },\n    };\n\n    // Test various resolution methods\n    const testCases = [\n      { input: \"services/auth-core\", description: \"exact match\" },\n      { input: \"auth\", description: \"alias match\" },\n      { input: \"flags\", description: \"substring match\" },\n      { input: \"unknown-module\", description: \"no match\" },\n    ];\n\n    const resolutions = {};\n    for (const testCase of testCases) {\n      const result = await resolveModuleId(testCase.input, samplePolicy, aliasTable);\n      resolutions[testCase.input] = {\n        canonical: result.canonical,\n        confidence: result.confidence,\n        source: result.source,\n        description: testCase.description,\n      };\n    }\n\n    snapshots.matchSnapshot(\"mixed-source-resolutions\", resolutions);\n  });\n\n  test(\"snapshot: alias resolution priority order\", async () => {\n    clearAliasTableCache();\n\n    // Create scenario where same input could match multiple ways\n    const aliasTable = {\n      aliases: {\n        \"src/cli/flags.ts\": {\n          canonical: \"services/auth-core\", // Alias for exact module ID\n          confidence: 1.0,\n        },\n      },\n    };\n\n    const result = await resolveModuleId(\"src/cli/flags.ts\", samplePolicy, aliasTable);\n\n    // Should prefer exact match over alias\n    snapshots.matchSnapshot(\"priority-exact-over-alias\", {\n      input: \"src/cli/flags.ts\",\n      canonical: result.canonical,\n      source: result.source,\n      confidence: result.confidence,\n      note: \"exact match takes precedence over alias lookup\",\n    });\n  });\n});\n\ndescribe(\"Snapshot Tests: Error Cases\", () => {\n  test(\"snapshot: ambiguous substring resolution\", async () => {\n    clearAliasTableCache();\n\n    // 'cli' matches both 'src/cli/flags.ts' and 'src/cli/commands.ts'\n    const result = await resolveModuleId(\"cli\", samplePolicy);\n\n    snapshots.matchSnapshot(\"ambiguous-substring\", {\n      input: \"cli\",\n      canonical: result.canonical,\n      confidence: result.confidence,\n      source: result.source,\n      note: \"ambiguous substring returns confidence 0\",\n    });\n  });\n\n  test(\"snapshot: unknown module resolution\", async () => {\n    clearAliasTableCache();\n\n    const result = await resolveModuleId(\"completely-unknown\", samplePolicy);\n\n    snapshots.matchSnapshot(\"unknown-module\", {\n      input: \"completely-unknown\",\n      canonical: result.canonical,\n      confidence: result.confidence,\n      source: result.source,\n      note: \"unknown returns original with confidence 0\",\n    });\n  });\n\n  test(\"snapshot: empty input resolution\", async () => {\n    clearAliasTableCache();\n\n    const result = await resolveModuleId(\"\", samplePolicy);\n\n    snapshots.matchSnapshot(\"empty-input\", {\n      input: \"\",\n      canonical: result.canonical,\n      confidence: result.confidence,\n      source: result.source,\n    });\n  });\n});\n\ndescribe(\"Snapshot Tests: Breaking Change Detection\", () => {\n  test(\"snapshot: resolution output format\", async () => {\n    clearAliasTableCache();\n\n    const result = await resolveModuleId(\"services/auth-core\", samplePolicy);\n\n    // Snapshot the complete result structure\n    // Any change to AliasResolution interface would break this\n    snapshots.matchSnapshot(\"resolution-output-format\", {\n      canonical: result.canonical,\n      confidence: result.confidence,\n      original: result.original,\n      source: result.source,\n      typeCheck: {\n        hasCanonical: typeof result.canonical === \"string\",\n        hasConfidence: typeof result.confidence === \"number\",\n        hasOriginal: typeof result.original === \"string\",\n        hasSource: typeof result.source === \"string\",\n        validSource: [\"exact\", \"alias\", \"fuzzy\", \"substring\"].includes(result.source),\n      },\n    });\n  });\n\n  test(\"snapshot: alias table structure\", () => {\n    const aliasTable = {\n      aliases: {\n        \"test-alias\": {\n          canonical: \"services/test\",\n          confidence: 1.0,\n          reason: \"test reason\",\n        },\n      },\n    };\n\n    // Snapshot the expected alias table structure\n    // Changes to AliasTable or AliasEntry interfaces would break this\n    snapshots.matchSnapshot(\"alias-table-structure\", {\n      aliases: aliasTable.aliases,\n      typeCheck: {\n        isObject: typeof aliasTable.aliases === \"object\",\n        hasEntries: Object.keys(aliasTable.aliases).length > 0,\n        entryStructure: Object.values(aliasTable.aliases).map((entry) => ({\n          hasCanonical: \"canonical\" in entry,\n          hasConfidence: \"confidence\" in entry,\n          hasReason: \"reason\" in entry,\n          canonicalType: typeof entry.canonical,\n          confidenceType: typeof entry.confidence,\n          reasonType: typeof entry.reason,\n        }))[0],\n      },\n    });\n  });\n});\n\ndescribe(\"Snapshot Tests: Real-World Scenarios\", () => {\n  test(\"snapshot: batch resolution for /remember command\", async () => {\n    clearAliasTableCache();\n\n    const aliasTable = {\n      aliases: {\n        \"auth\": {\n          canonical: \"services/auth-core\",\n          confidence: 1.0,\n        },\n        \"user\": {\n          canonical: \"services/user-api\",\n          confidence: 1.0,\n        },\n      },\n    };\n\n    // Simulate user typing mixed aliases and exact IDs\n    const userInput = [\"auth\", \"src/cli/flags.ts\", \"user\", \"gates\"];\n\n    const batchResolution = [];\n    for (const input of userInput) {\n      const result = await resolveModuleId(input, samplePolicy, aliasTable);\n      batchResolution.push({\n        input,\n        canonical: result.canonical,\n        confidence: result.confidence,\n        source: result.source,\n      });\n    }\n\n    snapshots.matchSnapshot(\"batch-remember-resolution\", batchResolution);\n  });\n\n  test(\"snapshot: refactoring migration scenario\", async () => {\n    clearAliasTableCache();\n\n    // Scenario: Module was refactored, old paths aliased to new\n    const aliasTable = {\n      aliases: {\n        \"old/auth/service\": {\n          canonical: \"services/auth-core\",\n          confidence: 1.0,\n          reason: \"refactored 2025-10-15\",\n        },\n        \"legacy/user-access\": {\n          canonical: \"services/user-api\",\n          confidence: 1.0,\n          reason: \"renamed 2025-11-01\",\n        },\n      },\n    };\n\n    const oldPaths = [\"old/auth/service\", \"legacy/user-access\"];\n    const migrations = {};\n\n    for (const oldPath of oldPaths) {\n      const result = await resolveModuleId(oldPath, samplePolicy, aliasTable);\n      migrations[oldPath] = {\n        newCanonical: result.canonical,\n        migrationNote: aliasTable.aliases[oldPath]?.reason,\n      };\n    }\n\n    snapshots.matchSnapshot(\"refactoring-migration\", migrations);\n  });\n});\n\ndescribe(\"Snapshot Update Instructions\", () => {\n  test(\"documentation: how to update snapshots\", () => {\n    const instructions = {\n      command: \"LEX_UPDATE_SNAPSHOTS=1 node --test src/shared/aliases/resolution.spec.mjs\",\n      purpose:\n        \"Updates snapshot files when the resolution output intentionally changes\",\n      when_to_update: [\n        \"Adding new fields to AliasResolution interface\",\n        \"Changing resolution algorithm output\",\n        \"Updating canonical module IDs in policy\",\n        \"Modifying alias table structure\",\n      ],\n      review_required:\n        \"Always review snapshot diffs in PR to ensure changes are intentional\",\n      location: \"__snapshots__/resolution.spec.mjs.snap\",\n    };\n\n    // This snapshot documents how to use snapshot testing\n    snapshots.matchSnapshot(\"snapshot-update-instructions\", instructions);\n  });\n});\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/aliases/resolver.test.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/aliases/substring.spec.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/atlas/atlas-frame.test.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/atlas/auto-tune.test.mjs","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'result' is assigned a value but never used. Allowed unused vars must match /^_/u.","line":144,"column":11,"nodeType":null,"messageId":"unusedVar","endLine":144,"endColumn":17}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Tests for Auto-Tuning\n *\n * Run with: node shared/atlas/auto-tune.test.mjs\n */\n\nimport { strict as assert } from \"assert\";\nimport { test, describe } from \"node:test\";\n// Adjusted import path to built dist output\nimport {\n  estimateTokens,\n  autoTuneRadius,\n  estimateTokensBeforeGeneration,\n} from \"../../../dist/shared/atlas/auto-tune.js\";\n\ndescribe(\"estimateTokens\", () => {\n  test(\"estimates tokens based on JSON size\", () => {\n    const mockFrame = {\n      atlas_timestamp: \"2025-01-01T00:00:00Z\",\n      seed_modules: [\"module-a\"],\n      fold_radius: 1,\n      modules: [],\n      edges: [],\n      critical_rule: \"test\",\n    };\n\n    const tokens = estimateTokens(mockFrame);\n\n    // Should be approximately JSON.stringify(mockFrame).length / 4\n    const json = JSON.stringify(mockFrame);\n    const expected = Math.ceil(json.length / 4);\n\n    assert.equal(tokens, expected);\n    assert.ok(tokens > 0);\n  });\n\n  test(\"larger frames have more tokens\", () => {\n    const smallFrame = {\n      atlas_timestamp: \"2025-01-01T00:00:00Z\",\n      seed_modules: [\"a\"],\n      fold_radius: 1,\n      modules: [],\n      edges: [],\n      critical_rule: \"test\",\n    };\n\n    const largeFrame = {\n      atlas_timestamp: \"2025-01-01T00:00:00Z\",\n      seed_modules: [\"module-a\", \"module-b\", \"module-c\"],\n      fold_radius: 2,\n      modules: [\n        { id: \"a\", coords: [100, 200], allowed_callers: [\"b\", \"c\"] },\n        { id: \"b\", coords: [150, 250], forbidden_callers: [\"d\"] },\n        { id: \"c\", coords: [200, 300], feature_flags: [\"flag1\", \"flag2\"] },\n      ],\n      edges: [\n        { from: \"a\", to: \"b\", allowed: true },\n        { from: \"b\", to: \"c\", allowed: false, reason: \"test\" },\n      ],\n      critical_rule: \"test rule with more text\",\n    };\n\n    const smallTokens = estimateTokens(smallFrame);\n    const largeTokens = estimateTokens(largeFrame);\n\n    assert.ok(largeTokens > smallTokens);\n  });\n});\n\ndescribe(\"autoTuneRadius\", () => {\n  test(\"returns frame when within token limit\", () => {\n    const generateFn = (radius) => ({\n      atlas_timestamp: \"2025-01-01T00:00:00Z\",\n      seed_modules: [\"a\"],\n      fold_radius: radius,\n      modules: [],\n      edges: [],\n      critical_rule: \"test\",\n    });\n\n    const result = autoTuneRadius(generateFn, 2, 10000);\n\n    assert.equal(result.radiusUsed, 2);\n    assert.ok(result.tokensUsed > 0);\n    assert.ok(result.tokensUsed < 10000);\n  });\n\n  test(\"reduces radius when exceeding token limit\", () => {\n    let callCount = 0;\n    const generateFn = (radius) => {\n      callCount++;\n      // Create frames that are clearly over/under the limit\n      // Radius 2 = ~331 tokens, radius 1 = ~231 tokens, radius 0 = ~131 tokens\n      const content = \"x\".repeat(radius * 400 + 400);\n      return {\n        atlas_timestamp: \"2025-01-01T00:00:00Z\",\n        seed_modules: [\"a\"],\n        fold_radius: radius,\n        modules: [],\n        edges: [],\n        critical_rule: content,\n      };\n    };\n\n    // Set limit to 250: radius 2 exceeds (331), radius 1 fits (231)\n    const result = autoTuneRadius(generateFn, 2, 250);\n\n    // Should have tried radius 2, then radius 1\n    assert.ok(callCount >= 2);\n    assert.equal(result.radiusUsed, 1);\n    assert.ok(result.tokensUsed <= 250);\n  });\n\n  test(\"stops at radius 0 if still exceeding limit\", () => {\n    const generateFn = (radius) => ({\n      atlas_timestamp: \"2025-01-01T00:00:00Z\",\n      seed_modules: [\"a\"],\n      fold_radius: radius,\n      modules: [],\n      edges: [],\n      critical_rule: \"x\".repeat(1000), // Always large\n    });\n\n    const result = autoTuneRadius(generateFn, 3, 10); // Very small limit\n\n    // Should reduce to radius 0 and stop\n    assert.equal(result.radiusUsed, 0);\n    // Even at radius 0, still exceeds limit, but returns anyway\n    assert.ok(result.tokensUsed > 10);\n  });\n\n  test(\"calls adjustment callback when reducing radius\", () => {\n    const adjustments = [];\n\n    const generateFn = (radius) => ({\n      atlas_timestamp: \"2025-01-01T00:00:00Z\",\n      seed_modules: [\"a\"],\n      fold_radius: radius,\n      modules: [],\n      edges: [],\n      critical_rule: \"x\".repeat(radius * 200 + 200),\n    });\n\n    const result = autoTuneRadius(generateFn, 3, 120, (oldRadius, newRadius, tokens, limit) => {\n      adjustments.push({ oldRadius, newRadius, tokens, limit });\n    });\n\n    // Should have reduced radius at least once\n    assert.ok(adjustments.length > 0);\n\n    // Each adjustment should show radius decreasing\n    for (const adj of adjustments) {\n      assert.equal(adj.newRadius, adj.oldRadius - 1);\n      assert.equal(adj.limit, 120);\n      assert.ok(adj.tokens > adj.limit);\n    }\n  });\n\n  test(\"does not call adjustment callback if no reduction needed\", () => {\n    let callbackCalled = false;\n\n    const generateFn = (radius) => ({\n      atlas_timestamp: \"2025-01-01T00:00:00Z\",\n      seed_modules: [\"a\"],\n      fold_radius: radius,\n      modules: [],\n      edges: [],\n      critical_rule: \"small\",\n    });\n\n    const result = autoTuneRadius(generateFn, 2, 10000, () => {\n      callbackCalled = true;\n    });\n\n    assert.equal(callbackCalled, false);\n    assert.equal(result.radiusUsed, 2);\n  });\n});\n\ndescribe(\"estimateTokensBeforeGeneration\", () => {\n  test(\"estimates increase with more seeds\", () => {\n    const tokens1 = estimateTokensBeforeGeneration(1, 1);\n    const tokens5 = estimateTokensBeforeGeneration(5, 1);\n\n    assert.ok(tokens5 > tokens1);\n  });\n\n  test(\"estimates increase with higher radius\", () => {\n    const radius0 = estimateTokensBeforeGeneration(1, 0);\n    const radius1 = estimateTokensBeforeGeneration(1, 1);\n    const radius2 = estimateTokensBeforeGeneration(1, 2);\n\n    assert.ok(radius1 > radius0);\n    assert.ok(radius2 > radius1);\n  });\n\n  test(\"uses custom average degree\", () => {\n    // Higher degree = more module expansion\n    const lowDegree = estimateTokensBeforeGeneration(1, 1, 2);\n    const highDegree = estimateTokensBeforeGeneration(1, 1, 5);\n\n    assert.ok(highDegree > lowDegree);\n  });\n\n  test(\"uses custom tokens per module\", () => {\n    const lowTokens = estimateTokensBeforeGeneration(1, 1, 3, 100);\n    const highTokens = estimateTokensBeforeGeneration(1, 1, 3, 500);\n\n    assert.ok(highTokens > lowTokens);\n  });\n\n  test(\"radius 0 returns approximately seed count * tokens per module\", () => {\n    const seeds = 5;\n    const tokensPerModule = 200;\n    const estimated = estimateTokensBeforeGeneration(seeds, 0, 3, tokensPerModule);\n\n    // Radius 0 = just seed modules + overhead\n    // Should be approximately seeds * tokensPerModule + overhead\n    const expected = seeds * tokensPerModule;\n\n    // Within 50% margin (rough estimate)\n    assert.ok(estimated >= expected * 0.5);\n    assert.ok(estimated <= expected * 1.5);\n  });\n});\n\nconsole.log(\"All auto-tune tests passed! âœ…\");\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/atlas/cache.test.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/atlas/rebuild.perf.test.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/atlas/rebuild.spec.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/atlas/validate.spec.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/cli/cli.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'readFileSync' is defined but never used. Allowed unused vars must match /^_/u.","line":10,"column":56,"nodeType":null,"messageId":"unusedVar","endLine":10,"endColumn":68}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * CLI Tests\n *\n * Tests for lex remember, lex recall, and lex check commands\n */\n\nimport { test } from \"node:test\";\nimport assert from \"node:assert\";\nimport { execSync } from \"node:child_process\";\nimport { writeFileSync, mkdirSync, existsSync, rmSync, readFileSync } from \"fs\";\nimport { join } from \"path\";\nimport { tmpdir } from \"os\";\n\nconst testDir = join(tmpdir(), \"lex-cli-test-\" + Date.now());\nconst testDbPath = join(testDir, \"frames.db\");\nconst lexBin = join(process.cwd(), \"dist\", \"shared\", \"cli\", \"lex.js\");\n\n// Setup test environment\nfunction setupTest() {\n  if (existsSync(testDir)) {\n    rmSync(testDir, { recursive: true, force: true });\n  }\n  mkdirSync(testDir, { recursive: true });\n\n  // Create a minimal policy file for testing\n  const policyPath = join(testDir, \"lexmap.policy.json\");\n  const policy = {\n    modules: {\n      \"ui/admin-panel\": {\n        owns_paths: [\"web-ui/admin/**\"],\n      },\n      \"services/auth-core\": {\n        owns_paths: [\"backend/auth/**\"],\n        forbidden_callers: [\"ui/**\"],\n      },\n      \"services/user-api\": {\n        owns_paths: [\"backend/users/**\"],\n      },\n    },\n  };\n  writeFileSync(policyPath, JSON.stringify(policy, null, 2));\n\n  // Set environment variable for policy path\n  process.env.LEX_POLICY_PATH = policyPath;\n  process.env.LEX_DB_PATH = testDbPath;\n}\n\nfunction cleanup() {\n  if (existsSync(testDir)) {\n    rmSync(testDir, { recursive: true, force: true });\n  }\n  delete process.env.LEX_POLICY_PATH;\n  delete process.env.LEX_DB_PATH;\n}\n\ntest(\"CLI: lex --version shows version\", () => {\n  setupTest();\n  try {\n    const output = execSync(`node ${lexBin} --version`, { encoding: \"utf-8\" });\n    assert.match(output, /\\d+\\.\\d+\\.\\d+/, \"Version should be in semver format\");\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex --help shows help text\", () => {\n  setupTest();\n  try {\n    const output = execSync(`node ${lexBin} --help`, { encoding: \"utf-8\" });\n    assert.match(output, /remember/, \"Help should mention remember command\");\n    assert.match(output, /recall/, \"Help should mention recall command\");\n    assert.match(output, /check/, \"Help should mention check command\");\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex remember with valid module_scope succeeds\", () => {\n  setupTest();\n  try {\n    const output = execSync(\n      `node ${lexBin} remember ` +\n        `--reference-point \"test frame\" ` +\n        `--summary \"Test summary\" ` +\n        `--next \"Test next action\" ` +\n        `--modules \"ui/admin-panel,services/user-api\"`,\n      { encoding: \"utf-8\", env: { ...process.env, LEX_DB_PATH: testDbPath } }\n    );\n\n    assert.match(output, /Frame created successfully/, \"Should show success message\");\n    assert.match(output, /Frame ID:/, \"Should show Frame ID\");\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex remember with invalid module_scope fails\", () => {\n  setupTest();\n  try {\n    execSync(\n      `node ${lexBin} remember ` +\n        `--reference-point \"test frame\" ` +\n        `--summary \"Test summary\" ` +\n        `--next \"Test next action\" ` +\n        `--modules \"invalid-module\"`,\n      { encoding: \"utf-8\", env: { ...process.env, LEX_DB_PATH: testDbPath } }\n    );\n    assert.fail(\"Should have thrown an error\");\n  } catch (error: any) {\n    assert.match(\n      error.stderr || error.stdout,\n      /Module validation failed/,\n      \"Should show validation error\"\n    );\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex remember with --json outputs JSON\", () => {\n  setupTest();\n  try {\n    const output = execSync(\n      `node ${lexBin} --json remember ` +\n        `--reference-point \"json test\" ` +\n        `--summary \"JSON test\" ` +\n        `--next \"Test action\" ` +\n        `--modules \"ui/admin-panel\"`,\n      { encoding: \"utf-8\", env: { ...process.env, LEX_DB_PATH: testDbPath } }\n    );\n\n    const json = JSON.parse(output.trim());\n    assert.ok(json.id, \"JSON should contain Frame ID\");\n    assert.ok(json.timestamp, \"JSON should contain timestamp\");\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex recall retrieves created frame\", () => {\n  setupTest();\n  try {\n    // Create a frame first\n    execSync(\n      `node ${lexBin} remember ` +\n        `--reference-point \"recall test frame\" ` +\n        `--summary \"Test recall\" ` +\n        `--next \"Test action\" ` +\n        `--modules \"ui/admin-panel\"`,\n      { encoding: \"utf-8\", env: { ...process.env, LEX_DB_PATH: testDbPath } }\n    );\n\n    // Recall it\n    const output = execSync(`node ${lexBin} recall \"recall test frame\"`, {\n      encoding: \"utf-8\",\n      env: { ...process.env, LEX_DB_PATH: testDbPath },\n    });\n\n    assert.match(output, /recall test frame/, \"Should show reference point\");\n    assert.match(output, /Test recall/, \"Should show summary\");\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex recall with --json outputs JSON\", () => {\n  setupTest();\n  try {\n    // Create a frame first\n    execSync(\n      `node ${lexBin} remember ` +\n        `--reference-point \"json recall test\" ` +\n        `--summary \"JSON recall\" ` +\n        `--next \"Test action\" ` +\n        `--modules \"ui/admin-panel\"`,\n      { encoding: \"utf-8\", env: { ...process.env, LEX_DB_PATH: testDbPath } }\n    );\n\n    // Recall it\n    const output = execSync(`node ${lexBin} --json recall \"json recall test\"`, {\n      encoding: \"utf-8\",\n      env: { ...process.env, LEX_DB_PATH: testDbPath },\n    });\n\n    const json = JSON.parse(output.trim());\n    assert.ok(Array.isArray(json), \"JSON should be an array\");\n    assert.ok(json.length > 0, \"JSON should contain results\");\n    assert.ok(json[0].frame, \"JSON should contain frame data\");\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex check with no violations exits with 0\", () => {\n  setupTest();\n  try {\n    const mergedPath = join(testDir, \"merged.json\");\n    const policyPath = join(testDir, \"lexmap.policy.json\");\n\n    // Create a merged scanner output with no violations\n    const merged = {\n      sources: [\"test\"],\n      files: [\n        {\n          path: \"web-ui/admin/test.ts\",\n          module_scope: \"ui/admin-panel\",\n          declarations: [],\n          imports: [{ from: \"services/user-api\", type: \"default\" }],\n          feature_flags: [],\n          permissions: [],\n          warnings: [],\n        },\n      ],\n    };\n    writeFileSync(mergedPath, JSON.stringify(merged, null, 2));\n\n    const output = execSync(`node ${lexBin} check ${mergedPath} ${policyPath}`, {\n      encoding: \"utf-8\",\n    });\n\n    assert.match(output, /No policy violations/, \"Should show no violations\");\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex check with violations exits with 1\", () => {\n  setupTest();\n  try {\n    const mergedPath = join(testDir, \"merged.json\");\n    const policyPath = join(testDir, \"lexmap.policy.json\");\n\n    // Create a merged scanner output with violations\n    const merged = {\n      sources: [\"test\"],\n      files: [\n        {\n          path: \"web-ui/admin/test.ts\",\n          module_scope: \"ui/admin-panel\",\n          declarations: [],\n          imports: [{ from: \"services/auth-core\", type: \"default\" }],\n          feature_flags: [],\n          permissions: [],\n          warnings: [],\n        },\n      ],\n    };\n    writeFileSync(mergedPath, JSON.stringify(merged, null, 2));\n\n    try {\n      execSync(`node ${lexBin} check ${mergedPath} ${policyPath}`, { encoding: \"utf-8\" });\n      assert.fail(\"Should have exited with code 1\");\n    } catch (error: any) {\n      assert.strictEqual(error.status, 1, \"Should exit with code 1\");\n      const output = error.stdout || error.stderr;\n      assert.match(output, /violation/i, \"Should mention violations\");\n    }\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex check with --json outputs JSON\", () => {\n  setupTest();\n  try {\n    const mergedPath = join(testDir, \"merged.json\");\n    const policyPath = join(testDir, \"lexmap.policy.json\");\n\n    // Create a merged scanner output with no violations\n    const merged = {\n      sources: [\"test\"],\n      files: [],\n    };\n    writeFileSync(mergedPath, JSON.stringify(merged, null, 2));\n\n    const output = execSync(`node ${lexBin} --json check ${mergedPath} ${policyPath}`, {\n      encoding: \"utf-8\",\n    });\n\n    const json = JSON.parse(output.trim());\n    assert.ok(Array.isArray(json.violations), \"JSON should contain violations array\");\n    assert.strictEqual(json.count, 0, \"JSON should show count of 0\");\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex timeline shows frames for a ticket\", () => {\n  setupTest();\n  try {\n    // Create multiple frames for the same ticket\n    execSync(\n      `node ${lexBin} remember ` +\n        `--jira TICKET-123 ` +\n        `--reference-point \"frame 1\" ` +\n        `--summary \"First frame\" ` +\n        `--next \"Test action 1\" ` +\n        `--modules \"ui/admin-panel\"`,\n      { encoding: \"utf-8\", env: { ...process.env, LEX_DB_PATH: testDbPath } }\n    );\n\n    execSync(\n      `node ${lexBin} remember ` +\n        `--jira TICKET-123 ` +\n        `--reference-point \"frame 2\" ` +\n        `--summary \"Second frame\" ` +\n        `--next \"Test action 2\" ` +\n        `--modules \"ui/admin-panel,services/user-api\"`,\n      { encoding: \"utf-8\", env: { ...process.env, LEX_DB_PATH: testDbPath } }\n    );\n\n    // Get timeline\n    const output = execSync(`node ${lexBin} timeline TICKET-123`, {\n      encoding: \"utf-8\",\n      env: { ...process.env, LEX_DB_PATH: testDbPath },\n    });\n\n    assert.match(output, /TICKET-123/, \"Should show ticket ID\");\n    assert.match(output, /First frame/, \"Should show first frame\");\n    assert.match(output, /Second frame/, \"Should show second frame\");\n    assert.match(output, /Module Scope Evolution/, \"Should show module scope evolution\");\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex timeline with --format=json outputs JSON\", () => {\n  setupTest();\n  try {\n    // Create a frame\n    execSync(\n      `node ${lexBin} remember ` +\n        `--jira TICKET-456 ` +\n        `--reference-point \"json timeline test\" ` +\n        `--summary \"JSON test\" ` +\n        `--next \"Test action\" ` +\n        `--modules \"ui/admin-panel\"`,\n      { encoding: \"utf-8\", env: { ...process.env, LEX_DB_PATH: testDbPath } }\n    );\n\n    // Get timeline as JSON\n    const output = execSync(`node ${lexBin} timeline TICKET-456 --format=json`, {\n      encoding: \"utf-8\",\n      env: { ...process.env, LEX_DB_PATH: testDbPath },\n    });\n\n    const json = JSON.parse(output.trim());\n    assert.ok(Array.isArray(json), \"JSON should be an array\");\n    assert.ok(json.length > 0, \"JSON should contain timeline entries\");\n    assert.ok(json[0].frame, \"Entry should contain frame\");\n  } finally {\n    cleanup();\n  }\n});\n\ntest(\"CLI: lex timeline shows blocker evolution\", () => {\n  setupTest();\n  try {\n    // Create frames with blockers\n    execSync(\n      `node ${lexBin} remember ` +\n        `--jira TICKET-789 ` +\n        `--reference-point \"blocker test 1\" ` +\n        `--summary \"Frame with blocker\" ` +\n        `--next \"Test action\" ` +\n        `--modules \"ui/admin-panel\" ` +\n        `--blockers \"CORS issue\"`,\n      { encoding: \"utf-8\", env: { ...process.env, LEX_DB_PATH: testDbPath } }\n    );\n\n    execSync(\n      `node ${lexBin} remember ` +\n        `--jira TICKET-789 ` +\n        `--reference-point \"blocker test 2\" ` +\n        `--summary \"Frame without blocker\" ` +\n        `--next \"Test action\" ` +\n        `--modules \"ui/admin-panel\"`,\n      { encoding: \"utf-8\", env: { ...process.env, LEX_DB_PATH: testDbPath } }\n    );\n\n    // Get timeline\n    const output = execSync(`node ${lexBin} timeline TICKET-789`, {\n      encoding: \"utf-8\",\n      env: { ...process.env, LEX_DB_PATH: testDbPath },\n    });\n\n    assert.match(output, /CORS issue/, \"Should show blocker\");\n    assert.match(output, /Blocker Tracking/, \"Should show blocker tracking section\");\n  } finally {\n    cleanup();\n  }\n});\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/cli/output.behavior.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/config.spec.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/git/branch.test.ts","messages":[{"ruleId":"@typescript-eslint/no-unused-vars","severity":1,"message":"'e' is defined but never used.","line":44,"column":16,"nodeType":null,"messageId":"unusedVar","endLine":44,"endColumn":17}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Tests for git branch detection utilities\n *\n * Tests cover:\n * - Normal git repository branch detection\n * - Detached HEAD state\n * - Non-git directory\n * - Environment variable override\n * - Caching behavior\n * - Error handling\n */\n\nimport { test, describe, beforeEach } from \"node:test\";\nimport assert from \"node:assert\";\nimport { getCurrentBranch, clearBranchCache } from \"@app/shared/git/branch.js\";\nimport { execSync } from \"child_process\";\nimport { mkdtempSync, rmSync } from \"fs\";\nimport { join } from \"path\";\nimport { tmpdir } from \"os\";\n\ndescribe(\"Git Branch Detection\", () => {\n  let originalDir: string;\n  let originalEnv: string | undefined;\n\n  // Setup: save current directory and environment\n  beforeEach(() => {\n    originalDir = process.cwd();\n    originalEnv = process.env.LEX_DEFAULT_BRANCH;\n    delete process.env.LEX_DEFAULT_BRANCH;\n    clearBranchCache();\n  });\n\n  // Teardown helper\n  function teardown(testDir?: string) {\n    process.chdir(originalDir);\n    if (originalEnv !== undefined) {\n      process.env.LEX_DEFAULT_BRANCH = originalEnv;\n    } else {\n      delete process.env.LEX_DEFAULT_BRANCH;\n    }\n    if (testDir) {\n      try {\n        rmSync(testDir, { recursive: true, force: true });\n      } catch (e) {\n        // Ignore cleanup errors\n      }\n    }\n    clearBranchCache();\n  }\n\n  test(\"detects current branch in normal git repository\", () => {\n    try {\n      // We're in the lex repo, so this should return the actual branch\n      const branch = getCurrentBranch();\n\n      // Should not be the fallback values\n      assert.notStrictEqual(branch, \"unknown\", \"Should detect branch in git repo\");\n      assert.notStrictEqual(branch, \"\", \"Branch should not be empty\");\n\n      // Should match what git actually says (unless detached)\n      if (branch !== \"detached\") {\n        const actualBranch = execSync(\"git rev-parse --abbrev-ref HEAD\", {\n          encoding: \"utf-8\",\n        }).trim();\n        assert.strictEqual(branch, actualBranch, \"Should match actual git branch\");\n      }\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"handles detached HEAD state\", () => {\n    // Create a temporary git repository\n    const testDir = mkdtempSync(join(tmpdir(), \"lex-git-test-\"));\n\n    try {\n      process.chdir(testDir);\n\n      // Initialize git repo\n      execSync(\"git init\", { stdio: \"pipe\" });\n      execSync('git config user.email \"test@example.com\"', { stdio: \"pipe\" });\n      execSync('git config user.name \"Test User\"', { stdio: \"pipe\" });\n\n      // Create a commit\n      execSync(\"touch test.txt\", { stdio: \"pipe\" });\n      execSync(\"git add test.txt\", { stdio: \"pipe\" });\n      execSync('git commit -m \"Initial commit\"', { stdio: \"pipe\" });\n\n      // Get the commit hash\n      const commitHash = execSync(\"git rev-parse HEAD\", {\n        encoding: \"utf-8\",\n      }).trim();\n\n      // Checkout the commit to create detached HEAD\n      execSync(`git checkout ${commitHash}`, { stdio: \"pipe\" });\n\n      // Clear cache and test\n      clearBranchCache();\n      const branch = getCurrentBranch();\n\n      assert.strictEqual(branch, \"detached\", \"Should return 'detached' for detached HEAD\");\n    } finally {\n      teardown(testDir);\n    }\n  });\n\n  test(\"handles non-git directory\", () => {\n    // Create a temporary non-git directory\n    const testDir = mkdtempSync(join(tmpdir(), \"lex-nongit-test-\"));\n\n    try {\n      process.chdir(testDir);\n\n      const branch = getCurrentBranch();\n\n      assert.strictEqual(branch, \"unknown\", \"Should return 'unknown' for non-git directory\");\n    } finally {\n      teardown(testDir);\n    }\n  });\n\n  test(\"respects LEX_DEFAULT_BRANCH environment variable\", () => {\n    try {\n      process.env.LEX_DEFAULT_BRANCH = \"custom-branch\";\n      clearBranchCache();\n\n      const branch = getCurrentBranch();\n\n      assert.strictEqual(branch, \"custom-branch\", \"Should return env var value\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"environment variable override takes precedence over git\", () => {\n    try {\n      // Even in a git repo, env var should take precedence\n      process.env.LEX_DEFAULT_BRANCH = \"env-override\";\n      clearBranchCache();\n\n      const branch = getCurrentBranch();\n\n      assert.strictEqual(branch, \"env-override\", \"Env var should override git detection\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"caches branch result for performance\", () => {\n    try {\n      clearBranchCache();\n\n      // First call\n      const branch1 = getCurrentBranch();\n\n      // Second call should return cached value (same result)\n      const branch2 = getCurrentBranch();\n\n      assert.strictEqual(branch1, branch2, \"Cached result should match first call\");\n    } finally {\n      teardown();\n    }\n  });\n\n  test(\"clearBranchCache allows re-detection\", () => {\n    // Create a temporary git repository\n    const testDir = mkdtempSync(join(tmpdir(), \"lex-cache-test-\"));\n\n    try {\n      process.chdir(testDir);\n\n      // Initialize git repo with a branch\n      execSync(\"git init\", { stdio: \"pipe\" });\n      execSync('git config user.email \"test@example.com\"', { stdio: \"pipe\" });\n      execSync('git config user.name \"Test User\"', { stdio: \"pipe\" });\n      execSync(\"touch test.txt\", { stdio: \"pipe\" });\n      execSync(\"git add test.txt\", { stdio: \"pipe\" });\n      execSync('git commit -m \"Initial commit\"', { stdio: \"pipe\" });\n\n      // Get initial branch\n      clearBranchCache();\n      const branch1 = getCurrentBranch();\n\n      // Switch to a new branch\n      execSync(\"git checkout -b feature-branch\", { stdio: \"pipe\" });\n\n      // Without clearing cache, should return old value\n      const branch2 = getCurrentBranch();\n      assert.strictEqual(branch2, branch1, \"Should return cached value\");\n\n      // After clearing cache, should detect new branch\n      clearBranchCache();\n      const branch3 = getCurrentBranch();\n      assert.strictEqual(branch3, \"feature-branch\", \"Should detect new branch after cache clear\");\n    } finally {\n      teardown(testDir);\n    }\n  });\n\n  test(\"handles git command errors gracefully\", () => {\n    // Create a temporary directory\n    const testDir = mkdtempSync(join(tmpdir(), \"lex-error-test-\"));\n\n    try {\n      process.chdir(testDir);\n\n      // No git repo, so command should fail\n      const branch = getCurrentBranch();\n\n      assert.strictEqual(branch, \"unknown\", \"Should handle git errors gracefully\");\n    } finally {\n      teardown(testDir);\n    }\n  });\n});\n","usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/logger.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/module_ids/validator.test.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/module_ids/validator.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/policy/loader.test.mjs","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/policy/loader.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/prompts/loader.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/prompts/renderer.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/schemas/loader.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/srv/lex-mcp/lex/test/shared/types/frame.test.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]}]
